{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Q/A.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq8t9CErtOY4RNZIMAsnji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanaythakral/BERT-Q-A/blob/master/BERT%20for%20QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAac8I9PszN2"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8tpzbIxsx8l",
        "outputId": "cba84e2d-50d9-4a8a-9e78-1df9dba3e23a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuuAk1XCsx7Q",
        "outputId": "de87bc5b-55cf-4c77-f137-207733f43a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Thesis project/Thesis project/datasets/WOF_split_into_sentences.csv')\n",
        "sentences = list(df['Sentences'])\n",
        "len(sentences)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0bANhj3vS7t",
        "outputId": "49fbea4d-11cf-4a6f-8c01-7ebe708d67a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.35.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4r97qrSs1Mr"
      },
      "source": [
        "#Context Extraction \n",
        "Using TF-IDF cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LrnnlWns_gg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk import wordpunct_tokenize, WordNetLemmatizer, sent_tokenize, pos_tag\n",
        "from nltk.corpus import stopwords as sw, wordnet as wn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import string \n",
        "import json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reZhLQBds_fM"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "X = normalize(X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfQilXwis_eg",
        "outputId": "ac7fb239-8d70-4276-c17d-c3ccb3757e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3085, 6929)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFYQTr5Ms_d3"
      },
      "source": [
        "def get_context(query,X,data_sentences):\n",
        "  Question = vectorizer.transform([query])\n",
        "  Question = normalize(Question)\n",
        "  cosineSimilarities = cosine_similarity(Question, X).flatten()\n",
        "  idx = cosineSimilarities.argsort()[::-1][:20]\n",
        "  temp = \"\"\n",
        "  print(query)\n",
        "  for i in idx:\n",
        "    if(cosineSimilarities[i] != 0):\n",
        "      # if(i-1 >=0):\n",
        "      #   temp = temp + data_sentences[i-1]\n",
        "      temp = temp + data_sentences[i]\n",
        "      # if(i+1 < len(data_sentences)):\n",
        "      #   temp = temp + data_sentences[i+1]\n",
        "  return temp\n",
        "\n",
        "def make_json_list(queries,X,sentences):\n",
        "  jsondata = {}\n",
        "  data1 = {}  \n",
        "  paras =[]\n",
        "  gpt2_feed = []\n",
        "  for idx,query in enumerate(queries):\n",
        "    context = get_context(query,X,sentences)\n",
        "    if(context == \"\"):\n",
        "      gpt2_feed.append(query)\n",
        "      continue\n",
        "    qa1 = {}\n",
        "    qa1[\"question\"] = query\n",
        "    qa1[\"id\"] = str(idx)\n",
        "    qa1[\"is_impossible\"] = \"\"\n",
        "    qas = [qa1]\n",
        "    paragraph1 = {}\n",
        "    paragraph1[\"qas\"] =[qa1]\n",
        "    paragraph1[\"context\"] = context\n",
        "    paras.append(paragraph1)\n",
        "\n",
        "  data1[\"paragraphs\"] = paras\n",
        "  data1[\"title\"] = \"WOF\"\n",
        "  data = [data1]\n",
        "  jsondata[\"version\"] = \"v2.0\"\n",
        "  jsondata[\"data\"] = data\n",
        "  jstr = json.dumps(jsondata,indent = 5)\n",
        "  print(json.dumps(jsondata,indent = 5))\n",
        "  return jstr,gpt2_feed\n",
        "\n",
        "\n",
        "def make_json(query,X,sentences):\n",
        "  context = get_context(query,X,sentences)\n",
        "  if(context == \"\"):\n",
        "    return 0\n",
        "  jsondata = {}\n",
        "  data1 = {}  \n",
        "  qa1 = {}\n",
        "  paragraph1 = {}\n",
        "  qa1[\"question\"] = query\n",
        "  qa1[\"id\"] = \"1\"\n",
        "  qa1[\"is_impossible\"] = \"\"\n",
        "  qas = [qa1]\n",
        "  paragraph1[\"qas\"] =[qa1]\n",
        "  paragraph1[\"context\"] = context\n",
        "  \n",
        "  \n",
        "  paras = [paragraph1]\n",
        "  data1[\"paragraphs\"] = paras\n",
        "  data1[\"title\"] = \"WOF\"\n",
        "  data = [data1]\n",
        "  jsondata[\"version\"] = \"v2.0\"\n",
        "  jsondata[\"data\"] = data\n",
        "  jstr = json.dumps(jsondata,indent = 5)\n",
        "  print(json.dumps(jsondata,indent = 5))\n",
        "  return jstr"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G07wuzdzs_c-",
        "outputId": "d5dccb45-4cd4-42ef-804b-3f1b52bae361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_questions = [\"What is your name?\",\"What is SLV?\", \"When is your birthday?\" , \"Who is Narayan?\", \"Who is your sister?\", \"where are you from?\", \"Where is Pentagon?\" , \"where did Trishul take off from?\", \"What is Prithvi?\" ,\"What is Astra?\", \"Did you have childhood friends?\",\"Which school did you go to as a child?\" , \"when did you start liking Science?\", \"What was your role in Nike-Apache?\" , \"What are sounding rockets used for?\" , \"Are you religious?\" , \"What is SAM?\" , \"Who is Indira Gandhi?\" , \"Who conferred the Honorary Doctor of Science degree on to you?\" , \"What is TCV?\"]\n",
        "jstr,gpt2_feed = make_json_list(test_questions,X,sentences)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is your name?\n",
            "What is SLV?\n",
            "When is your birthday?\n",
            "Who is Narayan?\n",
            "Who is your sister?\n",
            "where are you from?\n",
            "Where is Pentagon?\n",
            "where did Trishul take off from?\n",
            "What is Prithvi?\n",
            "What is Astra?\n",
            "Did you have childhood friends?\n",
            "Which school did you go to as a child?\n",
            "when did you start liking Science?\n",
            "What was your role in Nike-Apache?\n",
            "What are sounding rockets used for?\n",
            "Are you religious?\n",
            "What is SAM?\n",
            "Who is Indira Gandhi?\n",
            "Who conferred the Honorary Doctor of Science degree on to you?\n",
            "What is TCV?\n",
            "{\n",
            "     \"version\": \"v2.0\",\n",
            "     \"data\": [\n",
            "          {\n",
            "               \"paragraphs\": [\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"What is SLV?\",\n",
            "                                   \"id\": \"1\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"He drew the entire SLV  team close and demonstrated to me that I was not alone in my sorrow at  the SLV- 's failure.I therefore  take responsibility for the SLV- failure\\\".Now, before I dwell  on the finer aspects of the management of the SLV- project, let me talk  about the SLV- itself.I shared my SLV- experience with them.The next SLV- flight, SLV-D, took off on May, witnessed  this flight from the visitors' gallery.\\\"Everyone will work  to create their bit of SLV; your problem is going to be your dependency  on others in accomplishing the total SLV.The primary objectives of the SLV Project were design, development  and operation of a standard SLV system, SLV-, capable of reliably and  expeditiously fulfilling the specified mission of launching a  kg satellite  into a  km circular orbit around the earth.Although SLV- was still in the future, its subsystems were being  completed.Within a month of the SLV- success, I visited the Nehru Science  Centre in Bombay for a day, in response to an invitation to share my  experiences with the SLV-.We had all come under the current of the SLV flow.It is very important  to know the state of the SLV when it is in flight.Between SLV- and now, we had developed a mutual  affection.From my SLV- experience, I thought I knew  the answer.Back home at VSSC, SLV was taking shape.Such spells increased steadily in frequency, and the SLV- dream was  finally realised in the middle of We had scheduled the first experimental flight trial of SLV- for    August .The SLV mission will be  accomplished with, and through, a large number of people.Some   highlighted SLV- 's possible military implications in terms of acquiring  the capability for building IRBMs. Some were a general prognosis of all  that ailed our country and related it to the SLV-.The SLV- team developed their own internal success criteria.Each member of the SLV- project team was a specialist in his own  field.He told me that my progress on  the SLV project would bring me solace.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Who is your sister?\",\n",
            "                                   \"id\": \"4\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"My sister, Zohara, prepared special sweets for me.At that time, my sister, Zohara, stood behind me, mortgaging her gold  bangles and chain.Zohara, my sister, mortgaging her gold bangles  and chains to get me into engineering college?He worked at building  the boat on the seashore, with the help of a relative, Ahmed Jallaluddin,  who later married my sister, Zohara.I inherited honesty and self-discipline from my  father; from my mother, I inherited faith in goodness and deep kindness  and so did my three brothers and sister.My father, by now more than a hundred years old, pall-  bearer for his son-in-law, who had been half his age; the bereft soul of  my sister Zohara, her wounds from the loss of her four-year-old son still  raw \\u2014 these images came before my eyes in a blur, too terrible for me to  comprehend.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Where is Pentagon?\",\n",
            "                                   \"id\": \"6\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"After finishing our work at the Pentagon in Washington,  we landed in San Francisco on our way to Los Angeles to visit Northrop  Corporation.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"where did Trishul take off from?\",\n",
            "                                   \"id\": \"7\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"But he did.How did I do that ?But we did it at last!What was it that I did  not have?But what did  you do for the project\\\"?I did not find Rev.What did I want?How did it happen?I did well  at the interview.\\\"Why did you not prostrate yourself\\\"?With the completion of developmental trials  on Prithvi and Trishul, our choice was on test now.Somehow, I did not take to the new setting.The first launch of the Missile Programme was conducted on September , when Trishul took off from the test range at  Sriharikota (SHAR).Rear Admiral Mohan retired and his deputy, Kapoor, was to take  over Trishul.He did not take long to come to the point.Yet, he never  pretended to know more than he did.Or did we  have divine protection?The new aircraft did not need RATO.The successful test firing of Prithvi and  Trishul during the course of the Gulf War was enough to make an anxious  nation relax.It did not happen  immediately, but it happened nevertheless.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"What is Prithvi?\",\n",
            "                                   \"id\": \"8\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"Would a Prithvi suffice?\\\"When are you going to flight test Prithvi\\\"?Prithvi was launched at : hrs on  February .Prithvi had been designed as an inertially guided  missile.Work on Prithvi was nearing completion when we entered .The second flight of Prithvi at the end of September  was again  a great success.Working with Kurup on the Prithvi launch campaign gave me great  satisfaction.With the completion of developmental trials  on Prithvi and Trishul, our choice was on test now.Later Prithvi and then  Agni used similar guidance systems, with excellent results.The  importance of these rocket engines was not restricted to the Prithvi  project \\u2014 it was a national achievement.As I saw it, the development of Prithvi  represented the self-reliance of our country in the field of advanced  technology.Prithvi has proved to be the best surface-to-surface  missile in the world today.The launch of Prithvi sent shock waves across the unfriendly  neighbouring countries.Since the Interim Test Range at Balasore was still at least a year  away from completion, we had set up special facilities at SHAR for the  launch of Prithvi.The successful test firing of Prithvi and  Trishul during the course of the Gulf War was enough to make an anxious  nation relax.A common  query I encountered was whether Prithvi was superior to a Scud, whether  Akash could perform like a Patriot, and so on.Kurup worked for Prithvi as a team member, ignoring the  boundary lines that divide DRDO and ISRO, DRDL and SHAR.Thus the Surface-to-Surface weapon  system became Prithvi (\\\"the Earth\\\") and the Tactical Core Vehicle was  called Trishul (the trident of Lord Shiva).It is boosted by a first-stage solid rocket  motor derived from SLV- and further accelerated at the second stage  with the liquid rocket engines of Prithvi.My search for someone to lead the Prithvi project ended with  Col VJ Sundaram who belonged to the EME Corps of the Indian Army.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"What is Astra?\",\n",
            "                                   \"id\": \"9\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"I used this opportunity to share with the budding scientists my plans of  making an indigenous Air-to-Air missile, Astra.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Did you have childhood friends?\",\n",
            "                                   \"id\": \"10\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"I had three close friends in my childhood \\u2014 Ramanadha Sastry,  Aravindan, and Sivaprakasan.How did I do that ?What was it that I did  not have?But he did.But we did it at last!My childhood is precious to me, but would  it be of interest to anyone else?But what did  you do for the project\\\"?Some  of my friends cautioned me about what they termed as my naivete.I did not find Rev.What did I want?I did well  at the interview.How did it happen?In fact, I would say mine was a very secure  childhood, both materially and emotionally.Many friends, while asking me questions related  to space flights, sometimes slip into astrology.\\\"Why did you not prostrate yourself\\\"?Somehow, I did not take to the new setting.I tried  hard to do as he said, which was to strive to control my thoughts and my  mind and, through these, to influence my destiny Ironically, that destiny  did not lead me back to Rameswaram, but rather, swept me farther  away from the home of my childhood.But it was the time I spent with  Jallaluddin and Samsuddin that perhaps contributed most to the uniqueness  of my childhood and made all the difference in my later life.In this period of confusion and  uncertainty, memories from my childhood came back to me and I  discovered new meanings in them.To take an example from my  own life, I had been fascinated by the mysteries of the sky and the flight  of birds from early childhood.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Which school did you go to as a child?\",\n",
            "                                   \"id\": \"11\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"How did I do that ?But he did.What was it that I did  not have?But we did it at last!May God bless  you, my child\\\"!But what did  you do for the project\\\"?There was a child-like curiosity in him which was  very engaging.Occasionally, a child would appear and wave at the train.I did not find Rev.What did I want?I did well  at the interview.How did it happen?\\\"Why did you not prostrate yourself\\\"?I was struck by his irresistible, almost child-  like smile and gracious manner.Again miles to the Arab teaching school,  Climb sandy hills to Railway Station Road,  Collect, distribute newspapers to temple city citizens,  Few hours after sunrise, going to school.Take my word, this boy is  going to bring glory to his school and to his teachers\\\".After school, we went home and told our respective parents about  the incident.Somehow, I did not take to the new setting.He bluntly asked the teacher to either apologize or quit the school and  the island.Indeed, I  was the first child from Rameswaram to fly Iyadurai Solomon was a great teacher because he instilled in all the  children a sense of their own worth.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"when did you start liking Science?\",\n",
            "                                   \"id\": \"12\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"I wondered  where I should start.What was it that I did  not have?But we did it at last!How did I do that ?But he did.But what did  you do for the project\\\"?Nor did I have any information  about career opportunities available to a student of science.My day would start with a stroll of about  km around the lodge I  was living in.I did not find Rev.What did I want?How did it happen?I did well  at the interview.\\\"Why did you not prostrate yourself\\\"?I was very enthusiastic about ensuring that science  did not remain outside the purview of this wonderful language.Somehow, I did not take to the new setting.In science, reality is that which exists.His answer filled me with a strange energy and enthusiasm:   Whenever human beings find themselves alone, as a natural reaction,  they start looking for company.He did not take long to come to the point.Yet, he never  pretended to know more than he did.Technology, unlike science, is a group activity.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"What was your role in Nike-Apache?\",\n",
            "                                   \"id\": \"13\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"It was a sounding rocket, called Nike-  Apache, made at NASA.In the maiden Nike-Apache launch, I was in charge of rocket  integration and safety.After the successful  launch of Nike-Apache, he chose to share with us his dream of an  Indian Satellite Launch Vehicle.Dr Brahm Prakash played a very important role in shaping  my leadership skills.Two of my colleagues who played a very  active and crucial role in this launch were D Easwardas and R  Aravamudan.I emphasized the sea-skimming role of the core vehicle to  Admiral Dawson.Each individual creature on this beautiful planet is created by God  to fulfil a particular role.He describes  the role of visionary Indian scientists, such as Dr Vikram Sarabhai, and of the  creation of a coordinated network of research institutions.Their vision was very clear: if Indians were to play a  meaningful role in the community of nations, they must be second to  none in the application of advanced technologies to their real-life  problems.This excellent laboratory  played a truncated role that did not reflect its existing or potential  capabilities or even fulfill the expectations in South Block.This categorization now appears  nonsensical, as the US Air Force's ground- launched Tomahawk is used  in a tactical role, notwithstanding its range of some  km.I also drew  their attention to the crucial role that carbon-carbon and other advanced  composite materials play in mastering the re-entry technology.He  describes the struggles of his boyhood and youth, bringing alive everyday life  in a small town in South India and the inspirational role of educators.A crucial aspect of the team leader's  role is to negotiate with these key people for their requirements, and to  ensure that the dialogue continues on a regular basis as the situation  develops or changes.I will not be presumptuous enough to say that my life can be a role  model for anybody; but some poor child living in an obscure place, in an  underprivileged social setting may find a little solace in the way my destiny  has been shaped.Till the Agni launch, the Indian Armed Forces had been structured  for a strictly defensive role to safeguard our nation, to shield our  democratic processes from the turbulence in the countries around us  and to raise the cost of any external intervention to an unacceptable  level for countries which may entertain such notions.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"What are sounding rockets used for?\",\n",
            "                                   \"id\": \"14\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"The development of these rockets had resulted in a fully indigenous  capability in the production of sounding rockets as well as their propellants.Under this programme, a family of  operational sounding rockets were developed.Sounding rockets are normally used for probing the near-earth  environment, including the upper regions of the atmosphere.In June  , we used the Centaur sounding rocket launch  to test some of our critical systems.The RSR programme was responsible for the development and  fabrication of sounding rockets and their associated on-board systems  for scientific investigations in India.Until then the Indian Space Programme had not gone beyond  sounding rockets and even knowledgeable people were not ready to see  and acknowledge its efforts as anything more serious than fiddling around  with meteorological instruments.We made high-  strength glass cloth laminates to build non-magnetic payload housings  and flew them in two-stage sounding rockets.These rockets had wide  ranging capabilities, and to date several hundreds of these rockets have  been launched for various scientific and technological studies.When  Tipu Sultan was killed, the British captured more than  rockets and  subsystems of  rockets in the battle of Turukhanahally in .In fact, they are three different kinds of  rockets.This place was the base for NASA's sounding rocket programme.What is it  that distinguishes a sounding rocket from a Satellite Launch Vehicle  (SLV) and from a missile?That it would not be used was something beyond my comprehension.As participants in the SLV- project, we set three  milestones for ourselves: development and flight qualification of all  subsystems through sounding rockets by   ; sub-orbital flights by  ;  and the final orbital flight in .It was a sounding rocket, called Nike-  Apache, made at NASA.Because the distinction is more decisive in rocket engines, the term  propellant is used primarily to describe chemicals carried by rockets for  propulsive purposes.In the development of payloads for the sounding rockets, instead of  getting a certain payload and then engineering it to fit into the rocket, we  discussed the matter threadbare with the payload scientists working in  different organ-izations and at different locations.Slowly, but surely, two Indian rockets were born at Thumba.Narayanan used to needle me.We would make our own rockets, our own  Satellite Launch Vehicles (SLVs) and our own satellites.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Are you religious?\",\n",
            "                                   \"id\": \"15\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"Religious conquests continued.The value system  in which I had been nurtured was profoundly religious.Rules and policies are to be followed with religious fervour.I have always been a religious person in the sense that I maintain a  working partnership with God.As children, none of us ever felt any difference amongst  ourselves because of our religious differences and upbringing.In addition, there was the delicate matter of acquiring  a site of religious significance.With the passage of time, wars were  waged over religious and ideological beliefs; and now the dominant  struggle of sophisticated warfare is for economic and technological  supremacy.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Who is Indira Gandhi?\",\n",
            "                                   \"id\": \"17\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"We  were to meet the Prime Minister, Mrs Indira Gandhi.Prime Minister Indira Gandhi  cabled her congratulations.Prime Minister Indira Gandhi was a person with a tremendous sense  of pride \\u2014 in herself, in her work and in her country.Prime Minister  Indira Gandhi expressed her desire to personally apprise herself of the  progress of the IGMDP.In February, Prime Minister Indira Gandhi visited Thumba to dedicate TERLS  to the International Space Science Community.Shrimati  Gandhi asked.Prime Minister Indira Gandhi told Parliament  on  July ,\\\"The development and fabrication of relevant  technologies, subsystems and hardware (to make India's first Satellite  Launch Vehicle) are progressing satisfactorily.Madam Gandhi was a taskmaster, whereas Prime Minister  Rajiv Gandhi used his charisma to achieve his ends.On  July , Shrimati Gandhi visited DRDL.Agni was  the conclusion of a technological effort that was given its start by Prime  Minister Indira Gandhi when the country decided to break free from the  paralysing fetters of technological backwardness and slough off the dead  skin of subordination to industrialized nations.The  circumstances of Shrimati Gandhi's death were very ominous.Shrimati Gandhi's follow-up approach was not  only impressive, it was effective too.Her son, Rajiv Gandhi, took over as  the new Prime Minister of India.Suddenly, I saw Shrimati Gandhi smiling at me  as she said, \\\"Kalam!Shrimati Gandhi's death was a tremendous loss to the scientific  community.Shrimati Gandhi spoke to the Members  about the success of the SLV- and lauded our achievement.We were working on the action plan that had emerged from the  earlier month's review, when the news of Shrimati Gandhi's assassination  broke.Prime Minister Rajiv Gandhi laid the foundation stone of the Research  Centre Imarat (RCI) on  August .I consider Prof. Sarabhai as the Mahatma Gandhi of Indian science  \\u2014 generating leadership qualities in his team and inspiring them through  both ideas and example.Always encouraged to follow Buddha's or  Gandhi's teachings, how and why did India become a missile power is a  question that needs to be answered for future generations.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"Who conferred the Honorary Doctor of Science degree on to you?\",\n",
            "                                   \"id\": \"18\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"Meanwhile, Anna University, Madras, conferred the honorary degree  of Doctor of Science on me.The same year, I received an honorary degree of Doctor of Science  from the IIT, Bombay.Towards the end of , Jadavpur University conferred on me the  honour of Doctor of Science at a special convocation.To my delight, the honorary doctorate degree was awarded at a  convocation presided over by Prof. Raja Ramanna.I was conferred the Padma Vibhushan  along with Dr Arunachalam.This time  he had gone beyond the capabilities of any doctor, care or money.It had been nearly twenty years since I had  acquired my degree in aeronautical engineering.\\\"Your visit is enough for me to get well, why  bring a doctor and spend money on his fees\\\"?It is the agglomerate of all these aspects that decides  the degree and quality of a person's effort and performance.Whenever I learnt about my father's indifferent health, I would visit  Rameswaram with a good city doctor.Every time I did so, he would  chide me for my unnecessary concern and lecture me on the expenses  incurred on the doctor.In science, reality is that which exists.When I joined the B.Sc degree course at St.Joseph's, I was unaware  of any other option for higher education.Technology, unlike science, is a group activity.With a post-graduate degree in Aeronautical Engineering and expertise  in mechanical vibrations, Sundaram was head of the Structures Group  at DRDL.If you are a writer  who would secretly prefer to be a lawyer or a doctor, your written words  will feed but half the hunger of your readers; if you are a teacher who  would rather be a businessman, your instructions will meet but half the  need for knowledge of your students; if you are a scientist who hates  science, your performance will satisfy but half the needs of your mission.As I look at it,  the path of science can always wind through the heart.Gradually, I became aware of the difference between science and  technology, between research and development.Setbacks and  disappointments have always been and always will be an inherent part  of any career, even one in science.I have throughout my life tried to emulate my father in my own world  of science and technology.\"\n",
            "                    },\n",
            "                    {\n",
            "                         \"qas\": [\n",
            "                              {\n",
            "                                   \"question\": \"What is TCV?\",\n",
            "                                   \"id\": \"19\",\n",
            "                                   \"is_impossible\": \"\"\n",
            "                              }\n",
            "                         ],\n",
            "                         \"context\": \"The Tactical Core Vehicle (TCV) project had been  hanging fire for quite some time.\"\n",
            "                    }\n",
            "               ],\n",
            "               \"title\": \"WOF\"\n",
            "          }\n",
            "     ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IywmpB-BtZho"
      },
      "source": [
        "target = \"/content/drive/My Drive/Thesis project/Thesis project/datasets/jsons/context.json\"\n",
        "with open(target, \"w\") as outfile: \n",
        "    outfile.write(jstr) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfVKdEYltBXt"
      },
      "source": [
        "#BERT Q/A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNdTz5a1tIJ8",
        "outputId": "e21c35da-dcae-4436-ba77-974b3b51144d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.85 KiB | 4.07 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "--2020-09-30 06:46:03--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.124.128, 172.217.212.128, 172.217.214.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.124.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   135MB/s    in 2.9s    \n",
            "\n",
            "2020-09-30 06:46:06 (135 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo_RMir3vDL3",
        "outputId": "c05dd0b2-3b74-42bf-e367-8b3b14e72100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd bert"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCztOOvNungT",
        "outputId": "08e95bf3-e0a9-49d6-a198-3d03b2315578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is => ', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU address is =>  grpc://10.29.27.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5743208229570276053),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12109552467789443891),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13208596860776014844),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1594003637736477861),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8120811169984275798),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8596055683787211362),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13627971829071552279),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14913559059404178472),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4345278116556413257),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17886550892960700700),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 10125640712746277298)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhzUdM8puqIQ",
        "outputId": "e567d57e-35f4-4beb-8d49-ec203b25d371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "BUCKET = 'bucket-bert-qa' #@param {type:\"string\"}\n",
        "assert BUCKET, '*** Must specify an existing GCS bucket name ***'\n",
        "output_dir_name = 'bert_output' #@param {type:\"string\"}\n",
        "BUCKET_NAME = 'gs://{}'.format(BUCKET)\n",
        "OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET,output_dir_name)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://bucket-bert-qa/bert_output *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YtEyIvxuyQU"
      },
      "source": [
        "!cp \"/content/drive/My Drive/Thesis project/Thesis project/datasets/jsons/context.json\" \"/content/bert\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHwzYd2IvHgA",
        "outputId": "51092ce1-d45f-493c-e6a5-e558c6062549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_squad.py \\\n",
        "  --vocab_file=$BUCKET_NAME/uncased_L-12_H-768_A-12/vocab.txt \\\n",
        "  --bert_config_file=$BUCKET_NAME/uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "  --init_checkpoint=$OUTPUT_DIR/model.ckpt-10859 \\\n",
        "  --do_train=False \\\n",
        "  --max_query_length=30  \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file=context.json \\\n",
        "  --predict_batch_size=8 \\\n",
        "  --n_best_size=3 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --doc_stride=128 \\\n",
        "  --version_2_with_negative=True \\\n",
        "  --output_dir=output/"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:1283: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0930 06:58:59.792514 140552314279808 deprecation_wrapper.py:119] From run_squad.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0930 06:58:59.792715 140552314279808 deprecation_wrapper.py:119] From run_squad.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0930 06:58:59.793078 140552314279808 deprecation_wrapper.py:119] From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0930 06:59:01.067601 140552314279808 deprecation_wrapper.py:119] From run_squad.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "I0930 06:59:02.102586 140552314279808 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0930 06:59:02.418624 140552314279808 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd4b76846a8>) includes params argument, but params are not passed to Estimator.\n",
            "W0930 06:59:02.419263 140552314279808 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd4b76846a8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd4abb40828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0930 06:59:02.420621 140552314279808 estimator.py:209] Using config: {'_model_dir': 'output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd4abb40828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0930 06:59:02.420918 140552314279808 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0930 06:59:02.421518 140552314279808 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From run_squad.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0930 06:59:02.421707 140552314279808 deprecation_wrapper.py:119] From run_squad.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0930 06:59:02.430928 140552314279808 deprecation_wrapper.py:119] From run_squad.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0930 06:59:02.439725 140552314279808 deprecation_wrapper.py:119] From run_squad.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.439964 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000000\n",
            "I0930 06:59:02.440076 140552314279808 run_squad.py:432] unique_id: 1000000000\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0930 06:59:02.440165 140552314279808 run_squad.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.440247 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is sl ##v ? [SEP] he drew the entire sl ##v team close and demonstrated to me that i was not alone in my sorrow at the sl ##v - ' s failure . i therefore take responsibility for the sl ##v - failure \" . now , before i dwell on the finer aspects of the management of the sl ##v - project , let me talk about the sl ##v - itself . i shared my sl ##v - experience with them . the next sl ##v - flight , sl ##v - d , took off on may , witnessed this flight from the visitors ' gallery . \" everyone will work to create their bit of sl ##v ; your problem is going to be your dependency on others in accomplish ##ing the total sl ##v . the primary objectives of the sl ##v project were design , development and operation of a standard sl ##v system , sl ##v - , capable of re ##lia ##bly and ex ##ped ##iti ##ously fulfilling the specified mission of launching a kg satellite into a km circular orbit around the earth . although sl ##v - was still in the future , its sub ##systems were being completed . within a month of the sl ##v - success , i visited the nehru science centre in bombay for a day , in response to an invitation to share my experiences with the sl ##v - . we had all come under the current of the sl ##v flow . it is very important to know the state of the sl ##v when it is in flight . between sl ##v - and now , we had developed a mutual affection . from my sl ##v - experience , i thought i knew the answer . back home at vs ##sc , sl ##v was taking shape . such spells increased steadily in frequency , and the sl ##v - dream was finally realised in the middle of we had scheduled the first experimental flight trial of sl ##v - for august . the sl ##v mission will be accomplished with , and through , a large number of people . some highlighted sl ##v - ' s possible military implications in terms of acquiring the capability for building ir ##bm ##s . some were a general pro ##gno ##sis of all that ai ##led our country and related it to the sl ##v - . the sl ##v - team developed their own internal success criteria . each member of the sl ##v - project team was a specialist in his own field . he told me that my progress on the sl ##v project would bring me sol ##ace . [SEP]\n",
            "I0930 06:59:02.440485 140552314279808 run_squad.py:436] tokens: [CLS] what is sl ##v ? [SEP] he drew the entire sl ##v team close and demonstrated to me that i was not alone in my sorrow at the sl ##v - ' s failure . i therefore take responsibility for the sl ##v - failure \" . now , before i dwell on the finer aspects of the management of the sl ##v - project , let me talk about the sl ##v - itself . i shared my sl ##v - experience with them . the next sl ##v - flight , sl ##v - d , took off on may , witnessed this flight from the visitors ' gallery . \" everyone will work to create their bit of sl ##v ; your problem is going to be your dependency on others in accomplish ##ing the total sl ##v . the primary objectives of the sl ##v project were design , development and operation of a standard sl ##v system , sl ##v - , capable of re ##lia ##bly and ex ##ped ##iti ##ously fulfilling the specified mission of launching a kg satellite into a km circular orbit around the earth . although sl ##v - was still in the future , its sub ##systems were being completed . within a month of the sl ##v - success , i visited the nehru science centre in bombay for a day , in response to an invitation to share my experiences with the sl ##v - . we had all come under the current of the sl ##v flow . it is very important to know the state of the sl ##v when it is in flight . between sl ##v - and now , we had developed a mutual affection . from my sl ##v - experience , i thought i knew the answer . back home at vs ##sc , sl ##v was taking shape . such spells increased steadily in frequency , and the sl ##v - dream was finally realised in the middle of we had scheduled the first experimental flight trial of sl ##v - for august . the sl ##v mission will be accomplished with , and through , a large number of people . some highlighted sl ##v - ' s possible military implications in terms of acquiring the capability for building ir ##bm ##s . some were a general pro ##gno ##sis of all that ai ##led our country and related it to the sl ##v - . the sl ##v - team developed their own internal success criteria . each member of the sl ##v - project team was a specialist in his own field . he told me that my progress on the sl ##v project would bring me sol ##ace . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:17 26:18 27:19 28:20 29:21 30:21 31:21 32:22 33:22 34:23 35:23 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:29 44:29 45:30 46:30 47:30 48:30 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:43 63:43 64:43 65:44 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:50 74:50 75:51 76:51 77:51 78:52 79:53 80:54 81:54 82:54 83:55 84:56 85:57 86:57 87:57 88:58 89:59 90:59 91:59 92:60 93:60 94:61 95:61 96:61 97:61 98:61 99:62 100:63 101:64 102:65 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:71 111:72 112:72 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:80 124:80 125:81 126:82 127:83 128:84 129:85 130:86 131:87 132:88 133:89 134:90 135:91 136:92 137:92 138:93 139:94 140:95 141:95 142:95 143:95 144:96 145:97 146:98 147:99 148:100 149:100 150:101 151:102 152:103 153:103 154:104 155:105 156:106 157:107 158:108 159:109 160:110 161:110 162:111 163:111 164:112 165:112 166:112 167:112 168:113 169:114 170:115 171:115 172:115 173:116 174:117 175:117 176:117 177:117 178:118 179:119 180:120 181:121 182:122 183:123 184:124 185:125 186:126 187:127 188:128 189:129 190:130 191:131 192:132 193:133 194:134 195:134 196:134 197:135 198:135 199:135 200:136 201:137 202:138 203:139 204:140 205:140 206:141 207:142 208:142 209:143 210:144 211:145 212:145 213:145 214:146 215:147 216:148 217:149 218:150 219:150 220:150 221:151 222:151 223:152 224:153 225:154 226:155 227:156 228:157 229:158 230:159 231:160 232:161 233:162 234:162 235:163 236:164 237:165 238:166 239:167 240:168 241:169 242:170 243:171 244:172 245:173 246:174 247:174 248:174 249:174 250:174 251:175 252:176 253:177 254:178 255:179 256:180 257:181 258:182 259:183 260:183 261:184 262:184 263:184 264:185 265:186 266:187 267:188 268:189 269:190 270:191 271:192 272:193 273:194 274:194 275:195 276:196 277:197 278:198 279:199 280:199 281:199 282:200 283:200 284:200 285:201 286:202 287:202 288:203 289:204 290:205 291:206 292:207 293:208 294:208 295:208 296:209 297:210 298:210 299:210 300:211 301:211 302:212 303:213 304:214 305:215 306:216 307:217 308:217 309:217 310:218 311:219 312:220 313:220 314:220 315:221 316:221 317:222 318:223 319:224 320:224 321:224 322:225 323:226 324:227 325:228 326:229 327:229 328:230 329:231 330:232 331:232 332:232 333:233 334:234 335:235 336:236 337:237 338:238 339:239 340:240 341:241 342:242 343:243 344:244 345:245 346:246 347:247 348:248 349:249 350:250 351:250 352:250 353:251 354:252 355:253 356:253 357:254 358:254 359:255 360:256 361:257 362:258 363:259 364:259 365:260 366:261 367:261 368:262 369:263 370:264 371:265 372:266 373:266 374:266 375:267 376:268 377:268 378:268 379:269 380:269 381:270 382:271 383:272 384:273 385:274 386:275 387:276 388:277 389:278 390:279 391:280 392:281 393:281 394:281 395:281 396:282 397:283 398:284 399:285 400:286 401:286 402:286 403:287 404:288 405:289 406:290 407:290 408:291 409:292 410:293 411:294 412:295 413:296 414:297 415:298 416:298 417:298 418:298 419:298 420:299 421:299 422:299 423:300 424:301 425:302 426:303 427:304 428:305 429:306 430:306 431:306 432:307 433:308 434:309 435:310 436:310 437:310 438:311 439:312 440:313 441:314 442:315 443:316 444:317 445:318 446:319 447:319 448:319 449:320 450:321 451:322 452:323 453:324 454:325 455:326 456:327 457:327 458:328 459:329 460:330 461:331 462:332 463:332 464:332\n",
            "I0930 06:59:02.440716 140552314279808 run_squad.py:438] token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:17 26:18 27:19 28:20 29:21 30:21 31:21 32:22 33:22 34:23 35:23 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:29 44:29 45:30 46:30 47:30 48:30 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:43 63:43 64:43 65:44 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:50 74:50 75:51 76:51 77:51 78:52 79:53 80:54 81:54 82:54 83:55 84:56 85:57 86:57 87:57 88:58 89:59 90:59 91:59 92:60 93:60 94:61 95:61 96:61 97:61 98:61 99:62 100:63 101:64 102:65 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:71 111:72 112:72 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:80 124:80 125:81 126:82 127:83 128:84 129:85 130:86 131:87 132:88 133:89 134:90 135:91 136:92 137:92 138:93 139:94 140:95 141:95 142:95 143:95 144:96 145:97 146:98 147:99 148:100 149:100 150:101 151:102 152:103 153:103 154:104 155:105 156:106 157:107 158:108 159:109 160:110 161:110 162:111 163:111 164:112 165:112 166:112 167:112 168:113 169:114 170:115 171:115 172:115 173:116 174:117 175:117 176:117 177:117 178:118 179:119 180:120 181:121 182:122 183:123 184:124 185:125 186:126 187:127 188:128 189:129 190:130 191:131 192:132 193:133 194:134 195:134 196:134 197:135 198:135 199:135 200:136 201:137 202:138 203:139 204:140 205:140 206:141 207:142 208:142 209:143 210:144 211:145 212:145 213:145 214:146 215:147 216:148 217:149 218:150 219:150 220:150 221:151 222:151 223:152 224:153 225:154 226:155 227:156 228:157 229:158 230:159 231:160 232:161 233:162 234:162 235:163 236:164 237:165 238:166 239:167 240:168 241:169 242:170 243:171 244:172 245:173 246:174 247:174 248:174 249:174 250:174 251:175 252:176 253:177 254:178 255:179 256:180 257:181 258:182 259:183 260:183 261:184 262:184 263:184 264:185 265:186 266:187 267:188 268:189 269:190 270:191 271:192 272:193 273:194 274:194 275:195 276:196 277:197 278:198 279:199 280:199 281:199 282:200 283:200 284:200 285:201 286:202 287:202 288:203 289:204 290:205 291:206 292:207 293:208 294:208 295:208 296:209 297:210 298:210 299:210 300:211 301:211 302:212 303:213 304:214 305:215 306:216 307:217 308:217 309:217 310:218 311:219 312:220 313:220 314:220 315:221 316:221 317:222 318:223 319:224 320:224 321:224 322:225 323:226 324:227 325:228 326:229 327:229 328:230 329:231 330:232 331:232 332:232 333:233 334:234 335:235 336:236 337:237 338:238 339:239 340:240 341:241 342:242 343:243 344:244 345:245 346:246 347:247 348:248 349:249 350:250 351:250 352:250 353:251 354:252 355:253 356:253 357:254 358:254 359:255 360:256 361:257 362:258 363:259 364:259 365:260 366:261 367:261 368:262 369:263 370:264 371:265 372:266 373:266 374:266 375:267 376:268 377:268 378:268 379:269 380:269 381:270 382:271 383:272 384:273 385:274 386:275 387:276 388:277 389:278 390:279 391:280 392:281 393:281 394:281 395:281 396:282 397:283 398:284 399:285 400:286 401:286 402:286 403:287 404:288 405:289 406:290 407:290 408:291 409:292 410:293 411:294 412:295 413:296 414:297 415:298 416:298 417:298 418:298 419:298 420:299 421:299 422:299 423:300 424:301 425:302 426:303 427:304 428:305 429:306 430:306 431:306 432:307 433:308 434:309 435:310 436:310 437:310 438:311 439:312 440:313 441:314 442:315 443:316 444:317 445:318 446:319 447:319 448:319 449:320 450:321 451:322 452:323 453:324 454:325 455:326 456:327 457:327 458:328 459:329 460:330 461:331 462:332 463:332 464:332\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True\n",
            "I0930 06:59:02.440959 140552314279808 run_squad.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 22889 2615 1029 102 2002 3881 1996 2972 22889 2615 2136 2485 1998 7645 2000 2033 2008 1045 2001 2025 2894 1999 2026 14038 2012 1996 22889 2615 1011 1005 1055 4945 1012 1045 3568 2202 5368 2005 1996 22889 2615 1011 4945 1000 1012 2085 1010 2077 1045 23120 2006 1996 26954 5919 1997 1996 2968 1997 1996 22889 2615 1011 2622 1010 2292 2033 2831 2055 1996 22889 2615 1011 2993 1012 1045 4207 2026 22889 2615 1011 3325 2007 2068 1012 1996 2279 22889 2615 1011 3462 1010 22889 2615 1011 1040 1010 2165 2125 2006 2089 1010 9741 2023 3462 2013 1996 5731 1005 3916 1012 1000 3071 2097 2147 2000 3443 2037 2978 1997 22889 2615 1025 2115 3291 2003 2183 2000 2022 2115 24394 2006 2500 1999 14570 2075 1996 2561 22889 2615 1012 1996 3078 11100 1997 1996 22889 2615 2622 2020 2640 1010 2458 1998 3169 1997 1037 3115 22889 2615 2291 1010 22889 2615 1011 1010 5214 1997 2128 6632 6321 1998 4654 5669 25090 13453 21570 1996 9675 3260 1997 12106 1037 4705 5871 2046 1037 2463 8206 8753 2105 1996 3011 1012 2348 22889 2615 1011 2001 2145 1999 1996 2925 1010 2049 4942 29390 2020 2108 2949 1012 2306 1037 3204 1997 1996 22889 2615 1011 3112 1010 1045 4716 1996 23556 2671 2803 1999 11831 2005 1037 2154 1010 1999 3433 2000 2019 8468 2000 3745 2026 6322 2007 1996 22889 2615 1011 1012 2057 2018 2035 2272 2104 1996 2783 1997 1996 22889 2615 4834 1012 2009 2003 2200 2590 2000 2113 1996 2110 1997 1996 22889 2615 2043 2009 2003 1999 3462 1012 2090 22889 2615 1011 1998 2085 1010 2057 2018 2764 1037 8203 12242 1012 2013 2026 22889 2615 1011 3325 1010 1045 2245 1045 2354 1996 3437 1012 2067 2188 2012 5443 11020 1010 22889 2615 2001 2635 4338 1012 2107 11750 3445 11328 1999 6075 1010 1998 1996 22889 2615 1011 3959 2001 2633 11323 1999 1996 2690 1997 2057 2018 5115 1996 2034 6388 3462 3979 1997 22889 2615 1011 2005 2257 1012 1996 22889 2615 3260 2097 2022 8885 2007 1010 1998 2083 1010 1037 2312 2193 1997 2111 1012 2070 11548 22889 2615 1011 1005 1055 2825 2510 13494 1999 3408 1997 13868 1996 10673 2005 2311 20868 25526 2015 1012 2070 2020 1037 2236 4013 26745 6190 1997 2035 2008 9932 3709 2256 2406 1998 3141 2009 2000 1996 22889 2615 1011 1012 1996 22889 2615 1011 2136 2764 2037 2219 4722 3112 9181 1012 2169 2266 1997 1996 22889 2615 1011 2622 2136 2001 1037 8325 1999 2010 2219 2492 1012 2002 2409 2033 2008 2026 5082 2006 1996 22889 2615 2622 2052 3288 2033 14017 10732 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.538364 140552314279808 run_squad.py:442] input_ids: 101 2054 2003 22889 2615 1029 102 2002 3881 1996 2972 22889 2615 2136 2485 1998 7645 2000 2033 2008 1045 2001 2025 2894 1999 2026 14038 2012 1996 22889 2615 1011 1005 1055 4945 1012 1045 3568 2202 5368 2005 1996 22889 2615 1011 4945 1000 1012 2085 1010 2077 1045 23120 2006 1996 26954 5919 1997 1996 2968 1997 1996 22889 2615 1011 2622 1010 2292 2033 2831 2055 1996 22889 2615 1011 2993 1012 1045 4207 2026 22889 2615 1011 3325 2007 2068 1012 1996 2279 22889 2615 1011 3462 1010 22889 2615 1011 1040 1010 2165 2125 2006 2089 1010 9741 2023 3462 2013 1996 5731 1005 3916 1012 1000 3071 2097 2147 2000 3443 2037 2978 1997 22889 2615 1025 2115 3291 2003 2183 2000 2022 2115 24394 2006 2500 1999 14570 2075 1996 2561 22889 2615 1012 1996 3078 11100 1997 1996 22889 2615 2622 2020 2640 1010 2458 1998 3169 1997 1037 3115 22889 2615 2291 1010 22889 2615 1011 1010 5214 1997 2128 6632 6321 1998 4654 5669 25090 13453 21570 1996 9675 3260 1997 12106 1037 4705 5871 2046 1037 2463 8206 8753 2105 1996 3011 1012 2348 22889 2615 1011 2001 2145 1999 1996 2925 1010 2049 4942 29390 2020 2108 2949 1012 2306 1037 3204 1997 1996 22889 2615 1011 3112 1010 1045 4716 1996 23556 2671 2803 1999 11831 2005 1037 2154 1010 1999 3433 2000 2019 8468 2000 3745 2026 6322 2007 1996 22889 2615 1011 1012 2057 2018 2035 2272 2104 1996 2783 1997 1996 22889 2615 4834 1012 2009 2003 2200 2590 2000 2113 1996 2110 1997 1996 22889 2615 2043 2009 2003 1999 3462 1012 2090 22889 2615 1011 1998 2085 1010 2057 2018 2764 1037 8203 12242 1012 2013 2026 22889 2615 1011 3325 1010 1045 2245 1045 2354 1996 3437 1012 2067 2188 2012 5443 11020 1010 22889 2615 2001 2635 4338 1012 2107 11750 3445 11328 1999 6075 1010 1998 1996 22889 2615 1011 3959 2001 2633 11323 1999 1996 2690 1997 2057 2018 5115 1996 2034 6388 3462 3979 1997 22889 2615 1011 2005 2257 1012 1996 22889 2615 3260 2097 2022 8885 2007 1010 1998 2083 1010 1037 2312 2193 1997 2111 1012 2070 11548 22889 2615 1011 1005 1055 2825 2510 13494 1999 3408 1997 13868 1996 10673 2005 2311 20868 25526 2015 1012 2070 2020 1037 2236 4013 26745 6190 1997 2035 2008 9932 3709 2256 2406 1998 3141 2009 2000 1996 22889 2615 1011 1012 1996 22889 2615 1011 2136 2764 2037 2219 4722 3112 9181 1012 2169 2266 1997 1996 22889 2615 1011 2622 2136 2001 1037 8325 1999 2010 2219 2492 1012 2002 2409 2033 2008 2026 5082 2006 1996 22889 2615 2622 2052 3288 2033 14017 10732 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.538933 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.539305 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.544448 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000001\n",
            "I0930 06:59:02.544678 140552314279808 run_squad.py:432] unique_id: 1000000001\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0930 06:59:02.544790 140552314279808 run_squad.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.544878 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who is your sister ? [SEP] my sister , z ##oh ##ara , prepared special sweets for me . at that time , my sister , z ##oh ##ara , stood behind me , mort ##ga ##ging her gold bang ##les and chain . z ##oh ##ara , my sister , mort ##ga ##ging her gold bang ##les and chains to get me into engineering college ? he worked at building the boat on the seas ##hore , with the help of a relative , ahmed ja ##lla ##lu ##ddin , who later married my sister , z ##oh ##ara . i inherited honesty and self - discipline from my father ; from my mother , i inherited faith in goodness and deep kindness and so did my three brothers and sister . my father , by now more than a hundred years old , pal ##l - bearer for his son - in - law , who had been half his age ; the be ##re ##ft soul of my sister z ##oh ##ara , her wounds from the loss of her four - year - old son still raw — these images came before my eyes in a blur , too terrible for me to comprehend . [SEP]\n",
            "I0930 06:59:02.545039 140552314279808 run_squad.py:436] tokens: [CLS] who is your sister ? [SEP] my sister , z ##oh ##ara , prepared special sweets for me . at that time , my sister , z ##oh ##ara , stood behind me , mort ##ga ##ging her gold bang ##les and chain . z ##oh ##ara , my sister , mort ##ga ##ging her gold bang ##les and chains to get me into engineering college ? he worked at building the boat on the seas ##hore , with the help of a relative , ahmed ja ##lla ##lu ##ddin , who later married my sister , z ##oh ##ara . i inherited honesty and self - discipline from my father ; from my mother , i inherited faith in goodness and deep kindness and so did my three brothers and sister . my father , by now more than a hundred years old , pal ##l - bearer for his son - in - law , who had been half his age ; the be ##re ##ft soul of my sister z ##oh ##ara , her wounds from the loss of her four - year - old son still raw — these images came before my eyes in a blur , too terrible for me to comprehend . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:1 10:2 11:2 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:7 20:7 21:8 22:9 23:9 24:10 25:11 26:11 27:12 28:12 29:12 30:12 31:13 32:14 33:15 34:15 35:16 36:16 37:16 38:17 39:18 40:19 41:19 42:20 43:21 44:21 45:21 46:21 47:21 48:21 49:22 50:23 51:23 52:24 53:24 54:24 55:25 56:26 57:27 58:27 59:28 60:29 61:30 62:31 63:32 64:33 65:34 66:35 67:35 68:35 69:36 70:37 71:38 72:39 73:40 74:41 75:42 76:43 77:43 78:43 79:44 80:45 81:46 82:47 83:48 84:49 85:49 86:50 87:51 88:51 89:51 90:51 91:51 92:52 93:53 94:54 95:55 96:56 97:56 98:57 99:57 100:57 101:57 102:57 103:58 104:59 105:60 106:61 107:61 108:61 109:62 110:63 111:64 112:64 113:65 114:66 115:67 116:67 117:68 118:69 119:70 120:71 121:72 122:73 123:74 124:75 125:76 126:77 127:78 128:79 129:80 130:81 131:82 132:83 133:83 134:83 135:84 136:84 137:85 138:86 139:87 140:88 141:89 142:90 143:91 144:92 145:92 146:93 147:93 148:93 149:94 150:95 151:96 152:97 153:97 154:97 155:97 156:97 157:97 158:98 159:99 160:100 161:101 162:102 163:103 164:103 165:104 166:105 167:105 168:105 169:106 170:107 171:108 172:109 173:110 174:110 175:110 176:110 177:111 178:112 179:113 180:114 181:115 182:116 183:117 184:118 185:118 186:118 187:118 188:118 189:119 190:120 191:121 192:122 193:123 194:124 195:125 196:126 197:127 198:128 199:129 200:130 201:131 202:131 203:132 204:133 205:134 206:135 207:136 208:137 209:137\n",
            "I0930 06:59:02.545228 140552314279808 run_squad.py:438] token_to_orig_map: 7:0 8:1 9:1 10:2 11:2 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:7 20:7 21:8 22:9 23:9 24:10 25:11 26:11 27:12 28:12 29:12 30:12 31:13 32:14 33:15 34:15 35:16 36:16 37:16 38:17 39:18 40:19 41:19 42:20 43:21 44:21 45:21 46:21 47:21 48:21 49:22 50:23 51:23 52:24 53:24 54:24 55:25 56:26 57:27 58:27 59:28 60:29 61:30 62:31 63:32 64:33 65:34 66:35 67:35 68:35 69:36 70:37 71:38 72:39 73:40 74:41 75:42 76:43 77:43 78:43 79:44 80:45 81:46 82:47 83:48 84:49 85:49 86:50 87:51 88:51 89:51 90:51 91:51 92:52 93:53 94:54 95:55 96:56 97:56 98:57 99:57 100:57 101:57 102:57 103:58 104:59 105:60 106:61 107:61 108:61 109:62 110:63 111:64 112:64 113:65 114:66 115:67 116:67 117:68 118:69 119:70 120:71 121:72 122:73 123:74 124:75 125:76 126:77 127:78 128:79 129:80 130:81 131:82 132:83 133:83 134:83 135:84 136:84 137:85 138:86 139:87 140:88 141:89 142:90 143:91 144:92 145:92 146:93 147:93 148:93 149:94 150:95 151:96 152:97 153:97 154:97 155:97 156:97 157:97 158:98 159:99 160:100 161:101 162:102 163:103 164:103 165:104 166:105 167:105 168:105 169:106 170:107 171:108 172:109 173:110 174:110 175:110 176:110 177:111 178:112 179:113 180:114 181:115 182:116 183:117 184:118 185:118 186:118 187:118 188:118 189:119 190:120 191:121 192:122 193:123 194:124 195:125 196:126 197:127 198:128 199:129 200:130 201:131 202:131 203:132 204:133 205:134 206:135 207:136 208:137 209:137\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True\n",
            "I0930 06:59:02.545421 140552314279808 run_squad.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 2115 2905 1029 102 2026 2905 1010 1062 11631 5400 1010 4810 2569 26844 2005 2033 1012 2012 2008 2051 1010 2026 2905 1010 1062 11631 5400 1010 2768 2369 2033 1010 22294 3654 4726 2014 2751 9748 4244 1998 4677 1012 1062 11631 5400 1010 2026 2905 1010 22294 3654 4726 2014 2751 9748 4244 1998 8859 2000 2131 2033 2046 3330 2267 1029 2002 2499 2012 2311 1996 4049 2006 1996 11915 16892 1010 2007 1996 2393 1997 1037 5816 1010 10208 14855 4571 7630 18277 1010 2040 2101 2496 2026 2905 1010 1062 11631 5400 1012 1045 7900 16718 1998 2969 1011 9009 2013 2026 2269 1025 2013 2026 2388 1010 1045 7900 4752 1999 15003 1998 2784 16056 1998 2061 2106 2026 2093 3428 1998 2905 1012 2026 2269 1010 2011 2085 2062 2084 1037 3634 2086 2214 1010 14412 2140 1011 20905 2005 2010 2365 1011 1999 1011 2375 1010 2040 2018 2042 2431 2010 2287 1025 1996 2022 2890 6199 3969 1997 2026 2905 1062 11631 5400 1010 2014 8710 2013 1996 3279 1997 2014 2176 1011 2095 1011 2214 2365 2145 6315 1517 2122 4871 2234 2077 2026 2159 1999 1037 14819 1010 2205 6659 2005 2033 2000 22346 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.545656 140552314279808 run_squad.py:442] input_ids: 101 2040 2003 2115 2905 1029 102 2026 2905 1010 1062 11631 5400 1010 4810 2569 26844 2005 2033 1012 2012 2008 2051 1010 2026 2905 1010 1062 11631 5400 1010 2768 2369 2033 1010 22294 3654 4726 2014 2751 9748 4244 1998 4677 1012 1062 11631 5400 1010 2026 2905 1010 22294 3654 4726 2014 2751 9748 4244 1998 8859 2000 2131 2033 2046 3330 2267 1029 2002 2499 2012 2311 1996 4049 2006 1996 11915 16892 1010 2007 1996 2393 1997 1037 5816 1010 10208 14855 4571 7630 18277 1010 2040 2101 2496 2026 2905 1010 1062 11631 5400 1012 1045 7900 16718 1998 2969 1011 9009 2013 2026 2269 1025 2013 2026 2388 1010 1045 7900 4752 1999 15003 1998 2784 16056 1998 2061 2106 2026 2093 3428 1998 2905 1012 2026 2269 1010 2011 2085 2062 2084 1037 3634 2086 2214 1010 14412 2140 1011 20905 2005 2010 2365 1011 1999 1011 2375 1010 2040 2018 2042 2431 2010 2287 1025 1996 2022 2890 6199 3969 1997 2026 2905 1062 11631 5400 1010 2014 8710 2013 1996 3279 1997 2014 2176 1011 2095 1011 2214 2365 2145 6315 1517 2122 4871 2234 2077 2026 2159 1999 1037 14819 1010 2205 6659 2005 2033 2000 22346 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.545873 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.546077 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.548601 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000002\n",
            "I0930 06:59:02.548822 140552314279808 run_squad.py:432] unique_id: 1000000002\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0930 06:59:02.548920 140552314279808 run_squad.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.549003 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] where is pentagon ? [SEP] after finishing our work at the pentagon in washington , we landed in san francisco on our way to los angeles to visit north ##rop corporation . [SEP]\n",
            "I0930 06:59:02.549106 140552314279808 run_squad.py:436] tokens: [CLS] where is pentagon ? [SEP] after finishing our work at the pentagon in washington , we landed in san francisco on our way to los angeles to visit north ##rop corporation . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:6 13:7 14:8 15:8 16:9 17:10 18:11 19:12 20:13 21:14 22:15 23:16 24:17 25:18 26:19 27:20 28:21 29:22 30:22 31:23 32:23\n",
            "I0930 06:59:02.549212 140552314279808 run_squad.py:438] token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:6 13:7 14:8 15:8 16:9 17:10 18:11 19:12 20:13 21:14 22:15 23:16 24:17 25:18 26:19 27:20 28:21 29:22 30:22 31:23 32:23\n",
            "INFO:tensorflow:token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True\n",
            "I0930 06:59:02.645129 140552314279808 run_squad.py:440] token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True\n",
            "INFO:tensorflow:input_ids: 101 2073 2003 20864 1029 102 2044 5131 2256 2147 2012 1996 20864 1999 2899 1010 2057 5565 1999 2624 3799 2006 2256 2126 2000 3050 3349 2000 3942 2167 18981 3840 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.646009 140552314279808 run_squad.py:442] input_ids: 101 2073 2003 20864 1029 102 2044 5131 2256 2147 2012 1996 20864 1999 2899 1010 2057 5565 1999 2624 3799 2006 2256 2126 2000 3050 3349 2000 3942 2167 18981 3840 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.646699 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.647397 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.657637 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000003\n",
            "I0930 06:59:02.657844 140552314279808 run_squad.py:432] unique_id: 1000000003\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0930 06:59:02.657912 140552314279808 run_squad.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.657968 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] where did tri ##shu ##l take off from ? [SEP] but he did . how did i do that ? but we did it at last ! what was it that i did not have ? but what did you do for the project \" ? i did not find rev . what did i want ? how did it happen ? i did well at the interview . \" why did you not pro ##stra ##te yourself \" ? with the completion of developmental trials on pri ##th ##vi and tri ##shu ##l , our choice was on test now . somehow , i did not take to the new setting . the first launch of the missile programme was conducted on september , when tri ##shu ##l took off from the test range at sri ##hari ##kota ( sha ##r ) . rear admiral mohan retired and his deputy , kapoor , was to take over tri ##shu ##l . he did not take long to come to the point . yet , he never pretended to know more than he did . or did we have divine protection ? the new aircraft did not need rat ##o . the successful test firing of pri ##th ##vi and tri ##shu ##l during the course of the gulf war was enough to make an anxious nation relax . it did not happen immediately , but it happened nevertheless . [SEP]\n",
            "I0930 06:59:02.658089 140552314279808 run_squad.py:436] tokens: [CLS] where did tri ##shu ##l take off from ? [SEP] but he did . how did i do that ? but we did it at last ! what was it that i did not have ? but what did you do for the project \" ? i did not find rev . what did i want ? how did it happen ? i did well at the interview . \" why did you not pro ##stra ##te yourself \" ? with the completion of developmental trials on pri ##th ##vi and tri ##shu ##l , our choice was on test now . somehow , i did not take to the new setting . the first launch of the missile programme was conducted on september , when tri ##shu ##l took off from the test range at sri ##hari ##kota ( sha ##r ) . rear admiral mohan retired and his deputy , kapoor , was to take over tri ##shu ##l . he did not take long to come to the point . yet , he never pretended to know more than he did . or did we have divine protection ? the new aircraft did not need rat ##o . the successful test firing of pri ##th ##vi and tri ##shu ##l during the course of the gulf war was enough to make an anxious nation relax . it did not happen immediately , but it happened nevertheless . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:2 15:2 16:3 17:4 18:5 19:6 20:7 21:7 22:8 23:9 24:10 25:11 26:12 27:12 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:19 37:19 38:20 39:21 40:22 41:23 42:24 43:25 44:26 45:26 46:26 47:26 48:27 49:28 50:29 51:30 52:30 53:30 54:31 55:32 56:33 57:33 58:33 59:34 60:35 61:36 62:36 63:36 64:37 65:38 66:39 67:40 68:41 69:41 70:41 71:41 72:42 73:43 74:44 75:45 76:45 77:45 78:46 79:46 80:46 81:46 82:47 83:48 84:49 85:50 86:51 87:52 88:53 89:53 90:53 91:54 92:55 93:55 94:55 95:55 96:56 97:57 98:58 99:59 100:60 101:61 102:61 103:61 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:68 112:69 113:69 114:69 115:70 116:71 117:72 118:73 119:74 120:75 121:76 122:77 123:78 124:79 125:80 126:81 127:82 128:82 129:82 130:83 131:84 132:85 133:86 134:87 135:88 136:89 137:90 138:90 139:90 140:91 141:91 142:91 143:91 144:91 145:91 146:92 147:93 148:94 149:95 150:96 151:97 152:97 153:98 154:98 155:99 156:100 157:101 158:102 159:103 160:103 161:103 162:103 163:103 164:104 165:105 166:106 167:107 168:108 169:109 170:110 171:111 172:112 173:112 174:112 175:112 176:113 177:114 178:115 179:116 180:117 181:118 182:119 183:120 184:121 185:121 186:121 187:122 188:123 189:124 190:125 191:126 192:126 193:126 194:127 195:128 196:129 197:130 198:131 199:132 200:132 201:132 202:132 203:133 204:134 205:135 206:136 207:137 208:137 209:137 210:138 211:139 212:139 213:139 214:140 215:141 216:142 217:143 218:144 219:145 220:146 221:147 222:148 223:149 224:150 225:151 226:152 227:153 228:154 229:154 230:154 231:155 232:156 233:157 234:158 235:158 236:159 237:160 238:161 239:162 240:162\n",
            "I0930 06:59:02.658219 140552314279808 run_squad.py:438] token_to_orig_map: 11:0 12:1 13:2 14:2 15:2 16:3 17:4 18:5 19:6 20:7 21:7 22:8 23:9 24:10 25:11 26:12 27:12 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:19 37:19 38:20 39:21 40:22 41:23 42:24 43:25 44:26 45:26 46:26 47:26 48:27 49:28 50:29 51:30 52:30 53:30 54:31 55:32 56:33 57:33 58:33 59:34 60:35 61:36 62:36 63:36 64:37 65:38 66:39 67:40 68:41 69:41 70:41 71:41 72:42 73:43 74:44 75:45 76:45 77:45 78:46 79:46 80:46 81:46 82:47 83:48 84:49 85:50 86:51 87:52 88:53 89:53 90:53 91:54 92:55 93:55 94:55 95:55 96:56 97:57 98:58 99:59 100:60 101:61 102:61 103:61 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:68 112:69 113:69 114:69 115:70 116:71 117:72 118:73 119:74 120:75 121:76 122:77 123:78 124:79 125:80 126:81 127:82 128:82 129:82 130:83 131:84 132:85 133:86 134:87 135:88 136:89 137:90 138:90 139:90 140:91 141:91 142:91 143:91 144:91 145:91 146:92 147:93 148:94 149:95 150:96 151:97 152:97 153:98 154:98 155:99 156:100 157:101 158:102 159:103 160:103 161:103 162:103 163:103 164:104 165:105 166:106 167:107 168:108 169:109 170:110 171:111 172:112 173:112 174:112 175:112 176:113 177:114 178:115 179:116 180:117 181:118 182:119 183:120 184:121 185:121 186:121 187:122 188:123 189:124 190:125 191:126 192:126 193:126 194:127 195:128 196:129 197:130 198:131 199:132 200:132 201:132 202:132 203:133 204:134 205:135 206:136 207:137 208:137 209:137 210:138 211:139 212:139 213:139 214:140 215:141 216:142 217:143 218:144 219:145 220:146 221:147 222:148 223:149 224:150 225:151 226:152 227:153 228:154 229:154 230:154 231:155 232:156 233:157 234:158 235:158 236:159 237:160 238:161 239:162 240:162\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True\n",
            "I0930 06:59:02.658383 140552314279808 run_squad.py:440] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True\n",
            "INFO:tensorflow:input_ids: 101 2073 2106 13012 14235 2140 2202 2125 2013 1029 102 2021 2002 2106 1012 2129 2106 1045 2079 2008 1029 2021 2057 2106 2009 2012 2197 999 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 2129 2106 2009 4148 1029 1045 2106 2092 2012 1996 4357 1012 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 2007 1996 6503 1997 13908 7012 2006 26927 2705 5737 1998 13012 14235 2140 1010 2256 3601 2001 2006 3231 2085 1012 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 1996 2034 4888 1997 1996 7421 4746 2001 4146 2006 2244 1010 2043 13012 14235 2140 2165 2125 2013 1996 3231 2846 2012 5185 18428 27380 1006 21146 2099 1007 1012 4373 5902 18529 3394 1998 2010 4112 1010 17129 1010 2001 2000 2202 2058 13012 14235 2140 1012 2002 2106 2025 2202 2146 2000 2272 2000 1996 2391 1012 2664 1010 2002 2196 14688 2000 2113 2062 2084 2002 2106 1012 2030 2106 2057 2031 7746 3860 1029 1996 2047 2948 2106 2025 2342 9350 2080 1012 1996 3144 3231 7493 1997 26927 2705 5737 1998 13012 14235 2140 2076 1996 2607 1997 1996 6084 2162 2001 2438 2000 2191 2019 11480 3842 9483 1012 2009 2106 2025 4148 3202 1010 2021 2009 3047 6600 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.745995 140552314279808 run_squad.py:442] input_ids: 101 2073 2106 13012 14235 2140 2202 2125 2013 1029 102 2021 2002 2106 1012 2129 2106 1045 2079 2008 1029 2021 2057 2106 2009 2012 2197 999 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 2129 2106 2009 4148 1029 1045 2106 2092 2012 1996 4357 1012 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 2007 1996 6503 1997 13908 7012 2006 26927 2705 5737 1998 13012 14235 2140 1010 2256 3601 2001 2006 3231 2085 1012 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 1996 2034 4888 1997 1996 7421 4746 2001 4146 2006 2244 1010 2043 13012 14235 2140 2165 2125 2013 1996 3231 2846 2012 5185 18428 27380 1006 21146 2099 1007 1012 4373 5902 18529 3394 1998 2010 4112 1010 17129 1010 2001 2000 2202 2058 13012 14235 2140 1012 2002 2106 2025 2202 2146 2000 2272 2000 1996 2391 1012 2664 1010 2002 2196 14688 2000 2113 2062 2084 2002 2106 1012 2030 2106 2057 2031 7746 3860 1029 1996 2047 2948 2106 2025 2342 9350 2080 1012 1996 3144 3231 7493 1997 26927 2705 5737 1998 13012 14235 2140 2076 1996 2607 1997 1996 6084 2162 2001 2438 2000 2191 2019 11480 3842 9483 1012 2009 2106 2025 4148 3202 1010 2021 2009 3047 6600 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.746484 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.746825 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.757812 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000004\n",
            "I0930 06:59:02.758062 140552314279808 run_squad.py:432] unique_id: 1000000004\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0930 06:59:02.758163 140552314279808 run_squad.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.758265 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is pri ##th ##vi ? [SEP] would a pri ##th ##vi su ##ffi ##ce ? \" when are you going to flight test pri ##th ##vi \" ? pri ##th ##vi was launched at : hr ##s on february . pri ##th ##vi had been designed as an in ##ert ##ial ##ly guided missile . work on pri ##th ##vi was nearing completion when we entered . the second flight of pri ##th ##vi at the end of september was again a great success . working with ku ##rup on the pri ##th ##vi launch campaign gave me great satisfaction . with the completion of developmental trials on pri ##th ##vi and tri ##shu ##l , our choice was on test now . later pri ##th ##vi and then ag ##ni used similar guidance systems , with excellent results . the importance of these rocket engines was not restricted to the pri ##th ##vi project — it was a national achievement . as i saw it , the development of pri ##th ##vi represented the self - reliance of our country in the field of advanced technology . pri ##th ##vi has proved to be the best surface - to - surface missile in the world today . the launch of pri ##th ##vi sent shock waves across the un ##fr ##ien ##dly neighbouring countries . since the interim test range at bala ##sor ##e was still at least a year away from completion , we had set up special facilities at sha ##r for the launch of pri ##th ##vi . the successful test firing of pri ##th ##vi and tri ##shu ##l during the course of the gulf war was enough to make an anxious nation relax . a common query i encountered was whether pri ##th ##vi was superior to a sc ##ud , whether aka ##sh could perform like a patriot , and so on . ku ##rup worked for pri ##th ##vi as a team member , ignoring the boundary lines that divide dr ##do and is ##ro , dr ##dl and sha ##r . thus the surface - to - surface weapon system became pri ##th ##vi ( \" the earth \" ) and the tactical core vehicle was called tri ##shu ##l ( the trident of lord shiva ) . it is boosted by a first - stage solid rocket motor derived from sl ##v - and further accelerated at the second stage with the liquid rocket engines of pri ##th ##vi . my search for someone to lead the pri ##th ##vi project ended with col v ##j sun ##dara ##m who belonged to the em ##e corps of the indian army . [SEP]\n",
            "I0930 06:59:02.758532 140552314279808 run_squad.py:436] tokens: [CLS] what is pri ##th ##vi ? [SEP] would a pri ##th ##vi su ##ffi ##ce ? \" when are you going to flight test pri ##th ##vi \" ? pri ##th ##vi was launched at : hr ##s on february . pri ##th ##vi had been designed as an in ##ert ##ial ##ly guided missile . work on pri ##th ##vi was nearing completion when we entered . the second flight of pri ##th ##vi at the end of september was again a great success . working with ku ##rup on the pri ##th ##vi launch campaign gave me great satisfaction . with the completion of developmental trials on pri ##th ##vi and tri ##shu ##l , our choice was on test now . later pri ##th ##vi and then ag ##ni used similar guidance systems , with excellent results . the importance of these rocket engines was not restricted to the pri ##th ##vi project — it was a national achievement . as i saw it , the development of pri ##th ##vi represented the self - reliance of our country in the field of advanced technology . pri ##th ##vi has proved to be the best surface - to - surface missile in the world today . the launch of pri ##th ##vi sent shock waves across the un ##fr ##ien ##dly neighbouring countries . since the interim test range at bala ##sor ##e was still at least a year away from completion , we had set up special facilities at sha ##r for the launch of pri ##th ##vi . the successful test firing of pri ##th ##vi and tri ##shu ##l during the course of the gulf war was enough to make an anxious nation relax . a common query i encountered was whether pri ##th ##vi was superior to a sc ##ud , whether aka ##sh could perform like a patriot , and so on . ku ##rup worked for pri ##th ##vi as a team member , ignoring the boundary lines that divide dr ##do and is ##ro , dr ##dl and sha ##r . thus the surface - to - surface weapon system became pri ##th ##vi ( \" the earth \" ) and the tactical core vehicle was called tri ##shu ##l ( the trident of lord shiva ) . it is boosted by a first - stage solid rocket motor derived from sl ##v - and further accelerated at the second stage with the liquid rocket engines of pri ##th ##vi . my search for someone to lead the pri ##th ##vi project ended with col v ##j sun ##dara ##m who belonged to the em ##e corps of the indian army . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:3 14:3 15:3 16:3 17:3 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:10 26:10 27:10 28:10 29:10 30:10 31:10 32:10 33:11 34:12 35:13 36:14 37:15 38:15 39:16 40:17 41:18 42:18 43:18 44:18 45:19 46:20 47:21 48:22 49:23 50:24 51:24 52:24 53:24 54:25 55:26 56:26 57:26 58:27 59:28 60:28 61:28 62:29 63:30 64:31 65:32 66:33 67:34 68:35 69:35 70:36 71:37 72:38 73:39 74:39 75:39 76:40 77:41 78:42 79:43 80:44 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:50 89:51 90:51 91:52 92:53 93:54 94:54 95:54 96:55 97:56 98:57 99:58 100:59 101:60 102:60 103:60 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:67 112:67 113:68 114:69 115:69 116:69 117:69 118:70 119:71 120:72 121:73 122:74 123:75 124:75 125:75 126:76 127:76 128:76 129:77 130:78 131:79 132:79 133:80 134:81 135:82 136:83 137:83 138:84 139:85 140:86 141:86 142:86 143:87 144:88 145:89 146:90 147:91 148:92 149:93 150:94 151:95 152:96 153:97 154:97 155:97 156:98 157:99 158:100 159:101 160:102 161:103 162:104 163:104 164:104 165:105 166:106 167:107 168:107 169:108 170:109 171:110 172:111 173:111 174:111 175:112 176:113 177:114 178:114 179:114 180:115 181:116 182:117 183:118 184:119 185:120 186:121 187:122 188:123 189:123 190:123 191:123 192:123 193:124 194:125 195:126 196:127 197:128 198:129 199:130 200:130 201:130 202:130 203:130 204:131 205:132 206:133 207:134 208:135 209:135 210:135 211:136 212:137 213:138 214:138 215:138 216:139 217:140 218:141 219:142 220:143 221:144 222:144 223:144 224:144 225:145 226:146 227:146 228:146 229:147 230:148 231:149 232:150 233:151 234:152 235:152 236:152 237:153 238:154 239:155 240:156 241:157 242:158 243:159 244:160 245:161 246:161 247:162 248:163 249:164 250:165 251:166 252:167 253:168 254:169 255:169 256:170 257:171 258:172 259:173 260:174 261:174 262:174 263:174 264:174 265:175 266:176 267:177 268:178 269:179 270:179 271:179 272:180 273:181 274:181 275:181 276:182 277:183 278:184 279:185 280:186 281:187 282:188 283:189 284:190 285:191 286:192 287:193 288:194 289:195 290:196 291:196 292:196 293:197 294:198 295:199 296:200 297:201 298:202 299:203 300:203 301:203 302:204 303:205 304:206 305:207 306:208 307:208 308:208 309:209 310:210 311:210 312:211 313:212 314:213 315:214 316:215 317:215 318:216 319:217 320:218 321:218 322:218 323:218 324:219 325:220 326:221 327:221 328:221 329:222 330:223 331:224 332:225 333:225 334:226 335:227 336:228 337:229 338:230 339:231 340:232 341:232 342:233 343:234 344:234 345:234 346:235 347:235 348:236 349:237 350:237 351:237 352:237 353:238 354:239 355:239 356:239 357:239 358:239 359:240 360:241 361:242 362:243 363:243 364:243 365:244 366:244 367:244 368:245 369:245 370:245 371:246 372:247 373:248 374:249 375:250 376:251 377:252 378:253 379:253 380:253 381:254 382:254 383:255 384:256 385:257 386:258 387:258 388:258 389:258 390:259 391:260 392:261 393:262 394:263 395:263 396:263 397:264 398:265 399:266 400:267 401:268 402:269 403:269 404:269 405:270 406:271 407:272 408:273 409:274 410:275 411:276 412:277 413:278 414:279 415:280 416:281 417:282 418:283 419:283 420:283 421:283 422:283 423:284 424:285 425:286 426:287 427:288 428:289 429:290 430:290 431:290 432:291 433:292 434:293 435:294 436:295 437:295 438:296 439:296 440:296 441:297 442:298 443:299 444:300 445:301 446:301 447:302 448:303 449:304 450:305 451:306 452:306\n",
            "I0930 06:59:02.758811 140552314279808 run_squad.py:438] token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:3 14:3 15:3 16:3 17:3 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:10 26:10 27:10 28:10 29:10 30:10 31:10 32:10 33:11 34:12 35:13 36:14 37:15 38:15 39:16 40:17 41:18 42:18 43:18 44:18 45:19 46:20 47:21 48:22 49:23 50:24 51:24 52:24 53:24 54:25 55:26 56:26 57:26 58:27 59:28 60:28 61:28 62:29 63:30 64:31 65:32 66:33 67:34 68:35 69:35 70:36 71:37 72:38 73:39 74:39 75:39 76:40 77:41 78:42 79:43 80:44 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:50 89:51 90:51 91:52 92:53 93:54 94:54 95:54 96:55 97:56 98:57 99:58 100:59 101:60 102:60 103:60 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:67 112:67 113:68 114:69 115:69 116:69 117:69 118:70 119:71 120:72 121:73 122:74 123:75 124:75 125:75 126:76 127:76 128:76 129:77 130:78 131:79 132:79 133:80 134:81 135:82 136:83 137:83 138:84 139:85 140:86 141:86 142:86 143:87 144:88 145:89 146:90 147:91 148:92 149:93 150:94 151:95 152:96 153:97 154:97 155:97 156:98 157:99 158:100 159:101 160:102 161:103 162:104 163:104 164:104 165:105 166:106 167:107 168:107 169:108 170:109 171:110 172:111 173:111 174:111 175:112 176:113 177:114 178:114 179:114 180:115 181:116 182:117 183:118 184:119 185:120 186:121 187:122 188:123 189:123 190:123 191:123 192:123 193:124 194:125 195:126 196:127 197:128 198:129 199:130 200:130 201:130 202:130 203:130 204:131 205:132 206:133 207:134 208:135 209:135 210:135 211:136 212:137 213:138 214:138 215:138 216:139 217:140 218:141 219:142 220:143 221:144 222:144 223:144 224:144 225:145 226:146 227:146 228:146 229:147 230:148 231:149 232:150 233:151 234:152 235:152 236:152 237:153 238:154 239:155 240:156 241:157 242:158 243:159 244:160 245:161 246:161 247:162 248:163 249:164 250:165 251:166 252:167 253:168 254:169 255:169 256:170 257:171 258:172 259:173 260:174 261:174 262:174 263:174 264:174 265:175 266:176 267:177 268:178 269:179 270:179 271:179 272:180 273:181 274:181 275:181 276:182 277:183 278:184 279:185 280:186 281:187 282:188 283:189 284:190 285:191 286:192 287:193 288:194 289:195 290:196 291:196 292:196 293:197 294:198 295:199 296:200 297:201 298:202 299:203 300:203 301:203 302:204 303:205 304:206 305:207 306:208 307:208 308:208 309:209 310:210 311:210 312:211 313:212 314:213 315:214 316:215 317:215 318:216 319:217 320:218 321:218 322:218 323:218 324:219 325:220 326:221 327:221 328:221 329:222 330:223 331:224 332:225 333:225 334:226 335:227 336:228 337:229 338:230 339:231 340:232 341:232 342:233 343:234 344:234 345:234 346:235 347:235 348:236 349:237 350:237 351:237 352:237 353:238 354:239 355:239 356:239 357:239 358:239 359:240 360:241 361:242 362:243 363:243 364:243 365:244 366:244 367:244 368:245 369:245 370:245 371:246 372:247 373:248 374:249 375:250 376:251 377:252 378:253 379:253 380:253 381:254 382:254 383:255 384:256 385:257 386:258 387:258 388:258 389:258 390:259 391:260 392:261 393:262 394:263 395:263 396:263 397:264 398:265 399:266 400:267 401:268 402:269 403:269 404:269 405:270 406:271 407:272 408:273 409:274 410:275 411:276 412:277 413:278 414:279 415:280 416:281 417:282 418:283 419:283 420:283 421:283 422:283 423:284 424:285 425:286 426:287 427:288 428:289 429:290 430:290 431:290 432:291 433:292 434:293 435:294 436:295 437:295 438:296 439:296 440:296 441:297 442:298 443:299 444:300 445:301 446:301 447:302 448:303 449:304 450:305 451:306 452:306\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True\n",
            "I0930 06:59:02.759078 140552314279808 run_squad.py:440] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 26927 2705 5737 1029 102 2052 1037 26927 2705 5737 10514 26989 3401 1029 1000 2043 2024 2017 2183 2000 3462 3231 26927 2705 5737 1000 1029 26927 2705 5737 2001 3390 2012 1024 17850 2015 2006 2337 1012 26927 2705 5737 2018 2042 2881 2004 2019 1999 8743 4818 2135 8546 7421 1012 2147 2006 26927 2705 5737 2001 23454 6503 2043 2057 3133 1012 1996 2117 3462 1997 26927 2705 5737 2012 1996 2203 1997 2244 2001 2153 1037 2307 3112 1012 2551 2007 13970 21531 2006 1996 26927 2705 5737 4888 3049 2435 2033 2307 9967 1012 2007 1996 6503 1997 13908 7012 2006 26927 2705 5737 1998 13012 14235 2140 1010 2256 3601 2001 2006 3231 2085 1012 2101 26927 2705 5737 1998 2059 12943 3490 2109 2714 8606 3001 1010 2007 6581 3463 1012 1996 5197 1997 2122 7596 5209 2001 2025 7775 2000 1996 26927 2705 5737 2622 1517 2009 2001 1037 2120 6344 1012 2004 1045 2387 2009 1010 1996 2458 1997 26927 2705 5737 3421 1996 2969 1011 17975 1997 2256 2406 1999 1996 2492 1997 3935 2974 1012 26927 2705 5737 2038 4928 2000 2022 1996 2190 3302 1011 2000 1011 3302 7421 1999 1996 2088 2651 1012 1996 4888 1997 26927 2705 5737 2741 5213 5975 2408 1996 4895 19699 9013 18718 9632 3032 1012 2144 1996 9455 3231 2846 2012 21451 21748 2063 2001 2145 2012 2560 1037 2095 2185 2013 6503 1010 2057 2018 2275 2039 2569 4128 2012 21146 2099 2005 1996 4888 1997 26927 2705 5737 1012 1996 3144 3231 7493 1997 26927 2705 5737 1998 13012 14235 2140 2076 1996 2607 1997 1996 6084 2162 2001 2438 2000 2191 2019 11480 3842 9483 1012 1037 2691 23032 1045 8567 2001 3251 26927 2705 5737 2001 6020 2000 1037 8040 6784 1010 3251 9875 4095 2071 4685 2066 1037 16419 1010 1998 2061 2006 1012 13970 21531 2499 2005 26927 2705 5737 2004 1037 2136 2266 1010 9217 1996 6192 3210 2008 11443 2852 3527 1998 2003 3217 1010 2852 19422 1998 21146 2099 1012 2947 1996 3302 1011 2000 1011 3302 5195 2291 2150 26927 2705 5737 1006 1000 1996 3011 1000 1007 1998 1996 8608 4563 4316 2001 2170 13012 14235 2140 1006 1996 26515 1997 2935 12535 1007 1012 2009 2003 28043 2011 1037 2034 1011 2754 5024 7596 5013 5173 2013 22889 2615 1011 1998 2582 14613 2012 1996 2117 2754 2007 1996 6381 7596 5209 1997 26927 2705 5737 1012 2026 3945 2005 2619 2000 2599 1996 26927 2705 5737 2622 3092 2007 8902 1058 3501 3103 25329 2213 2040 6272 2000 1996 7861 2063 3650 1997 1996 2796 2390 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.850838 140552314279808 run_squad.py:442] input_ids: 101 2054 2003 26927 2705 5737 1029 102 2052 1037 26927 2705 5737 10514 26989 3401 1029 1000 2043 2024 2017 2183 2000 3462 3231 26927 2705 5737 1000 1029 26927 2705 5737 2001 3390 2012 1024 17850 2015 2006 2337 1012 26927 2705 5737 2018 2042 2881 2004 2019 1999 8743 4818 2135 8546 7421 1012 2147 2006 26927 2705 5737 2001 23454 6503 2043 2057 3133 1012 1996 2117 3462 1997 26927 2705 5737 2012 1996 2203 1997 2244 2001 2153 1037 2307 3112 1012 2551 2007 13970 21531 2006 1996 26927 2705 5737 4888 3049 2435 2033 2307 9967 1012 2007 1996 6503 1997 13908 7012 2006 26927 2705 5737 1998 13012 14235 2140 1010 2256 3601 2001 2006 3231 2085 1012 2101 26927 2705 5737 1998 2059 12943 3490 2109 2714 8606 3001 1010 2007 6581 3463 1012 1996 5197 1997 2122 7596 5209 2001 2025 7775 2000 1996 26927 2705 5737 2622 1517 2009 2001 1037 2120 6344 1012 2004 1045 2387 2009 1010 1996 2458 1997 26927 2705 5737 3421 1996 2969 1011 17975 1997 2256 2406 1999 1996 2492 1997 3935 2974 1012 26927 2705 5737 2038 4928 2000 2022 1996 2190 3302 1011 2000 1011 3302 7421 1999 1996 2088 2651 1012 1996 4888 1997 26927 2705 5737 2741 5213 5975 2408 1996 4895 19699 9013 18718 9632 3032 1012 2144 1996 9455 3231 2846 2012 21451 21748 2063 2001 2145 2012 2560 1037 2095 2185 2013 6503 1010 2057 2018 2275 2039 2569 4128 2012 21146 2099 2005 1996 4888 1997 26927 2705 5737 1012 1996 3144 3231 7493 1997 26927 2705 5737 1998 13012 14235 2140 2076 1996 2607 1997 1996 6084 2162 2001 2438 2000 2191 2019 11480 3842 9483 1012 1037 2691 23032 1045 8567 2001 3251 26927 2705 5737 2001 6020 2000 1037 8040 6784 1010 3251 9875 4095 2071 4685 2066 1037 16419 1010 1998 2061 2006 1012 13970 21531 2499 2005 26927 2705 5737 2004 1037 2136 2266 1010 9217 1996 6192 3210 2008 11443 2852 3527 1998 2003 3217 1010 2852 19422 1998 21146 2099 1012 2947 1996 3302 1011 2000 1011 3302 5195 2291 2150 26927 2705 5737 1006 1000 1996 3011 1000 1007 1998 1996 8608 4563 4316 2001 2170 13012 14235 2140 1006 1996 26515 1997 2935 12535 1007 1012 2009 2003 28043 2011 1037 2034 1011 2754 5024 7596 5013 5173 2013 22889 2615 1011 1998 2582 14613 2012 1996 2117 2754 2007 1996 6381 7596 5209 1997 26927 2705 5737 1012 2026 3945 2005 2619 2000 2599 1996 26927 2705 5737 2622 3092 2007 8902 1058 3501 3103 25329 2213 2040 6272 2000 1996 7861 2063 3650 1997 1996 2796 2390 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.851359 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.852787 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.856114 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000005\n",
            "I0930 06:59:02.856421 140552314279808 run_squad.py:432] unique_id: 1000000005\n",
            "INFO:tensorflow:example_index: 5\n",
            "I0930 06:59:02.856536 140552314279808 run_squad.py:433] example_index: 5\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.856622 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is as ##tra ? [SEP] i used this opportunity to share with the bud ##ding scientists my plans of making an indigenous air - to - air missile , as ##tra . [SEP]\n",
            "I0930 06:59:02.856725 140552314279808 run_squad.py:436] tokens: [CLS] what is as ##tra ? [SEP] i used this opportunity to share with the bud ##ding scientists my plans of making an indigenous air - to - air missile , as ##tra . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:16 26:16 27:16 28:16 29:17 30:17 31:18 32:18 33:18\n",
            "I0930 06:59:02.856822 140552314279808 run_squad.py:438] token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:16 26:16 27:16 28:16 29:17 30:17 31:18 32:18 33:18\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True\n",
            "I0930 06:59:02.856914 140552314279808 run_squad.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 2004 6494 1029 102 1045 2109 2023 4495 2000 3745 2007 1996 13007 4667 6529 2026 3488 1997 2437 2019 6284 2250 1011 2000 1011 2250 7421 1010 2004 6494 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.857189 140552314279808 run_squad.py:442] input_ids: 101 2054 2003 2004 6494 1029 102 1045 2109 2023 4495 2000 3745 2007 1996 13007 4667 6529 2026 3488 1997 2437 2019 6284 2250 1011 2000 1011 2250 7421 1010 2004 6494 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.857480 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.857799 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.864642 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000006\n",
            "I0930 06:59:02.864882 140552314279808 run_squad.py:432] unique_id: 1000000006\n",
            "INFO:tensorflow:example_index: 6\n",
            "I0930 06:59:02.864983 140552314279808 run_squad.py:433] example_index: 6\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.865071 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] did you have childhood friends ? [SEP] i had three close friends in my childhood — rama ##nad ##ha sas ##try , ara ##vin ##dan , and si ##va ##pr ##aka ##san . how did i do that ? what was it that i did not have ? but he did . but we did it at last ! my childhood is precious to me , but would it be of interest to anyone else ? but what did you do for the project \" ? some of my friends caution ##ed me about what they termed as my naive ##te . i did not find rev . what did i want ? i did well at the interview . how did it happen ? in fact , i would say mine was a very secure childhood , both material ##ly and emotionally . many friends , while asking me questions related to space flights , sometimes slip into astro ##logy . \" why did you not pro ##stra ##te yourself \" ? somehow , i did not take to the new setting . i tried hard to do as he said , which was to strive to control my thoughts and my mind and , through these , to influence my destiny ironically , that destiny did not lead me back to ram ##es ##wara ##m , but rather , swept me farther away from the home of my childhood . but it was the time i spent with ja ##lla ##lu ##ddin and sam ##su ##ddin that perhaps contributed most to the unique ##ness of my childhood and made all the difference in my later life . in this period of confusion and uncertainty , memories from my childhood came back to me and i discovered new meanings in them . to take an example from my own life , i had been fascinated by the mysteries of the sky and the flight of birds from early childhood . [SEP]\n",
            "I0930 06:59:02.865293 140552314279808 run_squad.py:436] tokens: [CLS] did you have childhood friends ? [SEP] i had three close friends in my childhood — rama ##nad ##ha sas ##try , ara ##vin ##dan , and si ##va ##pr ##aka ##san . how did i do that ? what was it that i did not have ? but he did . but we did it at last ! my childhood is precious to me , but would it be of interest to anyone else ? but what did you do for the project \" ? some of my friends caution ##ed me about what they termed as my naive ##te . i did not find rev . what did i want ? i did well at the interview . how did it happen ? in fact , i would say mine was a very secure childhood , both material ##ly and emotionally . many friends , while asking me questions related to space flights , sometimes slip into astro ##logy . \" why did you not pro ##stra ##te yourself \" ? somehow , i did not take to the new setting . i tried hard to do as he said , which was to strive to control my thoughts and my mind and , through these , to influence my destiny ironically , that destiny did not lead me back to ram ##es ##wara ##m , but rather , swept me farther away from the home of my childhood . but it was the time i spent with ja ##lla ##lu ##ddin and sam ##su ##ddin that perhaps contributed most to the unique ##ness of my childhood and made all the difference in my later life . in this period of confusion and uncertainty , memories from my childhood came back to me and i discovered new meanings in them . to take an example from my own life , i had been fascinated by the mysteries of the sky and the flight of birds from early childhood . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:9 19:9 20:10 21:10 22:10 23:11 24:11 25:11 26:11 27:12 28:13 29:13 30:13 31:13 32:13 33:13 34:13 35:14 36:15 37:16 38:17 39:18 40:18 41:19 42:20 43:21 44:22 45:23 46:24 47:25 48:25 49:25 50:26 51:27 52:27 53:27 54:28 55:29 56:30 57:31 58:32 59:32 60:32 61:33 62:34 63:35 64:36 65:37 66:37 67:38 68:39 69:40 70:41 71:42 72:43 73:44 74:45 75:46 76:46 77:46 78:47 79:48 80:49 81:50 82:51 83:52 84:53 85:53 86:53 87:53 88:54 89:55 90:56 91:57 92:57 93:58 94:59 95:60 96:61 97:62 98:63 99:64 100:65 101:65 102:65 103:65 104:66 105:67 106:68 107:69 108:69 109:69 110:70 111:71 112:72 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:77 121:77 122:78 123:79 124:80 125:80 126:80 127:81 128:81 129:82 130:83 131:84 132:85 133:86 134:87 135:88 136:89 137:90 138:90 139:91 140:92 141:92 142:93 143:94 144:94 145:94 146:95 147:95 148:96 149:97 150:98 151:99 152:100 153:101 154:102 155:103 156:103 157:104 158:105 159:106 160:107 161:107 162:107 163:107 164:107 165:108 166:109 167:110 168:111 169:111 170:111 171:112 172:112 173:112 174:112 175:112 176:113 177:114 178:115 179:116 180:117 181:118 182:119 183:120 184:120 185:120 186:121 187:122 188:123 189:124 190:125 191:126 192:127 193:127 194:128 195:129 196:130 197:131 198:132 199:133 200:134 201:135 202:136 203:137 204:138 205:139 206:139 207:140 208:141 209:141 210:142 211:143 212:144 213:145 214:146 215:146 216:147 217:148 218:149 219:150 220:151 221:152 222:153 223:154 224:155 225:155 226:155 227:155 228:155 229:156 230:157 231:157 232:158 233:159 234:160 235:161 236:162 237:163 238:164 239:165 240:166 241:167 242:167 243:167 244:168 245:169 246:170 247:171 248:172 249:173 250:174 251:175 252:175 253:175 254:175 255:176 256:177 257:177 258:177 259:178 260:179 261:180 262:181 263:182 264:183 265:184 266:184 267:185 268:186 269:187 270:188 271:189 272:190 273:191 274:192 275:193 276:194 277:195 278:196 279:196 280:196 281:197 282:198 283:199 284:200 285:201 286:202 287:202 288:203 289:204 290:205 291:206 292:207 293:208 294:209 295:210 296:211 297:212 298:213 299:214 300:215 301:216 302:217 303:217 304:217 305:218 306:219 307:220 308:221 309:222 310:223 311:224 312:224 313:225 314:226 315:227 316:228 317:229 318:230 319:231 320:232 321:233 322:234 323:235 324:236 325:237 326:238 327:239 328:240 329:241 330:242 331:242\n",
            "I0930 06:59:02.865525 140552314279808 run_squad.py:438] token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:9 19:9 20:10 21:10 22:10 23:11 24:11 25:11 26:11 27:12 28:13 29:13 30:13 31:13 32:13 33:13 34:13 35:14 36:15 37:16 38:17 39:18 40:18 41:19 42:20 43:21 44:22 45:23 46:24 47:25 48:25 49:25 50:26 51:27 52:27 53:27 54:28 55:29 56:30 57:31 58:32 59:32 60:32 61:33 62:34 63:35 64:36 65:37 66:37 67:38 68:39 69:40 70:41 71:42 72:43 73:44 74:45 75:46 76:46 77:46 78:47 79:48 80:49 81:50 82:51 83:52 84:53 85:53 86:53 87:53 88:54 89:55 90:56 91:57 92:57 93:58 94:59 95:60 96:61 97:62 98:63 99:64 100:65 101:65 102:65 103:65 104:66 105:67 106:68 107:69 108:69 109:69 110:70 111:71 112:72 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:77 121:77 122:78 123:79 124:80 125:80 126:80 127:81 128:81 129:82 130:83 131:84 132:85 133:86 134:87 135:88 136:89 137:90 138:90 139:91 140:92 141:92 142:93 143:94 144:94 145:94 146:95 147:95 148:96 149:97 150:98 151:99 152:100 153:101 154:102 155:103 156:103 157:104 158:105 159:106 160:107 161:107 162:107 163:107 164:107 165:108 166:109 167:110 168:111 169:111 170:111 171:112 172:112 173:112 174:112 175:112 176:113 177:114 178:115 179:116 180:117 181:118 182:119 183:120 184:120 185:120 186:121 187:122 188:123 189:124 190:125 191:126 192:127 193:127 194:128 195:129 196:130 197:131 198:132 199:133 200:134 201:135 202:136 203:137 204:138 205:139 206:139 207:140 208:141 209:141 210:142 211:143 212:144 213:145 214:146 215:146 216:147 217:148 218:149 219:150 220:151 221:152 222:153 223:154 224:155 225:155 226:155 227:155 228:155 229:156 230:157 231:157 232:158 233:159 234:160 235:161 236:162 237:163 238:164 239:165 240:166 241:167 242:167 243:167 244:168 245:169 246:170 247:171 248:172 249:173 250:174 251:175 252:175 253:175 254:175 255:176 256:177 257:177 258:177 259:178 260:179 261:180 262:181 263:182 264:183 265:184 266:184 267:185 268:186 269:187 270:188 271:189 272:190 273:191 274:192 275:193 276:194 277:195 278:196 279:196 280:196 281:197 282:198 283:199 284:200 285:201 286:202 287:202 288:203 289:204 290:205 291:206 292:207 293:208 294:209 295:210 296:211 297:212 298:213 299:214 300:215 301:216 302:217 303:217 304:217 305:218 306:219 307:220 308:221 309:222 310:223 311:224 312:224 313:225 314:226 315:227 316:228 317:229 318:230 319:231 320:232 321:233 322:234 323:235 324:236 325:237 326:238 327:239 328:240 329:241 330:242 331:242\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True\n",
            "I0930 06:59:02.952858 140552314279808 run_squad.py:440] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True\n",
            "INFO:tensorflow:input_ids: 101 2106 2017 2031 5593 2814 1029 102 1045 2018 2093 2485 2814 1999 2026 5593 1517 14115 25389 3270 21871 11129 1010 19027 6371 7847 1010 1998 9033 3567 18098 11905 8791 1012 2129 2106 1045 2079 2008 1029 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2002 2106 1012 2021 2057 2106 2009 2012 2197 999 2026 5593 2003 9062 2000 2033 1010 2021 2052 2009 2022 1997 3037 2000 3087 2842 1029 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 2070 1997 2026 2814 14046 2098 2033 2055 2054 2027 12061 2004 2026 15743 2618 1012 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 1045 2106 2092 2012 1996 4357 1012 2129 2106 2009 4148 1029 1999 2755 1010 1045 2052 2360 3067 2001 1037 2200 5851 5593 1010 2119 3430 2135 1998 14868 1012 2116 2814 1010 2096 4851 2033 3980 3141 2000 2686 7599 1010 2823 7540 2046 28625 6483 1012 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 1045 2699 2524 2000 2079 2004 2002 2056 1010 2029 2001 2000 29453 2000 2491 2026 4301 1998 2026 2568 1998 1010 2083 2122 1010 2000 3747 2026 10461 18527 1010 2008 10461 2106 2025 2599 2033 2067 2000 8223 2229 11872 2213 1010 2021 2738 1010 7260 2033 8736 2185 2013 1996 2188 1997 2026 5593 1012 2021 2009 2001 1996 2051 1045 2985 2007 14855 4571 7630 18277 1998 3520 6342 18277 2008 3383 5201 2087 2000 1996 4310 2791 1997 2026 5593 1998 2081 2035 1996 4489 1999 2026 2101 2166 1012 1999 2023 2558 1997 6724 1998 12503 1010 5758 2013 2026 5593 2234 2067 2000 2033 1998 1045 3603 2047 15383 1999 2068 1012 2000 2202 2019 2742 2013 2026 2219 2166 1010 1045 2018 2042 15677 2011 1996 15572 1997 1996 3712 1998 1996 3462 1997 5055 2013 2220 5593 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.953782 140552314279808 run_squad.py:442] input_ids: 101 2106 2017 2031 5593 2814 1029 102 1045 2018 2093 2485 2814 1999 2026 5593 1517 14115 25389 3270 21871 11129 1010 19027 6371 7847 1010 1998 9033 3567 18098 11905 8791 1012 2129 2106 1045 2079 2008 1029 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2002 2106 1012 2021 2057 2106 2009 2012 2197 999 2026 5593 2003 9062 2000 2033 1010 2021 2052 2009 2022 1997 3037 2000 3087 2842 1029 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 2070 1997 2026 2814 14046 2098 2033 2055 2054 2027 12061 2004 2026 15743 2618 1012 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 1045 2106 2092 2012 1996 4357 1012 2129 2106 2009 4148 1029 1999 2755 1010 1045 2052 2360 3067 2001 1037 2200 5851 5593 1010 2119 3430 2135 1998 14868 1012 2116 2814 1010 2096 4851 2033 3980 3141 2000 2686 7599 1010 2823 7540 2046 28625 6483 1012 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 1045 2699 2524 2000 2079 2004 2002 2056 1010 2029 2001 2000 29453 2000 2491 2026 4301 1998 2026 2568 1998 1010 2083 2122 1010 2000 3747 2026 10461 18527 1010 2008 10461 2106 2025 2599 2033 2067 2000 8223 2229 11872 2213 1010 2021 2738 1010 7260 2033 8736 2185 2013 1996 2188 1997 2026 5593 1012 2021 2009 2001 1996 2051 1045 2985 2007 14855 4571 7630 18277 1998 3520 6342 18277 2008 3383 5201 2087 2000 1996 4310 2791 1997 2026 5593 1998 2081 2035 1996 4489 1999 2026 2101 2166 1012 1999 2023 2558 1997 6724 1998 12503 1010 5758 2013 2026 5593 2234 2067 2000 2033 1998 1045 3603 2047 15383 1999 2068 1012 2000 2202 2019 2742 2013 2026 2219 2166 1010 1045 2018 2042 15677 2011 1996 15572 1997 1996 3712 1998 1996 3462 1997 5055 2013 2220 5593 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.954565 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:02.954805 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:02.960163 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000007\n",
            "I0930 06:59:02.960373 140552314279808 run_squad.py:432] unique_id: 1000000007\n",
            "INFO:tensorflow:example_index: 7\n",
            "I0930 06:59:02.960444 140552314279808 run_squad.py:433] example_index: 7\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:02.960510 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] which school did you go to as a child ? [SEP] how did i do that ? but he did . what was it that i did not have ? but we did it at last ! may god bless you , my child \" ! but what did you do for the project \" ? there was a child - like curiosity in him which was very engaging . occasionally , a child would appear and wave at the train . i did not find rev . what did i want ? i did well at the interview . how did it happen ? \" why did you not pro ##stra ##te yourself \" ? i was struck by his irresistible , almost child - like smile and gr ##acious manner . again miles to the arab teaching school , climb sandy hills to railway station road , collect , distribute newspapers to temple city citizens , few hours after sunrise , going to school . take my word , this boy is going to bring glory to his school and to his teachers \" . after school , we went home and told our respective parents about the incident . somehow , i did not take to the new setting . he blunt ##ly asked the teacher to either apologize or quit the school and the island . indeed , i was the first child from ram ##es ##wara ##m to fly i ##yad ##urai solomon was a great teacher because he ins ##till ##ed in all the children a sense of their own worth . [SEP]\n",
            "I0930 06:59:02.960638 140552314279808 run_squad.py:436] tokens: [CLS] which school did you go to as a child ? [SEP] how did i do that ? but he did . what was it that i did not have ? but we did it at last ! may god bless you , my child \" ! but what did you do for the project \" ? there was a child - like curiosity in him which was very engaging . occasionally , a child would appear and wave at the train . i did not find rev . what did i want ? i did well at the interview . how did it happen ? \" why did you not pro ##stra ##te yourself \" ? i was struck by his irresistible , almost child - like smile and gr ##acious manner . again miles to the arab teaching school , climb sandy hills to railway station road , collect , distribute newspapers to temple city citizens , few hours after sunrise , going to school . take my word , this boy is going to bring glory to his school and to his teachers \" . after school , we went home and told our respective parents about the incident . somehow , i did not take to the new setting . he blunt ##ly asked the teacher to either apologize or quit the school and the island . indeed , i was the first child from ram ##es ##wara ##m to fly i ##yad ##urai solomon was a great teacher because he ins ##till ##ed in all the children a sense of their own worth . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:5 19:6 20:7 21:7 22:7 23:8 24:9 25:10 26:11 27:12 28:13 29:14 30:14 31:14 32:15 33:16 34:17 35:18 36:19 37:19 38:19 39:20 40:21 41:22 42:22 43:23 44:24 45:24 46:24 47:24 48:25 49:26 50:27 51:28 52:29 53:30 54:31 55:31 56:31 57:31 58:32 59:33 60:34 61:34 62:34 63:35 64:36 65:37 66:38 67:39 68:40 69:41 70:41 71:41 72:41 73:42 74:43 75:44 76:45 77:46 78:47 79:48 80:49 81:50 82:50 83:50 84:51 85:52 86:53 87:54 88:54 89:54 90:55 91:56 92:57 93:57 94:57 95:58 96:59 97:60 98:61 99:62 100:62 101:62 102:63 103:64 104:65 105:65 106:65 107:65 108:66 109:67 110:68 111:69 112:69 113:69 114:70 115:70 116:70 117:70 118:71 119:72 120:73 121:74 122:75 123:75 124:76 125:77 126:77 127:78 128:79 129:80 130:81 131:81 132:82 133:82 134:82 135:83 136:84 137:85 138:86 139:87 140:88 141:88 142:89 143:90 144:91 145:92 146:93 147:94 148:95 149:95 150:96 151:96 152:97 153:98 154:99 155:100 156:101 157:102 158:102 159:103 160:104 161:105 162:106 163:106 164:107 165:108 166:109 167:109 168:109 169:110 170:111 171:111 172:112 173:113 174:114 175:115 176:116 177:117 178:118 179:119 180:120 181:121 182:122 183:123 184:124 185:125 186:125 187:125 188:125 189:126 190:126 191:127 192:128 193:129 194:130 195:131 196:132 197:133 198:134 199:135 200:136 201:137 202:137 203:137 204:137 205:138 206:139 207:140 208:141 209:142 210:143 211:144 212:145 213:145 214:145 215:146 216:146 217:147 218:148 219:149 220:150 221:151 222:152 223:153 224:154 225:155 226:156 227:157 228:158 229:159 230:159 231:159 232:159 233:160 234:161 235:162 236:163 237:164 238:165 239:166 240:166 241:166 242:166 243:167 244:168 245:169 246:169 247:169 248:170 249:171 250:172 251:173 252:174 253:175 254:176 255:177 256:177 257:177 258:178 259:179 260:180 261:181 262:182 263:183 264:184 265:185 266:186 267:187 268:187\n",
            "I0930 06:59:02.960783 140552314279808 run_squad.py:438] token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:5 19:6 20:7 21:7 22:7 23:8 24:9 25:10 26:11 27:12 28:13 29:14 30:14 31:14 32:15 33:16 34:17 35:18 36:19 37:19 38:19 39:20 40:21 41:22 42:22 43:23 44:24 45:24 46:24 47:24 48:25 49:26 50:27 51:28 52:29 53:30 54:31 55:31 56:31 57:31 58:32 59:33 60:34 61:34 62:34 63:35 64:36 65:37 66:38 67:39 68:40 69:41 70:41 71:41 72:41 73:42 74:43 75:44 76:45 77:46 78:47 79:48 80:49 81:50 82:50 83:50 84:51 85:52 86:53 87:54 88:54 89:54 90:55 91:56 92:57 93:57 94:57 95:58 96:59 97:60 98:61 99:62 100:62 101:62 102:63 103:64 104:65 105:65 106:65 107:65 108:66 109:67 110:68 111:69 112:69 113:69 114:70 115:70 116:70 117:70 118:71 119:72 120:73 121:74 122:75 123:75 124:76 125:77 126:77 127:78 128:79 129:80 130:81 131:81 132:82 133:82 134:82 135:83 136:84 137:85 138:86 139:87 140:88 141:88 142:89 143:90 144:91 145:92 146:93 147:94 148:95 149:95 150:96 151:96 152:97 153:98 154:99 155:100 156:101 157:102 158:102 159:103 160:104 161:105 162:106 163:106 164:107 165:108 166:109 167:109 168:109 169:110 170:111 171:111 172:112 173:113 174:114 175:115 176:116 177:117 178:118 179:119 180:120 181:121 182:122 183:123 184:124 185:125 186:125 187:125 188:125 189:126 190:126 191:127 192:128 193:129 194:130 195:131 196:132 197:133 198:134 199:135 200:136 201:137 202:137 203:137 204:137 205:138 206:139 207:140 208:141 209:142 210:143 211:144 212:145 213:145 214:145 215:146 216:146 217:147 218:148 219:149 220:150 221:151 222:152 223:153 224:154 225:155 226:156 227:157 228:158 229:159 230:159 231:159 232:159 233:160 234:161 235:162 236:163 237:164 238:165 239:166 240:166 241:166 242:166 243:167 244:168 245:169 246:169 247:169 248:170 249:171 250:172 251:173 252:174 253:175 254:176 255:177 256:177 257:177 258:178 259:179 260:180 261:181 262:182 263:183 264:184 265:185 266:186 267:187 268:187\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True\n",
            "I0930 06:59:02.960917 140552314279808 run_squad.py:440] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True\n",
            "INFO:tensorflow:input_ids: 101 2029 2082 2106 2017 2175 2000 2004 1037 2775 1029 102 2129 2106 1045 2079 2008 1029 2021 2002 2106 1012 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2057 2106 2009 2012 2197 999 2089 2643 19994 2017 1010 2026 2775 1000 999 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 2045 2001 1037 2775 1011 2066 10628 1999 2032 2029 2001 2200 11973 1012 5681 1010 1037 2775 2052 3711 1998 4400 2012 1996 3345 1012 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 1045 2106 2092 2012 1996 4357 1012 2129 2106 2009 4148 1029 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 1045 2001 4930 2011 2010 27149 1010 2471 2775 1011 2066 2868 1998 24665 20113 5450 1012 2153 2661 2000 1996 5424 4252 2082 1010 7105 7525 4564 2000 2737 2276 2346 1010 8145 1010 16062 6399 2000 3379 2103 4480 1010 2261 2847 2044 13932 1010 2183 2000 2082 1012 2202 2026 2773 1010 2023 2879 2003 2183 2000 3288 8294 2000 2010 2082 1998 2000 2010 5089 1000 1012 2044 2082 1010 2057 2253 2188 1998 2409 2256 7972 3008 2055 1996 5043 1012 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 2002 14969 2135 2356 1996 3836 2000 2593 12134 2030 8046 1996 2082 1998 1996 2479 1012 5262 1010 1045 2001 1996 2034 2775 2013 8223 2229 11872 2213 2000 4875 1045 25152 24804 9168 2001 1037 2307 3836 2138 2002 16021 28345 2098 1999 2035 1996 2336 1037 3168 1997 2037 2219 4276 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.058770 140552314279808 run_squad.py:442] input_ids: 101 2029 2082 2106 2017 2175 2000 2004 1037 2775 1029 102 2129 2106 1045 2079 2008 1029 2021 2002 2106 1012 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2057 2106 2009 2012 2197 999 2089 2643 19994 2017 1010 2026 2775 1000 999 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 2045 2001 1037 2775 1011 2066 10628 1999 2032 2029 2001 2200 11973 1012 5681 1010 1037 2775 2052 3711 1998 4400 2012 1996 3345 1012 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 1045 2106 2092 2012 1996 4357 1012 2129 2106 2009 4148 1029 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 1045 2001 4930 2011 2010 27149 1010 2471 2775 1011 2066 2868 1998 24665 20113 5450 1012 2153 2661 2000 1996 5424 4252 2082 1010 7105 7525 4564 2000 2737 2276 2346 1010 8145 1010 16062 6399 2000 3379 2103 4480 1010 2261 2847 2044 13932 1010 2183 2000 2082 1012 2202 2026 2773 1010 2023 2879 2003 2183 2000 3288 8294 2000 2010 2082 1998 2000 2010 5089 1000 1012 2044 2082 1010 2057 2253 2188 1998 2409 2256 7972 3008 2055 1996 5043 1012 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 2002 14969 2135 2356 1996 3836 2000 2593 12134 2030 8046 1996 2082 1998 1996 2479 1012 5262 1010 1045 2001 1996 2034 2775 2013 8223 2229 11872 2213 2000 4875 1045 25152 24804 9168 2001 1037 2307 3836 2138 2002 16021 28345 2098 1999 2035 1996 2336 1037 3168 1997 2037 2219 4276 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.059350 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.059717 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.067028 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000008\n",
            "I0930 06:59:03.067272 140552314279808 run_squad.py:432] unique_id: 1000000008\n",
            "INFO:tensorflow:example_index: 8\n",
            "I0930 06:59:03.067403 140552314279808 run_squad.py:433] example_index: 8\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.067490 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when did you start liking science ? [SEP] i wondered where i should start . what was it that i did not have ? but we did it at last ! how did i do that ? but he did . but what did you do for the project \" ? nor did i have any information about career opportunities available to a student of science . my day would start with a stroll of about km around the lodge i was living in . i did not find rev . what did i want ? how did it happen ? i did well at the interview . \" why did you not pro ##stra ##te yourself \" ? i was very enthusiastic about ensuring that science did not remain outside the pu ##r ##view of this wonderful language . somehow , i did not take to the new setting . in science , reality is that which exists . his answer filled me with a strange energy and enthusiasm : whenever human beings find themselves alone , as a natural reaction , they start looking for company . he did not take long to come to the point . yet , he never pretended to know more than he did . technology , unlike science , is a group activity . [SEP]\n",
            "I0930 06:59:03.067654 140552314279808 run_squad.py:436] tokens: [CLS] when did you start liking science ? [SEP] i wondered where i should start . what was it that i did not have ? but we did it at last ! how did i do that ? but he did . but what did you do for the project \" ? nor did i have any information about career opportunities available to a student of science . my day would start with a stroll of about km around the lodge i was living in . i did not find rev . what did i want ? how did it happen ? i did well at the interview . \" why did you not pro ##stra ##te yourself \" ? i was very enthusiastic about ensuring that science did not remain outside the pu ##r ##view of this wonderful language . somehow , i did not take to the new setting . in science , reality is that which exists . his answer filled me with a strange energy and enthusiasm : whenever human beings find themselves alone , as a natural reaction , they start looking for company . he did not take long to come to the point . yet , he never pretended to know more than he did . technology , unlike science , is a group activity . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:5 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:12 25:12 26:13 27:14 28:15 29:16 30:17 31:17 32:17 33:18 34:19 35:20 36:21 37:22 38:22 39:23 40:24 41:24 42:24 43:25 44:26 45:27 46:28 47:29 48:30 49:31 50:31 51:31 52:31 53:32 54:33 55:34 56:35 57:36 58:37 59:38 60:39 61:40 62:41 63:42 64:43 65:44 66:45 67:45 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:61 86:61 87:62 88:63 89:64 90:65 91:65 92:65 93:66 94:67 95:68 96:68 97:68 98:69 99:70 100:71 101:71 102:71 103:72 104:73 105:74 106:75 107:76 108:76 109:76 110:76 111:77 112:78 113:79 114:80 115:80 116:80 117:81 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:86 126:87 127:88 128:89 129:90 130:91 131:92 132:93 133:94 134:94 135:94 136:95 137:96 138:97 139:98 140:98 141:98 142:98 143:99 144:100 145:101 146:102 147:103 148:104 149:105 150:106 151:106 152:106 153:107 154:107 155:108 156:109 157:110 158:111 159:112 160:112 161:112 162:113 163:114 164:115 165:116 166:117 167:118 168:119 169:120 170:121 171:121 172:122 173:123 174:124 175:125 176:126 177:127 178:127 179:128 180:129 181:130 182:131 183:131 184:132 185:133 186:134 187:135 188:136 189:136 190:136 191:137 192:138 193:139 194:140 195:141 196:142 197:143 198:144 199:145 200:145 201:145 202:145 203:146 204:147 205:148 206:149 207:150 208:151 209:152 210:153 211:154 212:154 213:154 214:154 215:155 216:156 217:156 218:157 219:158 220:159 221:160 222:160\n",
            "I0930 06:59:03.067829 140552314279808 run_squad.py:438] token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:5 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:12 25:12 26:13 27:14 28:15 29:16 30:17 31:17 32:17 33:18 34:19 35:20 36:21 37:22 38:22 39:23 40:24 41:24 42:24 43:25 44:26 45:27 46:28 47:29 48:30 49:31 50:31 51:31 52:31 53:32 54:33 55:34 56:35 57:36 58:37 59:38 60:39 61:40 62:41 63:42 64:43 65:44 66:45 67:45 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:61 86:61 87:62 88:63 89:64 90:65 91:65 92:65 93:66 94:67 95:68 96:68 97:68 98:69 99:70 100:71 101:71 102:71 103:72 104:73 105:74 106:75 107:76 108:76 109:76 110:76 111:77 112:78 113:79 114:80 115:80 116:80 117:81 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:86 126:87 127:88 128:89 129:90 130:91 131:92 132:93 133:94 134:94 135:94 136:95 137:96 138:97 139:98 140:98 141:98 142:98 143:99 144:100 145:101 146:102 147:103 148:104 149:105 150:106 151:106 152:106 153:107 154:107 155:108 156:109 157:110 158:111 159:112 160:112 161:112 162:113 163:114 164:115 165:116 166:117 167:118 168:119 169:120 170:121 171:121 172:122 173:123 174:124 175:125 176:126 177:127 178:127 179:128 180:129 181:130 182:131 183:131 184:132 185:133 186:134 187:135 188:136 189:136 190:136 191:137 192:138 193:139 194:140 195:141 196:142 197:143 198:144 199:145 200:145 201:145 202:145 203:146 204:147 205:148 206:149 207:150 208:151 209:152 210:153 211:154 212:154 213:154 214:154 215:155 216:156 217:156 218:157 219:158 220:159 221:160 222:160\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True\n",
            "I0930 06:59:03.158257 140552314279808 run_squad.py:440] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 2017 2707 16663 2671 1029 102 1045 4999 2073 1045 2323 2707 1012 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2057 2106 2009 2012 2197 999 2129 2106 1045 2079 2008 1029 2021 2002 2106 1012 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 4496 2106 1045 2031 2151 2592 2055 2476 6695 2800 2000 1037 3076 1997 2671 1012 2026 2154 2052 2707 2007 1037 27244 1997 2055 2463 2105 1996 7410 1045 2001 2542 1999 1012 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 2129 2106 2009 4148 1029 1045 2106 2092 2012 1996 4357 1012 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 1045 2001 2200 14727 2055 12725 2008 2671 2106 2025 3961 2648 1996 16405 2099 8584 1997 2023 6919 2653 1012 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 1999 2671 1010 4507 2003 2008 2029 6526 1012 2010 3437 3561 2033 2007 1037 4326 2943 1998 12024 1024 7188 2529 9552 2424 3209 2894 1010 2004 1037 3019 4668 1010 2027 2707 2559 2005 2194 1012 2002 2106 2025 2202 2146 2000 2272 2000 1996 2391 1012 2664 1010 2002 2196 14688 2000 2113 2062 2084 2002 2106 1012 2974 1010 4406 2671 1010 2003 1037 2177 4023 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.158801 140552314279808 run_squad.py:442] input_ids: 101 2043 2106 2017 2707 16663 2671 1029 102 1045 4999 2073 1045 2323 2707 1012 2054 2001 2009 2008 1045 2106 2025 2031 1029 2021 2057 2106 2009 2012 2197 999 2129 2106 1045 2079 2008 1029 2021 2002 2106 1012 2021 2054 2106 2017 2079 2005 1996 2622 1000 1029 4496 2106 1045 2031 2151 2592 2055 2476 6695 2800 2000 1037 3076 1997 2671 1012 2026 2154 2052 2707 2007 1037 27244 1997 2055 2463 2105 1996 7410 1045 2001 2542 1999 1012 1045 2106 2025 2424 7065 1012 2054 2106 1045 2215 1029 2129 2106 2009 4148 1029 1045 2106 2092 2012 1996 4357 1012 1000 2339 2106 2017 2025 4013 20528 2618 4426 1000 1029 1045 2001 2200 14727 2055 12725 2008 2671 2106 2025 3961 2648 1996 16405 2099 8584 1997 2023 6919 2653 1012 5064 1010 1045 2106 2025 2202 2000 1996 2047 4292 1012 1999 2671 1010 4507 2003 2008 2029 6526 1012 2010 3437 3561 2033 2007 1037 4326 2943 1998 12024 1024 7188 2529 9552 2424 3209 2894 1010 2004 1037 3019 4668 1010 2027 2707 2559 2005 2194 1012 2002 2106 2025 2202 2146 2000 2272 2000 1996 2391 1012 2664 1010 2002 2196 14688 2000 2113 2062 2084 2002 2106 1012 2974 1010 4406 2671 1010 2003 1037 2177 4023 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.159159 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.159504 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.169256 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000009\n",
            "I0930 06:59:03.169561 140552314279808 run_squad.py:432] unique_id: 1000000009\n",
            "INFO:tensorflow:example_index: 9\n",
            "I0930 06:59:03.169683 140552314279808 run_squad.py:433] example_index: 9\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.169780 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what was your role in nike - apache ? [SEP] it was a sounding rocket , called nike - apache , made at nasa . in the maiden nike - apache launch , i was in charge of rocket integration and safety . after the successful launch of nike - apache , he chose to share with us his dream of an indian satellite launch vehicle . dr bra ##hm prakash played a very important role in shaping my leadership skills . two of my colleagues who played a very active and crucial role in this launch were d ea ##sw ##ard ##as and r ara ##va ##mu ##dan . i emphasized the sea - ski ##mming role of the core vehicle to admiral dawson . each individual creature on this beautiful planet is created by god to fu ##lf ##il a particular role . he describes the role of visionary indian scientists , such as dr vikram sara ##bha ##i , and of the creation of a coordinated network of research institutions . their vision was very clear : if indians were to play a meaningful role in the community of nations , they must be second to none in the application of advanced technologies to their real - life problems . this excellent laboratory played a truncated role that did not reflect its existing or potential capabilities or even fulfill the expectations in south block . this cat ##ego ##rization now appears non ##sen ##sic ##al , as the us air force ' s ground - launched tom ##aha ##wk is used in a tactical role , notwithstanding its range of some km . i also drew their attention to the crucial role that carbon - carbon and other advanced composite materials play in mastering the re - entry technology . he describes the struggles of his boy ##hood and youth , bringing alive everyday life in a small town in south india and the inspirational role of educators . a crucial aspect of the team leader ' s role is to negotiate with these key people for their requirements , and to ensure that the dialogue continues on a regular basis as the situation develops or changes . i will not be pre ##sum ##pt ##uous enough to say that my life can be a role model for anybody ; but some poor child living in an obscure place , in an under ##pr ##iv ##ile ##ged social setting may find a little sol ##ace in the way my destiny has been shaped . till the ag ##ni launch , the indian armed forces had been structured for a strictly defensive role to safeguard our nation , to shield our democratic processes from the turbulence in the countries around us and to raise the cost of any external intervention to an unacceptable level for countries which may entertain such notions . [SEP]\n",
            "I0930 06:59:03.170106 140552314279808 run_squad.py:436] tokens: [CLS] what was your role in nike - apache ? [SEP] it was a sounding rocket , called nike - apache , made at nasa . in the maiden nike - apache launch , i was in charge of rocket integration and safety . after the successful launch of nike - apache , he chose to share with us his dream of an indian satellite launch vehicle . dr bra ##hm prakash played a very important role in shaping my leadership skills . two of my colleagues who played a very active and crucial role in this launch were d ea ##sw ##ard ##as and r ara ##va ##mu ##dan . i emphasized the sea - ski ##mming role of the core vehicle to admiral dawson . each individual creature on this beautiful planet is created by god to fu ##lf ##il a particular role . he describes the role of visionary indian scientists , such as dr vikram sara ##bha ##i , and of the creation of a coordinated network of research institutions . their vision was very clear : if indians were to play a meaningful role in the community of nations , they must be second to none in the application of advanced technologies to their real - life problems . this excellent laboratory played a truncated role that did not reflect its existing or potential capabilities or even fulfill the expectations in south block . this cat ##ego ##rization now appears non ##sen ##sic ##al , as the us air force ' s ground - launched tom ##aha ##wk is used in a tactical role , notwithstanding its range of some km . i also drew their attention to the crucial role that carbon - carbon and other advanced composite materials play in mastering the re - entry technology . he describes the struggles of his boy ##hood and youth , bringing alive everyday life in a small town in south india and the inspirational role of educators . a crucial aspect of the team leader ' s role is to negotiate with these key people for their requirements , and to ensure that the dialogue continues on a regular basis as the situation develops or changes . i will not be pre ##sum ##pt ##uous enough to say that my life can be a role model for anybody ; but some poor child living in an obscure place , in an under ##pr ##iv ##ile ##ged social setting may find a little sol ##ace in the way my destiny has been shaped . till the ag ##ni launch , the indian armed forces had been structured for a strictly defensive role to safeguard our nation , to shield our democratic processes from the turbulence in the countries around us and to raise the cost of any external intervention to an unacceptable level for countries which may entertain such notions . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:4 17:5 18:6 19:6 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:11 28:12 29:13 30:13 31:13 32:14 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:22 42:23 43:23 44:23 45:24 46:25 47:26 48:27 49:28 50:28 51:28 52:28 53:29 54:30 55:31 56:32 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:40 65:41 66:42 67:42 68:42 69:43 70:43 71:44 72:45 73:46 74:47 75:48 76:49 77:50 78:51 79:52 80:53 81:54 82:54 83:54 84:55 85:56 86:57 87:58 88:59 89:60 90:61 91:62 92:63 93:64 94:65 95:66 96:67 97:68 98:69 99:70 100:71 101:71 102:71 103:71 104:72 105:73 106:74 107:74 108:74 109:74 110:74 111:74 112:75 113:76 114:77 115:77 116:77 117:77 118:78 119:79 120:80 121:81 122:82 123:83 124:84 125:85 126:85 127:85 128:86 129:87 130:88 131:89 132:90 133:91 134:92 135:93 136:94 137:95 138:96 139:97 140:97 141:97 142:98 143:99 144:100 145:100 146:100 147:101 148:102 149:103 150:104 151:105 152:106 153:107 154:107 155:108 156:109 157:110 158:111 159:112 160:112 161:112 162:112 163:113 164:114 165:115 166:116 167:117 168:118 169:119 170:120 171:121 172:122 173:123 174:123 175:123 176:124 177:125 178:126 179:127 180:127 181:128 182:129 183:130 184:131 185:132 186:133 187:134 188:135 189:136 190:137 191:138 192:139 193:140 194:140 195:141 196:142 197:143 198:144 199:145 200:146 201:147 202:148 203:149 204:150 205:151 206:152 207:153 208:154 209:155 210:155 211:155 212:156 213:156 214:156 215:157 216:158 217:159 218:160 219:161 220:162 221:163 222:164 223:165 224:166 225:167 226:168 227:169 228:170 229:171 230:172 231:173 232:174 233:175 234:176 235:177 236:178 237:179 238:179 239:179 240:180 241:180 242:180 243:181 244:182 245:183 246:183 247:183 248:183 249:183 250:184 251:185 252:186 253:187 254:188 255:188 256:188 257:189 258:189 259:190 260:191 261:191 262:191 263:192 264:193 265:194 266:195 267:196 268:197 269:197 270:198 271:199 272:200 273:201 274:202 275:203 276:203 277:203 278:204 279:205 280:206 281:207 282:208 283:209 284:210 285:211 286:212 287:213 288:213 289:213 290:214 291:215 292:216 293:217 294:218 295:219 296:220 297:221 298:222 299:223 300:223 301:223 302:224 303:224 304:224 305:225 306:226 307:227 308:228 309:229 310:230 311:230 312:231 313:232 314:232 315:233 316:234 317:235 318:236 319:237 320:238 321:239 322:240 323:241 324:242 325:243 326:244 327:245 328:246 329:247 330:248 331:249 332:249 333:249 334:250 335:251 336:252 337:253 338:254 339:255 340:255 341:255 342:256 343:257 344:258 345:259 346:260 347:261 348:262 349:263 350:264 351:265 352:266 353:266 354:267 355:268 356:269 357:270 358:271 359:272 360:273 361:274 362:275 363:276 364:277 365:278 366:279 367:280 368:281 369:282 370:283 371:283 372:283 373:284 374:285 375:286 376:287 377:287 378:287 379:287 380:288 381:289 382:290 383:291 384:292 385:293 386:294 387:295 388:296 389:297 390:298 391:299 392:300 393:300 394:301 395:302 396:303 397:304 398:305 399:306 400:307 401:308 402:309 403:309 404:310 405:311 406:312 407:312 408:312 409:312 410:312 411:313 412:314 413:315 414:316 415:317 416:318 417:319 418:319 419:320 420:321 421:322 422:323 423:324 424:325 425:326 426:327 427:327 428:327 429:328 430:329 431:329 432:330 433:330 434:331 435:332 436:333 437:334 438:335 439:336 440:337 441:338 442:339 443:340 444:341 445:342 446:343 447:344 448:345 449:346 450:346 451:347 452:348 453:349 454:350 455:351 456:352 457:353 458:354 459:355 460:356 461:357 462:358 463:359 464:360 465:361 466:362 467:363 468:364 469:365 470:366 471:367 472:368 473:369 474:370 475:371 476:372 477:373 478:374 479:375 480:376 481:377 482:378 483:379 484:379\n",
            "I0930 06:59:03.170562 140552314279808 run_squad.py:438] token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:4 17:5 18:6 19:6 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:11 28:12 29:13 30:13 31:13 32:14 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:22 42:23 43:23 44:23 45:24 46:25 47:26 48:27 49:28 50:28 51:28 52:28 53:29 54:30 55:31 56:32 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:40 65:41 66:42 67:42 68:42 69:43 70:43 71:44 72:45 73:46 74:47 75:48 76:49 77:50 78:51 79:52 80:53 81:54 82:54 83:54 84:55 85:56 86:57 87:58 88:59 89:60 90:61 91:62 92:63 93:64 94:65 95:66 96:67 97:68 98:69 99:70 100:71 101:71 102:71 103:71 104:72 105:73 106:74 107:74 108:74 109:74 110:74 111:74 112:75 113:76 114:77 115:77 116:77 117:77 118:78 119:79 120:80 121:81 122:82 123:83 124:84 125:85 126:85 127:85 128:86 129:87 130:88 131:89 132:90 133:91 134:92 135:93 136:94 137:95 138:96 139:97 140:97 141:97 142:98 143:99 144:100 145:100 146:100 147:101 148:102 149:103 150:104 151:105 152:106 153:107 154:107 155:108 156:109 157:110 158:111 159:112 160:112 161:112 162:112 163:113 164:114 165:115 166:116 167:117 168:118 169:119 170:120 171:121 172:122 173:123 174:123 175:123 176:124 177:125 178:126 179:127 180:127 181:128 182:129 183:130 184:131 185:132 186:133 187:134 188:135 189:136 190:137 191:138 192:139 193:140 194:140 195:141 196:142 197:143 198:144 199:145 200:146 201:147 202:148 203:149 204:150 205:151 206:152 207:153 208:154 209:155 210:155 211:155 212:156 213:156 214:156 215:157 216:158 217:159 218:160 219:161 220:162 221:163 222:164 223:165 224:166 225:167 226:168 227:169 228:170 229:171 230:172 231:173 232:174 233:175 234:176 235:177 236:178 237:179 238:179 239:179 240:180 241:180 242:180 243:181 244:182 245:183 246:183 247:183 248:183 249:183 250:184 251:185 252:186 253:187 254:188 255:188 256:188 257:189 258:189 259:190 260:191 261:191 262:191 263:192 264:193 265:194 266:195 267:196 268:197 269:197 270:198 271:199 272:200 273:201 274:202 275:203 276:203 277:203 278:204 279:205 280:206 281:207 282:208 283:209 284:210 285:211 286:212 287:213 288:213 289:213 290:214 291:215 292:216 293:217 294:218 295:219 296:220 297:221 298:222 299:223 300:223 301:223 302:224 303:224 304:224 305:225 306:226 307:227 308:228 309:229 310:230 311:230 312:231 313:232 314:232 315:233 316:234 317:235 318:236 319:237 320:238 321:239 322:240 323:241 324:242 325:243 326:244 327:245 328:246 329:247 330:248 331:249 332:249 333:249 334:250 335:251 336:252 337:253 338:254 339:255 340:255 341:255 342:256 343:257 344:258 345:259 346:260 347:261 348:262 349:263 350:264 351:265 352:266 353:266 354:267 355:268 356:269 357:270 358:271 359:272 360:273 361:274 362:275 363:276 364:277 365:278 366:279 367:280 368:281 369:282 370:283 371:283 372:283 373:284 374:285 375:286 376:287 377:287 378:287 379:287 380:288 381:289 382:290 383:291 384:292 385:293 386:294 387:295 388:296 389:297 390:298 391:299 392:300 393:300 394:301 395:302 396:303 397:304 398:305 399:306 400:307 401:308 402:309 403:309 404:310 405:311 406:312 407:312 408:312 409:312 410:312 411:313 412:314 413:315 414:316 415:317 416:318 417:319 418:319 419:320 420:321 421:322 422:323 423:324 424:325 425:326 426:327 427:327 428:327 429:328 430:329 431:329 432:330 433:330 434:331 435:332 436:333 437:334 438:335 439:336 440:337 441:338 442:339 443:340 444:341 445:342 446:343 447:344 448:345 449:346 450:346 451:347 452:348 453:349 454:350 455:351 456:352 457:353 458:354 459:355 460:356 461:357 462:358 463:359 464:360 465:361 466:362 467:363 468:364 469:365 470:366 471:367 472:368 473:369 474:370 475:371 476:372 477:373 478:374 479:375 480:376 481:377 482:378 483:379 484:379\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True 471:True 472:True 473:True 474:True 475:True 476:True 477:True 478:True 479:True 480:True 481:True 482:True 483:True 484:True\n",
            "I0930 06:59:03.170945 140552314279808 run_squad.py:440] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True 471:True 472:True 473:True 474:True 475:True 476:True 477:True 478:True 479:True 480:True 481:True 482:True 483:True 484:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2001 2115 2535 1999 18368 1011 15895 1029 102 2009 2001 1037 9391 7596 1010 2170 18368 1011 15895 1010 2081 2012 9274 1012 1999 1996 10494 18368 1011 15895 4888 1010 1045 2001 1999 3715 1997 7596 8346 1998 3808 1012 2044 1996 3144 4888 1997 18368 1011 15895 1010 2002 4900 2000 3745 2007 2149 2010 3959 1997 2019 2796 5871 4888 4316 1012 2852 11655 14227 22233 2209 1037 2200 2590 2535 1999 20300 2026 4105 4813 1012 2048 1997 2026 8628 2040 2209 1037 2200 3161 1998 10232 2535 1999 2023 4888 2020 1040 19413 26760 4232 3022 1998 1054 19027 3567 12274 7847 1012 1045 13155 1996 2712 1011 8301 25057 2535 1997 1996 4563 4316 2000 5902 11026 1012 2169 3265 6492 2006 2023 3376 4774 2003 2580 2011 2643 2000 11865 10270 4014 1037 3327 2535 1012 2002 5577 1996 2535 1997 28036 2796 6529 1010 2107 2004 2852 29063 7354 22655 2072 1010 1998 1997 1996 4325 1997 1037 14206 2897 1997 2470 4896 1012 2037 4432 2001 2200 3154 1024 2065 6505 2020 2000 2377 1037 15902 2535 1999 1996 2451 1997 3741 1010 2027 2442 2022 2117 2000 3904 1999 1996 4646 1997 3935 6786 2000 2037 2613 1011 2166 3471 1012 2023 6581 5911 2209 1037 25449 2535 2008 2106 2025 8339 2049 4493 2030 4022 9859 2030 2130 13883 1996 10908 1999 2148 3796 1012 2023 4937 20265 26910 2085 3544 2512 5054 19570 2389 1010 2004 1996 2149 2250 2486 1005 1055 2598 1011 3390 3419 23278 26291 2003 2109 1999 1037 8608 2535 1010 26206 2049 2846 1997 2070 2463 1012 1045 2036 3881 2037 3086 2000 1996 10232 2535 2008 6351 1011 6351 1998 2060 3935 12490 4475 2377 1999 11495 1996 2128 1011 4443 2974 1012 2002 5577 1996 11785 1997 2010 2879 9021 1998 3360 1010 5026 4142 10126 2166 1999 1037 2235 2237 1999 2148 2634 1998 1996 28676 2535 1997 19156 1012 1037 10232 7814 1997 1996 2136 3003 1005 1055 2535 2003 2000 13676 2007 2122 3145 2111 2005 2037 5918 1010 1998 2000 5676 2008 1996 7982 4247 2006 1037 3180 3978 2004 1996 3663 11791 2030 3431 1012 1045 2097 2025 2022 3653 17421 13876 8918 2438 2000 2360 2008 2026 2166 2064 2022 1037 2535 2944 2005 10334 1025 2021 2070 3532 2775 2542 1999 2019 14485 2173 1010 1999 2019 2104 18098 12848 9463 5999 2591 4292 2089 2424 1037 2210 14017 10732 1999 1996 2126 2026 10461 2038 2042 5044 1012 6229 1996 12943 3490 4888 1010 1996 2796 4273 2749 2018 2042 14336 2005 1037 9975 5600 2535 2000 28805 2256 3842 1010 2000 6099 2256 3537 6194 2013 1996 29083 1999 1996 3032 2105 2149 1998 2000 5333 1996 3465 1997 2151 6327 8830 2000 2019 21873 2504 2005 3032 2029 2089 20432 2107 21951 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.263248 140552314279808 run_squad.py:442] input_ids: 101 2054 2001 2115 2535 1999 18368 1011 15895 1029 102 2009 2001 1037 9391 7596 1010 2170 18368 1011 15895 1010 2081 2012 9274 1012 1999 1996 10494 18368 1011 15895 4888 1010 1045 2001 1999 3715 1997 7596 8346 1998 3808 1012 2044 1996 3144 4888 1997 18368 1011 15895 1010 2002 4900 2000 3745 2007 2149 2010 3959 1997 2019 2796 5871 4888 4316 1012 2852 11655 14227 22233 2209 1037 2200 2590 2535 1999 20300 2026 4105 4813 1012 2048 1997 2026 8628 2040 2209 1037 2200 3161 1998 10232 2535 1999 2023 4888 2020 1040 19413 26760 4232 3022 1998 1054 19027 3567 12274 7847 1012 1045 13155 1996 2712 1011 8301 25057 2535 1997 1996 4563 4316 2000 5902 11026 1012 2169 3265 6492 2006 2023 3376 4774 2003 2580 2011 2643 2000 11865 10270 4014 1037 3327 2535 1012 2002 5577 1996 2535 1997 28036 2796 6529 1010 2107 2004 2852 29063 7354 22655 2072 1010 1998 1997 1996 4325 1997 1037 14206 2897 1997 2470 4896 1012 2037 4432 2001 2200 3154 1024 2065 6505 2020 2000 2377 1037 15902 2535 1999 1996 2451 1997 3741 1010 2027 2442 2022 2117 2000 3904 1999 1996 4646 1997 3935 6786 2000 2037 2613 1011 2166 3471 1012 2023 6581 5911 2209 1037 25449 2535 2008 2106 2025 8339 2049 4493 2030 4022 9859 2030 2130 13883 1996 10908 1999 2148 3796 1012 2023 4937 20265 26910 2085 3544 2512 5054 19570 2389 1010 2004 1996 2149 2250 2486 1005 1055 2598 1011 3390 3419 23278 26291 2003 2109 1999 1037 8608 2535 1010 26206 2049 2846 1997 2070 2463 1012 1045 2036 3881 2037 3086 2000 1996 10232 2535 2008 6351 1011 6351 1998 2060 3935 12490 4475 2377 1999 11495 1996 2128 1011 4443 2974 1012 2002 5577 1996 11785 1997 2010 2879 9021 1998 3360 1010 5026 4142 10126 2166 1999 1037 2235 2237 1999 2148 2634 1998 1996 28676 2535 1997 19156 1012 1037 10232 7814 1997 1996 2136 3003 1005 1055 2535 2003 2000 13676 2007 2122 3145 2111 2005 2037 5918 1010 1998 2000 5676 2008 1996 7982 4247 2006 1037 3180 3978 2004 1996 3663 11791 2030 3431 1012 1045 2097 2025 2022 3653 17421 13876 8918 2438 2000 2360 2008 2026 2166 2064 2022 1037 2535 2944 2005 10334 1025 2021 2070 3532 2775 2542 1999 2019 14485 2173 1010 1999 2019 2104 18098 12848 9463 5999 2591 4292 2089 2424 1037 2210 14017 10732 1999 1996 2126 2026 10461 2038 2042 5044 1012 6229 1996 12943 3490 4888 1010 1996 2796 4273 2749 2018 2042 14336 2005 1037 9975 5600 2535 2000 28805 2256 3842 1010 2000 6099 2256 3537 6194 2013 1996 29083 1999 1996 3032 2105 2149 1998 2000 5333 1996 3465 1997 2151 6327 8830 2000 2019 21873 2504 2005 3032 2029 2089 20432 2107 21951 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.263745 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.264106 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.276481 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000010\n",
            "I0930 06:59:03.276718 140552314279808 run_squad.py:432] unique_id: 1000000010\n",
            "INFO:tensorflow:example_index: 10\n",
            "I0930 06:59:03.276791 140552314279808 run_squad.py:433] example_index: 10\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.276847 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what are sounding rockets used for ? [SEP] the development of these rockets had resulted in a fully indigenous capability in the production of sounding rockets as well as their prop ##ellant ##s . under this programme , a family of operational sounding rockets were developed . sounding rockets are normally used for probing the near - earth environment , including the upper regions of the atmosphere . in june , we used the cent ##aur sounding rocket launch to test some of our critical systems . the rs ##r programme was responsible for the development and fabrication of sounding rockets and their associated on - board systems for scientific investigations in india . until then the indian space programme had not gone beyond sounding rockets and even knowledge ##able people were not ready to see and acknowledge its efforts as anything more serious than fi ##ddling around with meteorological instruments . we made high - strength glass cloth lam ##inates to build non - magnetic payload housing ##s and flew them in two - stage sounding rockets . these rockets had wide ranging capabilities , and to date several hundreds of these rockets have been launched for various scientific and technological studies . when tip ##u sultan was killed , the british captured more than rockets and sub ##systems of rockets in the battle of tu ##ru ##khan ##aha ##lly in . in fact , they are three different kinds of rockets . this place was the base for nasa ' s sounding rocket programme . what is it that distinguishes a sounding rocket from a satellite launch vehicle ( sl ##v ) and from a missile ? that it would not be used was something beyond my comprehension . as participants in the sl ##v - project , we set three milestone ##s for ourselves : development and flight qualification of all sub ##systems through sounding rockets by ; sub - orbital flights by ; and the final orbital flight in . it was a sounding rocket , called nike - apache , made at nasa . because the distinction is more decisive in rocket engines , the term prop ##ellant is used primarily to describe chemicals carried by rockets for prop ##ulsive purposes . in the development of payload ##s for the sounding rockets , instead of getting a certain payload and then engineering it to fit into the rocket , we discussed the matter thread ##bar ##e with the payload scientists working in different organ - i ##zation ##s and at different locations . slowly , but surely , two indian rockets were born at thumb ##a . narayan ##an used to needle me . we would make our own rockets , our own satellite launch vehicles ( sl ##vs ) and our own satellites . [SEP]\n",
            "I0930 06:59:03.277027 140552314279808 run_squad.py:436] tokens: [CLS] what are sounding rockets used for ? [SEP] the development of these rockets had resulted in a fully indigenous capability in the production of sounding rockets as well as their prop ##ellant ##s . under this programme , a family of operational sounding rockets were developed . sounding rockets are normally used for probing the near - earth environment , including the upper regions of the atmosphere . in june , we used the cent ##aur sounding rocket launch to test some of our critical systems . the rs ##r programme was responsible for the development and fabrication of sounding rockets and their associated on - board systems for scientific investigations in india . until then the indian space programme had not gone beyond sounding rockets and even knowledge ##able people were not ready to see and acknowledge its efforts as anything more serious than fi ##ddling around with meteorological instruments . we made high - strength glass cloth lam ##inates to build non - magnetic payload housing ##s and flew them in two - stage sounding rockets . these rockets had wide ranging capabilities , and to date several hundreds of these rockets have been launched for various scientific and technological studies . when tip ##u sultan was killed , the british captured more than rockets and sub ##systems of rockets in the battle of tu ##ru ##khan ##aha ##lly in . in fact , they are three different kinds of rockets . this place was the base for nasa ' s sounding rocket programme . what is it that distinguishes a sounding rocket from a satellite launch vehicle ( sl ##v ) and from a missile ? that it would not be used was something beyond my comprehension . as participants in the sl ##v - project , we set three milestone ##s for ourselves : development and flight qualification of all sub ##systems through sounding rockets by ; sub - orbital flights by ; and the final orbital flight in . it was a sounding rocket , called nike - apache , made at nasa . because the distinction is more decisive in rocket engines , the term prop ##ellant is used primarily to describe chemicals carried by rockets for prop ##ulsive purposes . in the development of payload ##s for the sounding rockets , instead of getting a certain payload and then engineering it to fit into the rocket , we discussed the matter thread ##bar ##e with the payload scientists working in different organ - i ##zation ##s and at different locations . slowly , but surely , two indian rockets were born at thumb ##a . narayan ##an used to needle me . we would make our own rockets , our own satellite launch vehicles ( sl ##vs ) and our own satellites . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:19 29:20 30:21 31:22 32:22 33:22 34:22 35:22 36:23 37:24 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:40 58:40 59:41 60:41 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:48 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:64 88:64 89:65 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:74 100:75 101:76 102:77 103:78 104:79 105:80 106:80 107:80 108:81 109:82 110:83 111:84 112:85 113:86 114:86 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:99 129:100 130:100 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:109 140:110 141:111 142:112 143:113 144:114 145:115 146:116 147:116 148:117 149:118 150:119 151:120 152:120 153:120 154:121 155:122 156:122 157:123 158:124 159:125 160:126 161:126 162:127 163:128 164:129 165:129 166:129 167:130 168:131 169:131 170:132 171:133 172:134 173:135 174:136 175:136 176:136 177:137 178:138 179:138 180:138 181:139 182:140 183:141 184:142 185:143 186:143 187:144 188:145 189:146 190:147 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:157 201:158 202:159 203:160 204:160 205:160 206:161 207:161 208:162 209:163 210:164 211:164 212:165 213:166 214:167 215:168 216:169 217:170 218:171 219:172 220:172 221:173 222:174 223:175 224:176 225:177 226:178 227:179 228:179 229:179 230:179 231:179 232:180 233:181 234:181 235:182 236:182 237:183 238:184 239:185 240:186 241:187 242:188 243:189 244:189 245:189 246:190 247:191 248:192 249:193 250:194 251:195 252:195 253:195 254:196 255:197 256:198 257:198 258:198 259:199 260:200 261:201 262:202 263:203 264:204 265:205 266:206 267:207 268:208 269:209 270:210 271:211 272:211 273:211 274:211 275:212 276:213 277:214 278:215 279:215 280:215 281:216 282:217 283:218 284:219 285:220 286:221 287:222 288:223 289:224 290:225 291:225 292:225 293:226 294:227 295:228 296:229 297:229 298:229 299:230 300:230 301:231 302:232 303:233 304:234 305:234 306:235 307:236 308:236 309:237 310:238 311:239 312:240 313:241 314:242 315:243 316:243 317:244 318:245 319:246 320:247 321:248 322:249 323:249 324:249 325:250 326:251 327:252 328:253 329:254 330:255 331:256 332:257 333:258 334:259 335:259 336:260 337:261 338:262 339:263 340:263 341:264 342:265 343:265 344:266 345:266 346:267 347:268 348:269 349:269 350:269 351:270 352:271 353:272 354:273 355:274 356:275 357:276 358:277 359:277 360:278 361:279 362:280 363:280 364:281 365:282 366:283 367:284 368:285 369:286 370:287 371:288 372:289 373:290 374:291 375:291 376:292 377:292 378:292 379:293 380:294 381:295 382:296 383:296 384:297 385:298 386:299 387:300 388:300 389:301 390:302 391:303 392:304 393:305 394:306 395:307 396:308 397:309 398:310 399:311 400:312 401:313 402:314 403:315 404:315 405:316 406:317 407:318 408:319 409:320 410:320 411:320 412:321 413:322 414:323 415:324 416:325 417:326 418:327 419:328 420:328 421:328 422:328 423:328 424:329 425:330 426:331 427:332 428:332 429:332 430:332 431:333 432:334 433:334 434:335 435:336 436:337 437:338 438:339 439:340 440:341 441:341 442:341 443:341 444:341 445:342 446:343 447:344 448:345 449:345 450:345 451:346 452:347 453:348 454:349 455:350 456:350 457:351 458:352 459:353 460:354 461:355 462:356 463:356 464:356 465:356 466:357 467:358 468:359 469:360 470:360\n",
            "I0930 06:59:03.363163 140552314279808 run_squad.py:438] token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:19 29:20 30:21 31:22 32:22 33:22 34:22 35:22 36:23 37:24 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:40 58:40 59:41 60:41 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:48 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:64 88:64 89:65 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:74 100:75 101:76 102:77 103:78 104:79 105:80 106:80 107:80 108:81 109:82 110:83 111:84 112:85 113:86 114:86 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:99 129:100 130:100 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:109 140:110 141:111 142:112 143:113 144:114 145:115 146:116 147:116 148:117 149:118 150:119 151:120 152:120 153:120 154:121 155:122 156:122 157:123 158:124 159:125 160:126 161:126 162:127 163:128 164:129 165:129 166:129 167:130 168:131 169:131 170:132 171:133 172:134 173:135 174:136 175:136 176:136 177:137 178:138 179:138 180:138 181:139 182:140 183:141 184:142 185:143 186:143 187:144 188:145 189:146 190:147 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:157 201:158 202:159 203:160 204:160 205:160 206:161 207:161 208:162 209:163 210:164 211:164 212:165 213:166 214:167 215:168 216:169 217:170 218:171 219:172 220:172 221:173 222:174 223:175 224:176 225:177 226:178 227:179 228:179 229:179 230:179 231:179 232:180 233:181 234:181 235:182 236:182 237:183 238:184 239:185 240:186 241:187 242:188 243:189 244:189 245:189 246:190 247:191 248:192 249:193 250:194 251:195 252:195 253:195 254:196 255:197 256:198 257:198 258:198 259:199 260:200 261:201 262:202 263:203 264:204 265:205 266:206 267:207 268:208 269:209 270:210 271:211 272:211 273:211 274:211 275:212 276:213 277:214 278:215 279:215 280:215 281:216 282:217 283:218 284:219 285:220 286:221 287:222 288:223 289:224 290:225 291:225 292:225 293:226 294:227 295:228 296:229 297:229 298:229 299:230 300:230 301:231 302:232 303:233 304:234 305:234 306:235 307:236 308:236 309:237 310:238 311:239 312:240 313:241 314:242 315:243 316:243 317:244 318:245 319:246 320:247 321:248 322:249 323:249 324:249 325:250 326:251 327:252 328:253 329:254 330:255 331:256 332:257 333:258 334:259 335:259 336:260 337:261 338:262 339:263 340:263 341:264 342:265 343:265 344:266 345:266 346:267 347:268 348:269 349:269 350:269 351:270 352:271 353:272 354:273 355:274 356:275 357:276 358:277 359:277 360:278 361:279 362:280 363:280 364:281 365:282 366:283 367:284 368:285 369:286 370:287 371:288 372:289 373:290 374:291 375:291 376:292 377:292 378:292 379:293 380:294 381:295 382:296 383:296 384:297 385:298 386:299 387:300 388:300 389:301 390:302 391:303 392:304 393:305 394:306 395:307 396:308 397:309 398:310 399:311 400:312 401:313 402:314 403:315 404:315 405:316 406:317 407:318 408:319 409:320 410:320 411:320 412:321 413:322 414:323 415:324 416:325 417:326 418:327 419:328 420:328 421:328 422:328 423:328 424:329 425:330 426:331 427:332 428:332 429:332 430:332 431:333 432:334 433:334 434:335 435:336 436:337 437:338 438:339 439:340 440:341 441:341 442:341 443:341 444:341 445:342 446:343 447:344 448:345 449:345 450:345 451:346 452:347 453:348 454:349 455:350 456:350 457:351 458:352 459:353 460:354 461:355 462:356 463:356 464:356 465:356 466:357 467:358 468:359 469:360 470:360\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True\n",
            "I0930 06:59:03.363438 140552314279808 run_squad.py:440] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2024 9391 12496 2109 2005 1029 102 1996 2458 1997 2122 12496 2018 4504 1999 1037 3929 6284 10673 1999 1996 2537 1997 9391 12496 2004 2092 2004 2037 17678 24178 2015 1012 2104 2023 4746 1010 1037 2155 1997 6515 9391 12496 2020 2764 1012 9391 12496 2024 5373 2109 2005 28664 1996 2379 1011 3011 4044 1010 2164 1996 3356 4655 1997 1996 7224 1012 1999 2238 1010 2057 2109 1996 9358 21159 9391 7596 4888 2000 3231 2070 1997 2256 4187 3001 1012 1996 12667 2099 4746 2001 3625 2005 1996 2458 1998 25884 1997 9391 12496 1998 2037 3378 2006 1011 2604 3001 2005 4045 9751 1999 2634 1012 2127 2059 1996 2796 2686 4746 2018 2025 2908 3458 9391 12496 1998 2130 3716 3085 2111 2020 2025 3201 2000 2156 1998 13399 2049 4073 2004 2505 2062 3809 2084 10882 21814 2105 2007 20557 5693 1012 2057 2081 2152 1011 3997 3221 8416 16983 28184 2000 3857 2512 1011 8060 18093 3847 2015 1998 5520 2068 1999 2048 1011 2754 9391 12496 1012 2122 12496 2018 2898 7478 9859 1010 1998 2000 3058 2195 5606 1997 2122 12496 2031 2042 3390 2005 2536 4045 1998 10660 2913 1012 2043 5955 2226 7544 2001 2730 1010 1996 2329 4110 2062 2084 12496 1998 4942 29390 1997 12496 1999 1996 2645 1997 10722 6820 26370 23278 9215 1999 1012 1999 2755 1010 2027 2024 2093 2367 7957 1997 12496 1012 2023 2173 2001 1996 2918 2005 9274 1005 1055 9391 7596 4746 1012 2054 2003 2009 2008 27343 1037 9391 7596 2013 1037 5871 4888 4316 1006 22889 2615 1007 1998 2013 1037 7421 1029 2008 2009 2052 2025 2022 2109 2001 2242 3458 2026 26683 1012 2004 6818 1999 1996 22889 2615 1011 2622 1010 2057 2275 2093 19199 2015 2005 9731 1024 2458 1998 3462 8263 1997 2035 4942 29390 2083 9391 12496 2011 1025 4942 1011 13943 7599 2011 1025 1998 1996 2345 13943 3462 1999 1012 2009 2001 1037 9391 7596 1010 2170 18368 1011 15895 1010 2081 2012 9274 1012 2138 1996 7835 2003 2062 13079 1999 7596 5209 1010 1996 2744 17678 24178 2003 2109 3952 2000 6235 12141 3344 2011 12496 2005 17678 23004 5682 1012 1999 1996 2458 1997 18093 2015 2005 1996 9391 12496 1010 2612 1997 2893 1037 3056 18093 1998 2059 3330 2009 2000 4906 2046 1996 7596 1010 2057 6936 1996 3043 11689 8237 2063 2007 1996 18093 6529 2551 1999 2367 5812 1011 1045 9276 2015 1998 2012 2367 5269 1012 3254 1010 2021 7543 1010 2048 2796 12496 2020 2141 2012 7639 2050 1012 24331 2319 2109 2000 12201 2033 1012 2057 2052 2191 2256 2219 12496 1010 2256 2219 5871 4888 4683 1006 22889 15088 1007 1998 2256 2219 14549 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.466017 140552314279808 run_squad.py:442] input_ids: 101 2054 2024 9391 12496 2109 2005 1029 102 1996 2458 1997 2122 12496 2018 4504 1999 1037 3929 6284 10673 1999 1996 2537 1997 9391 12496 2004 2092 2004 2037 17678 24178 2015 1012 2104 2023 4746 1010 1037 2155 1997 6515 9391 12496 2020 2764 1012 9391 12496 2024 5373 2109 2005 28664 1996 2379 1011 3011 4044 1010 2164 1996 3356 4655 1997 1996 7224 1012 1999 2238 1010 2057 2109 1996 9358 21159 9391 7596 4888 2000 3231 2070 1997 2256 4187 3001 1012 1996 12667 2099 4746 2001 3625 2005 1996 2458 1998 25884 1997 9391 12496 1998 2037 3378 2006 1011 2604 3001 2005 4045 9751 1999 2634 1012 2127 2059 1996 2796 2686 4746 2018 2025 2908 3458 9391 12496 1998 2130 3716 3085 2111 2020 2025 3201 2000 2156 1998 13399 2049 4073 2004 2505 2062 3809 2084 10882 21814 2105 2007 20557 5693 1012 2057 2081 2152 1011 3997 3221 8416 16983 28184 2000 3857 2512 1011 8060 18093 3847 2015 1998 5520 2068 1999 2048 1011 2754 9391 12496 1012 2122 12496 2018 2898 7478 9859 1010 1998 2000 3058 2195 5606 1997 2122 12496 2031 2042 3390 2005 2536 4045 1998 10660 2913 1012 2043 5955 2226 7544 2001 2730 1010 1996 2329 4110 2062 2084 12496 1998 4942 29390 1997 12496 1999 1996 2645 1997 10722 6820 26370 23278 9215 1999 1012 1999 2755 1010 2027 2024 2093 2367 7957 1997 12496 1012 2023 2173 2001 1996 2918 2005 9274 1005 1055 9391 7596 4746 1012 2054 2003 2009 2008 27343 1037 9391 7596 2013 1037 5871 4888 4316 1006 22889 2615 1007 1998 2013 1037 7421 1029 2008 2009 2052 2025 2022 2109 2001 2242 3458 2026 26683 1012 2004 6818 1999 1996 22889 2615 1011 2622 1010 2057 2275 2093 19199 2015 2005 9731 1024 2458 1998 3462 8263 1997 2035 4942 29390 2083 9391 12496 2011 1025 4942 1011 13943 7599 2011 1025 1998 1996 2345 13943 3462 1999 1012 2009 2001 1037 9391 7596 1010 2170 18368 1011 15895 1010 2081 2012 9274 1012 2138 1996 7835 2003 2062 13079 1999 7596 5209 1010 1996 2744 17678 24178 2003 2109 3952 2000 6235 12141 3344 2011 12496 2005 17678 23004 5682 1012 1999 1996 2458 1997 18093 2015 2005 1996 9391 12496 1010 2612 1997 2893 1037 3056 18093 1998 2059 3330 2009 2000 4906 2046 1996 7596 1010 2057 6936 1996 3043 11689 8237 2063 2007 1996 18093 6529 2551 1999 2367 5812 1011 1045 9276 2015 1998 2012 2367 5269 1012 3254 1010 2021 7543 1010 2048 2796 12496 2020 2141 2012 7639 2050 1012 24331 2319 2109 2000 12201 2033 1012 2057 2052 2191 2256 2219 12496 1010 2256 2219 5871 4888 4683 1006 22889 15088 1007 1998 2256 2219 14549 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.466492 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.466802 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.472785 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000011\n",
            "I0930 06:59:03.472991 140552314279808 run_squad.py:432] unique_id: 1000000011\n",
            "INFO:tensorflow:example_index: 11\n",
            "I0930 06:59:03.473057 140552314279808 run_squad.py:433] example_index: 11\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.473126 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] are you religious ? [SEP] religious conquest ##s continued . the value system in which i had been nur ##ture ##d was profoundly religious . rules and policies are to be followed with religious fe ##r ##vo ##ur . i have always been a religious person in the sense that i maintain a working partnership with god . as children , none of us ever felt any difference amongst ourselves because of our religious differences and upbringing . in addition , there was the delicate matter of acquiring a site of religious significance . with the passage of time , wars were wage ##d over religious and ideological beliefs ; and now the dominant struggle of sophisticated warfare is for economic and technological supremacy . [SEP]\n",
            "I0930 06:59:03.473219 140552314279808 run_squad.py:436] tokens: [CLS] are you religious ? [SEP] religious conquest ##s continued . the value system in which i had been nur ##ture ##d was profoundly religious . rules and policies are to be followed with religious fe ##r ##vo ##ur . i have always been a religious person in the sense that i maintain a working partnership with god . as children , none of us ever felt any difference amongst ourselves because of our religious differences and upbringing . in addition , there was the delicate matter of acquiring a site of religious significance . with the passage of time , wars were wage ##d over religious and ideological beliefs ; and now the dominant struggle of sophisticated warfare is for economic and technological supremacy . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:0 7:1 8:1 9:2 10:2 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:10 21:10 22:11 23:12 24:13 25:13 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:22 37:22 38:22 39:22 40:22 41:23 42:24 43:25 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:39 59:39 60:40 61:40 62:41 63:42 64:43 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:56 79:56 80:57 81:57 82:58 83:59 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:69 95:69 96:70 97:71 98:72 99:73 100:73 101:74 102:75 103:76 104:76 105:77 106:78 107:79 108:80 109:81 110:81 111:82 112:83 113:84 114:85 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:95\n",
            "I0930 06:59:03.565455 140552314279808 run_squad.py:438] token_to_orig_map: 6:0 7:1 8:1 9:2 10:2 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:10 21:10 22:11 23:12 24:13 25:13 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:22 37:22 38:22 39:22 40:22 41:23 42:24 43:25 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:39 59:39 60:40 61:40 62:41 63:42 64:43 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:56 79:56 80:57 81:57 82:58 83:59 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:69 95:69 96:70 97:71 98:72 99:73 100:73 101:74 102:75 103:76 104:76 105:77 106:78 107:79 108:80 109:81 110:81 111:82 112:83 113:84 114:85 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:95\n",
            "INFO:tensorflow:token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True\n",
            "I0930 06:59:03.565616 140552314279808 run_squad.py:440] token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True\n",
            "INFO:tensorflow:input_ids: 101 2024 2017 3412 1029 102 3412 9187 2015 2506 1012 1996 3643 2291 1999 2029 1045 2018 2042 27617 11244 2094 2001 28089 3412 1012 3513 1998 6043 2024 2000 2022 2628 2007 3412 10768 2099 6767 3126 1012 1045 2031 2467 2042 1037 3412 2711 1999 1996 3168 2008 1045 5441 1037 2551 5386 2007 2643 1012 2004 2336 1010 3904 1997 2149 2412 2371 2151 4489 5921 9731 2138 1997 2256 3412 5966 1998 24615 1012 1999 2804 1010 2045 2001 1996 10059 3043 1997 13868 1037 2609 1997 3412 7784 1012 2007 1996 6019 1997 2051 1010 5233 2020 11897 2094 2058 3412 1998 17859 9029 1025 1998 2085 1996 7444 5998 1997 12138 8309 2003 2005 3171 1998 10660 22006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.565815 140552314279808 run_squad.py:442] input_ids: 101 2024 2017 3412 1029 102 3412 9187 2015 2506 1012 1996 3643 2291 1999 2029 1045 2018 2042 27617 11244 2094 2001 28089 3412 1012 3513 1998 6043 2024 2000 2022 2628 2007 3412 10768 2099 6767 3126 1012 1045 2031 2467 2042 1037 3412 2711 1999 1996 3168 2008 1045 5441 1037 2551 5386 2007 2643 1012 2004 2336 1010 3904 1997 2149 2412 2371 2151 4489 5921 9731 2138 1997 2256 3412 5966 1998 24615 1012 1999 2804 1010 2045 2001 1996 10059 3043 1997 13868 1037 2609 1997 3412 7784 1012 2007 1996 6019 1997 2051 1010 5233 2020 11897 2094 2058 3412 1998 17859 9029 1025 1998 2085 1996 7444 5998 1997 12138 8309 2003 2005 3171 1998 10660 22006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.565976 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.566129 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.578529 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000012\n",
            "I0930 06:59:03.578920 140552314279808 run_squad.py:432] unique_id: 1000000012\n",
            "INFO:tensorflow:example_index: 12\n",
            "I0930 06:59:03.579032 140552314279808 run_squad.py:433] example_index: 12\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.579094 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who is indira gandhi ? [SEP] we were to meet the prime minister , mrs indira gandhi . prime minister indira gandhi cable ##d her congratulations . prime minister indira gandhi was a person with a tremendous sense of pride — in herself , in her work and in her country . prime minister indira gandhi expressed her desire to personally app ##rise herself of the progress of the i ##gm ##dp . in february , prime minister indira gandhi visited thumb ##a to de ##dicate ter ##ls to the international space science community . shri ##mat ##i gandhi asked . prime minister indira gandhi told parliament on july , \" the development and fabrication of relevant technologies , sub ##systems and hardware ( to make india ' s first satellite launch vehicle ) are progressing sat ##is ##fa ##ctor ##ily . madam gandhi was a task ##master , whereas prime minister raj ##iv gandhi used his char ##ism ##a to achieve his ends . on july , shri ##mat ##i gandhi visited dr ##dl . ag ##ni was the conclusion of a technological effort that was given its start by prime minister indira gandhi when the country decided to break free from the para ##ly ##sing fe ##tters of technological backward ##ness and sl ##ough off the dead skin of sub ##ord ##ination to industrial ##ized nations . the circumstances of shri ##mat ##i gandhi ' s death were very ominous . shri ##mat ##i gandhi ' s follow - up approach was not only impressive , it was effective too . her son , raj ##iv gandhi , took over as the new prime minister of india . suddenly , i saw shri ##mat ##i gandhi smiling at me as she said , \" kala ##m ! shri ##mat ##i gandhi ' s death was a tremendous loss to the scientific community . shri ##mat ##i gandhi spoke to the members about the success of the sl ##v - and lauded our achievement . we were working on the action plan that had emerged from the earlier month ' s review , when the news of shri ##mat ##i gandhi ' s assassination broke . prime minister raj ##iv gandhi laid the foundation stone of the research centre im ##arat ( rc ##i ) on august . i consider prof . sara ##bha ##i as the maha ##tma gandhi of indian science — generating leadership qualities in his team and inspiring them through both ideas and example . always encouraged to follow buddha ' s or gandhi ' s teachings , how and why did india become a missile power is a question that needs to be answered for future generations . [SEP]\n",
            "I0930 06:59:03.579286 140552314279808 run_squad.py:436] tokens: [CLS] who is indira gandhi ? [SEP] we were to meet the prime minister , mrs indira gandhi . prime minister indira gandhi cable ##d her congratulations . prime minister indira gandhi was a person with a tremendous sense of pride — in herself , in her work and in her country . prime minister indira gandhi expressed her desire to personally app ##rise herself of the progress of the i ##gm ##dp . in february , prime minister indira gandhi visited thumb ##a to de ##dicate ter ##ls to the international space science community . shri ##mat ##i gandhi asked . prime minister indira gandhi told parliament on july , \" the development and fabrication of relevant technologies , sub ##systems and hardware ( to make india ' s first satellite launch vehicle ) are progressing sat ##is ##fa ##ctor ##ily . madam gandhi was a task ##master , whereas prime minister raj ##iv gandhi used his char ##ism ##a to achieve his ends . on july , shri ##mat ##i gandhi visited dr ##dl . ag ##ni was the conclusion of a technological effort that was given its start by prime minister indira gandhi when the country decided to break free from the para ##ly ##sing fe ##tters of technological backward ##ness and sl ##ough off the dead skin of sub ##ord ##ination to industrial ##ized nations . the circumstances of shri ##mat ##i gandhi ' s death were very ominous . shri ##mat ##i gandhi ' s follow - up approach was not only impressive , it was effective too . her son , raj ##iv gandhi , took over as the new prime minister of india . suddenly , i saw shri ##mat ##i gandhi smiling at me as she said , \" kala ##m ! shri ##mat ##i gandhi ' s death was a tremendous loss to the scientific community . shri ##mat ##i gandhi spoke to the members about the success of the sl ##v - and lauded our achievement . we were working on the action plan that had emerged from the earlier month ' s review , when the news of shri ##mat ##i gandhi ' s assassination broke . prime minister raj ##iv gandhi laid the foundation stone of the research centre im ##arat ( rc ##i ) on august . i consider prof . sara ##bha ##i as the maha ##tma gandhi of indian science — generating leadership qualities in his team and inspiring them through both ideas and example . always encouraged to follow buddha ' s or gandhi ' s teachings , how and why did india become a missile power is a question that needs to be answered for future generations . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:6 15:7 16:8 17:9 18:9 19:9 20:10 21:11 22:12 23:13 24:13 25:14 26:15 27:15 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:30 45:31 46:32 47:33 48:34 49:35 50:36 51:37 52:37 53:37 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:46 64:47 65:48 66:49 67:50 68:51 69:52 70:53 71:53 72:53 73:53 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:60 84:61 85:62 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:69 96:69 97:69 98:69 99:70 100:71 101:71 102:71 103:72 104:73 105:74 106:75 107:76 108:77 109:78 110:79 111:79 112:79 113:80 114:81 115:82 116:83 117:84 118:85 119:85 120:86 121:86 122:87 123:88 124:89 125:89 126:90 127:91 128:91 129:91 130:92 131:93 132:94 133:95 134:95 135:96 136:97 137:98 138:98 139:98 140:98 141:98 142:98 143:98 144:99 145:100 146:101 147:102 148:102 149:102 150:103 151:104 152:105 153:106 154:106 155:107 156:108 157:109 158:110 159:110 160:110 161:111 162:112 163:113 164:114 165:114 166:114 167:115 168:116 169:117 170:117 171:117 172:118 173:119 174:120 175:120 176:120 177:120 178:120 179:121 180:122 181:123 182:124 183:125 184:126 185:127 186:128 187:129 188:130 189:131 190:132 191:133 192:134 193:135 194:136 195:137 196:138 197:139 198:140 199:141 200:142 201:143 202:144 203:145 204:146 205:147 206:147 207:147 208:148 209:148 210:149 211:150 212:151 213:151 214:152 215:153 216:153 217:154 218:155 219:156 220:157 221:158 222:159 223:159 224:159 225:160 226:161 227:161 228:162 229:162 230:162 231:163 232:164 233:165 234:165 235:165 236:166 237:166 238:166 239:167 240:168 241:169 242:170 243:170 244:170 245:170 246:170 247:171 248:171 249:171 250:172 251:172 252:172 253:173 254:174 255:175 256:176 257:177 258:177 259:178 260:179 261:180 262:181 263:181 264:181 265:182 266:182 267:183 268:183 269:184 270:184 271:185 272:186 273:187 274:188 275:189 276:190 277:191 278:192 279:193 280:193 281:193 282:193 283:194 284:195 285:196 286:196 287:196 288:197 289:198 290:199 291:200 292:201 293:202 294:203 295:203 296:204 297:204 298:204 299:204 300:204 301:204 302:204 303:205 304:205 305:205 306:206 307:207 308:208 309:209 310:210 311:211 312:212 313:213 314:214 315:214 316:214 317:214 318:214 319:215 320:216 321:217 322:218 323:219 324:220 325:221 326:222 327:223 328:224 329:225 330:225 331:225 332:226 333:227 334:228 335:229 336:229 337:229 338:230 339:231 340:232 341:233 342:234 343:235 344:236 345:237 346:238 347:239 348:240 349:241 350:242 351:242 352:242 353:243 354:243 355:244 356:245 357:246 358:247 359:248 360:248 361:248 362:249 363:249 364:249 365:250 366:251 367:251 368:251 369:252 370:253 371:253 372:254 373:255 374:256 375:257 376:258 377:259 378:260 379:261 380:262 381:263 382:263 383:264 384:264 385:264 386:264 387:265 388:266 389:267 390:267 391:268 392:269 393:269 394:270 395:270 396:270 397:271 398:272 399:273 400:273 401:274 402:275 403:276 404:277 405:278 406:279 407:280 408:281 409:282 410:283 411:284 412:285 413:286 414:287 415:288 416:289 417:290 418:291 419:292 420:292 421:292 422:293 423:294 424:295 425:296 426:296 427:296 428:297 429:298 430:298 431:298 432:299 433:299 434:300 435:301 436:302 437:303 438:304 439:305 440:306 441:307 442:308 443:309 444:310 445:311 446:312 447:313 448:314 449:315 450:316 451:317 452:318 453:319 454:319\n",
            "I0930 06:59:03.667298 140552314279808 run_squad.py:438] token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:6 15:7 16:8 17:9 18:9 19:9 20:10 21:11 22:12 23:13 24:13 25:14 26:15 27:15 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:30 45:31 46:32 47:33 48:34 49:35 50:36 51:37 52:37 53:37 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:46 64:47 65:48 66:49 67:50 68:51 69:52 70:53 71:53 72:53 73:53 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:60 84:61 85:62 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:69 96:69 97:69 98:69 99:70 100:71 101:71 102:71 103:72 104:73 105:74 106:75 107:76 108:77 109:78 110:79 111:79 112:79 113:80 114:81 115:82 116:83 117:84 118:85 119:85 120:86 121:86 122:87 123:88 124:89 125:89 126:90 127:91 128:91 129:91 130:92 131:93 132:94 133:95 134:95 135:96 136:97 137:98 138:98 139:98 140:98 141:98 142:98 143:98 144:99 145:100 146:101 147:102 148:102 149:102 150:103 151:104 152:105 153:106 154:106 155:107 156:108 157:109 158:110 159:110 160:110 161:111 162:112 163:113 164:114 165:114 166:114 167:115 168:116 169:117 170:117 171:117 172:118 173:119 174:120 175:120 176:120 177:120 178:120 179:121 180:122 181:123 182:124 183:125 184:126 185:127 186:128 187:129 188:130 189:131 190:132 191:133 192:134 193:135 194:136 195:137 196:138 197:139 198:140 199:141 200:142 201:143 202:144 203:145 204:146 205:147 206:147 207:147 208:148 209:148 210:149 211:150 212:151 213:151 214:152 215:153 216:153 217:154 218:155 219:156 220:157 221:158 222:159 223:159 224:159 225:160 226:161 227:161 228:162 229:162 230:162 231:163 232:164 233:165 234:165 235:165 236:166 237:166 238:166 239:167 240:168 241:169 242:170 243:170 244:170 245:170 246:170 247:171 248:171 249:171 250:172 251:172 252:172 253:173 254:174 255:175 256:176 257:177 258:177 259:178 260:179 261:180 262:181 263:181 264:181 265:182 266:182 267:183 268:183 269:184 270:184 271:185 272:186 273:187 274:188 275:189 276:190 277:191 278:192 279:193 280:193 281:193 282:193 283:194 284:195 285:196 286:196 287:196 288:197 289:198 290:199 291:200 292:201 293:202 294:203 295:203 296:204 297:204 298:204 299:204 300:204 301:204 302:204 303:205 304:205 305:205 306:206 307:207 308:208 309:209 310:210 311:211 312:212 313:213 314:214 315:214 316:214 317:214 318:214 319:215 320:216 321:217 322:218 323:219 324:220 325:221 326:222 327:223 328:224 329:225 330:225 331:225 332:226 333:227 334:228 335:229 336:229 337:229 338:230 339:231 340:232 341:233 342:234 343:235 344:236 345:237 346:238 347:239 348:240 349:241 350:242 351:242 352:242 353:243 354:243 355:244 356:245 357:246 358:247 359:248 360:248 361:248 362:249 363:249 364:249 365:250 366:251 367:251 368:251 369:252 370:253 371:253 372:254 373:255 374:256 375:257 376:258 377:259 378:260 379:261 380:262 381:263 382:263 383:264 384:264 385:264 386:264 387:265 388:266 389:267 390:267 391:268 392:269 393:269 394:270 395:270 396:270 397:271 398:272 399:273 400:273 401:274 402:275 403:276 404:277 405:278 406:279 407:280 408:281 409:282 410:283 411:284 412:285 413:286 414:287 415:288 416:289 417:290 418:291 419:292 420:292 421:292 422:293 423:294 424:295 425:296 426:296 427:296 428:297 429:298 430:298 431:298 432:299 433:299 434:300 435:301 436:302 437:303 438:304 439:305 440:306 441:307 442:308 443:309 444:310 445:311 446:312 447:313 448:314 449:315 450:316 451:317 452:318 453:319 454:319\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True\n",
            "I0930 06:59:03.668055 140552314279808 run_squad.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 28232 12338 1029 102 2057 2020 2000 3113 1996 3539 2704 1010 3680 28232 12338 1012 3539 2704 28232 12338 5830 2094 2014 23156 1012 3539 2704 28232 12338 2001 1037 2711 2007 1037 14388 3168 1997 6620 1517 1999 2841 1010 1999 2014 2147 1998 1999 2014 2406 1012 3539 2704 28232 12338 5228 2014 4792 2000 7714 10439 29346 2841 1997 1996 5082 1997 1996 1045 21693 18927 1012 1999 2337 1010 3539 2704 28232 12338 4716 7639 2050 2000 2139 16467 28774 4877 2000 1996 2248 2686 2671 2451 1012 14880 18900 2072 12338 2356 1012 3539 2704 28232 12338 2409 3323 2006 2251 1010 1000 1996 2458 1998 25884 1997 7882 6786 1010 4942 29390 1998 8051 1006 2000 2191 2634 1005 1055 2034 5871 4888 4316 1007 2024 27673 2938 2483 7011 16761 6588 1012 21658 12338 2001 1037 4708 8706 1010 6168 3539 2704 11948 12848 12338 2109 2010 25869 2964 2050 2000 6162 2010 4515 1012 2006 2251 1010 14880 18900 2072 12338 4716 2852 19422 1012 12943 3490 2001 1996 7091 1997 1037 10660 3947 2008 2001 2445 2049 2707 2011 3539 2704 28232 12338 2043 1996 2406 2787 2000 3338 2489 2013 1996 11498 2135 7741 10768 24168 1997 10660 8848 2791 1998 22889 10593 2125 1996 2757 3096 1997 4942 8551 12758 2000 3919 3550 3741 1012 1996 6214 1997 14880 18900 2072 12338 1005 1055 2331 2020 2200 23504 1012 14880 18900 2072 12338 1005 1055 3582 1011 2039 3921 2001 2025 2069 8052 1010 2009 2001 4621 2205 1012 2014 2365 1010 11948 12848 12338 1010 2165 2058 2004 1996 2047 3539 2704 1997 2634 1012 3402 1010 1045 2387 14880 18900 2072 12338 5629 2012 2033 2004 2016 2056 1010 1000 26209 2213 999 14880 18900 2072 12338 1005 1055 2331 2001 1037 14388 3279 2000 1996 4045 2451 1012 14880 18900 2072 12338 3764 2000 1996 2372 2055 1996 3112 1997 1996 22889 2615 1011 1998 26507 2256 6344 1012 2057 2020 2551 2006 1996 2895 2933 2008 2018 6003 2013 1996 3041 3204 1005 1055 3319 1010 2043 1996 2739 1997 14880 18900 2072 12338 1005 1055 10102 3631 1012 3539 2704 11948 12848 12338 4201 1996 3192 2962 1997 1996 2470 2803 10047 25879 1006 22110 2072 1007 2006 2257 1012 1045 5136 11268 1012 7354 22655 2072 2004 1996 24404 29418 12338 1997 2796 2671 1517 11717 4105 11647 1999 2010 2136 1998 18988 2068 2083 2119 4784 1998 2742 1012 2467 6628 2000 3582 11903 1005 1055 2030 12338 1005 1055 12209 1010 2129 1998 2339 2106 2634 2468 1037 7421 2373 2003 1037 3160 2008 3791 2000 2022 4660 2005 2925 8213 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.767925 140552314279808 run_squad.py:442] input_ids: 101 2040 2003 28232 12338 1029 102 2057 2020 2000 3113 1996 3539 2704 1010 3680 28232 12338 1012 3539 2704 28232 12338 5830 2094 2014 23156 1012 3539 2704 28232 12338 2001 1037 2711 2007 1037 14388 3168 1997 6620 1517 1999 2841 1010 1999 2014 2147 1998 1999 2014 2406 1012 3539 2704 28232 12338 5228 2014 4792 2000 7714 10439 29346 2841 1997 1996 5082 1997 1996 1045 21693 18927 1012 1999 2337 1010 3539 2704 28232 12338 4716 7639 2050 2000 2139 16467 28774 4877 2000 1996 2248 2686 2671 2451 1012 14880 18900 2072 12338 2356 1012 3539 2704 28232 12338 2409 3323 2006 2251 1010 1000 1996 2458 1998 25884 1997 7882 6786 1010 4942 29390 1998 8051 1006 2000 2191 2634 1005 1055 2034 5871 4888 4316 1007 2024 27673 2938 2483 7011 16761 6588 1012 21658 12338 2001 1037 4708 8706 1010 6168 3539 2704 11948 12848 12338 2109 2010 25869 2964 2050 2000 6162 2010 4515 1012 2006 2251 1010 14880 18900 2072 12338 4716 2852 19422 1012 12943 3490 2001 1996 7091 1997 1037 10660 3947 2008 2001 2445 2049 2707 2011 3539 2704 28232 12338 2043 1996 2406 2787 2000 3338 2489 2013 1996 11498 2135 7741 10768 24168 1997 10660 8848 2791 1998 22889 10593 2125 1996 2757 3096 1997 4942 8551 12758 2000 3919 3550 3741 1012 1996 6214 1997 14880 18900 2072 12338 1005 1055 2331 2020 2200 23504 1012 14880 18900 2072 12338 1005 1055 3582 1011 2039 3921 2001 2025 2069 8052 1010 2009 2001 4621 2205 1012 2014 2365 1010 11948 12848 12338 1010 2165 2058 2004 1996 2047 3539 2704 1997 2634 1012 3402 1010 1045 2387 14880 18900 2072 12338 5629 2012 2033 2004 2016 2056 1010 1000 26209 2213 999 14880 18900 2072 12338 1005 1055 2331 2001 1037 14388 3279 2000 1996 4045 2451 1012 14880 18900 2072 12338 3764 2000 1996 2372 2055 1996 3112 1997 1996 22889 2615 1011 1998 26507 2256 6344 1012 2057 2020 2551 2006 1996 2895 2933 2008 2018 6003 2013 1996 3041 3204 1005 1055 3319 1010 2043 1996 2739 1997 14880 18900 2072 12338 1005 1055 10102 3631 1012 3539 2704 11948 12848 12338 4201 1996 3192 2962 1997 1996 2470 2803 10047 25879 1006 22110 2072 1007 2006 2257 1012 1045 5136 11268 1012 7354 22655 2072 2004 1996 24404 29418 12338 1997 2796 2671 1517 11717 4105 11647 1999 2010 2136 1998 18988 2068 2083 2119 4784 1998 2742 1012 2467 6628 2000 3582 11903 1005 1055 2030 12338 1005 1055 12209 1010 2129 1998 2339 2106 2634 2468 1037 7421 2373 2003 1037 3160 2008 3791 2000 2022 4660 2005 2925 8213 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.768225 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.768419 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.777561 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000013\n",
            "I0930 06:59:03.777776 140552314279808 run_squad.py:432] unique_id: 1000000013\n",
            "INFO:tensorflow:example_index: 13\n",
            "I0930 06:59:03.777844 140552314279808 run_squad.py:433] example_index: 13\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.777901 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who conferred the honorary doctor of science degree on to you ? [SEP] meanwhile , anna university , madras , conferred the honorary degree of doctor of science on me . the same year , i received an honorary degree of doctor of science from the ii ##t , bombay . towards the end of , ja ##dav ##pur university conferred on me the honour of doctor of science at a special con ##vocation . to my delight , the honorary doctorate degree was awarded at a con ##vocation presided over by prof . raja rama ##nna . i was conferred the padma vi ##bh ##ush ##an along with dr arun ##achal ##am . this time he had gone beyond the capabilities of any doctor , care or money . it had been nearly twenty years since i had acquired my degree in aeronautical engineering . \" your visit is enough for me to get well , why bring a doctor and spend money on his fees \" ? it is the ag ##gl ##ome ##rate of all these aspects that decides the degree and quality of a person ' s effort and performance . whenever i learnt about my father ' s indifferent health , i would visit ram ##es ##wara ##m with a good city doctor . every time i did so , he would chi ##de me for my unnecessary concern and lecture me on the expenses incurred on the doctor . in science , reality is that which exists . when i joined the b . sc degree course at st . joseph ' s , i was unaware of any other option for higher education . technology , unlike science , is a group activity . with a post - graduate degree in aeronautical engineering and expertise in mechanical vibrations , sun ##dara ##m was head of the structures group at dr ##dl . if you are a writer who would secretly prefer to be a lawyer or a doctor , your written words will feed but half the hunger of your readers ; if you are a teacher who would rather be a businessman , your instructions will meet but half the need for knowledge of your students ; if you are a scientist who hates science , your performance will satisfy but half the needs of your mission . as i look at it , the path of science can always wind through the heart . gradually , i became aware of the difference between science and technology , between research and development . set ##backs and disappointment ##s have always been and always will be an inherent part of any career , even one in science . i have throughout my life tried to em ##ulate my father in my own world of science and technology . [SEP]\n",
            "I0930 06:59:03.778110 140552314279808 run_squad.py:436] tokens: [CLS] who conferred the honorary doctor of science degree on to you ? [SEP] meanwhile , anna university , madras , conferred the honorary degree of doctor of science on me . the same year , i received an honorary degree of doctor of science from the ii ##t , bombay . towards the end of , ja ##dav ##pur university conferred on me the honour of doctor of science at a special con ##vocation . to my delight , the honorary doctorate degree was awarded at a con ##vocation presided over by prof . raja rama ##nna . i was conferred the padma vi ##bh ##ush ##an along with dr arun ##achal ##am . this time he had gone beyond the capabilities of any doctor , care or money . it had been nearly twenty years since i had acquired my degree in aeronautical engineering . \" your visit is enough for me to get well , why bring a doctor and spend money on his fees \" ? it is the ag ##gl ##ome ##rate of all these aspects that decides the degree and quality of a person ' s effort and performance . whenever i learnt about my father ' s indifferent health , i would visit ram ##es ##wara ##m with a good city doctor . every time i did so , he would chi ##de me for my unnecessary concern and lecture me on the expenses incurred on the doctor . in science , reality is that which exists . when i joined the b . sc degree course at st . joseph ' s , i was unaware of any other option for higher education . technology , unlike science , is a group activity . with a post - graduate degree in aeronautical engineering and expertise in mechanical vibrations , sun ##dara ##m was head of the structures group at dr ##dl . if you are a writer who would secretly prefer to be a lawyer or a doctor , your written words will feed but half the hunger of your readers ; if you are a teacher who would rather be a businessman , your instructions will meet but half the need for knowledge of your students ; if you are a scientist who hates science , your performance will satisfy but half the needs of your mission . as i look at it , the path of science can always wind through the heart . gradually , i became aware of the difference between science and technology , between research and development . set ##backs and disappointment ##s have always been and always will be an inherent part of any career , even one in science . i have throughout my life tried to em ##ulate my father in my own world of science and technology . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 14:0 15:0 16:1 17:2 18:2 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:13 32:13 33:14 34:15 35:15 36:16 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:26 47:27 48:27 49:27 50:28 51:28 52:28 53:29 54:30 55:31 56:32 57:33 58:33 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:47 75:47 76:47 77:48 78:49 79:49 80:50 81:51 82:52 83:53 84:54 85:55 86:56 87:57 88:58 89:58 90:59 91:60 92:61 93:62 94:62 95:63 96:64 97:64 98:64 99:64 100:65 101:66 102:67 103:68 104:69 105:69 106:69 107:69 108:70 109:71 110:72 111:73 112:73 113:73 114:73 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:81 124:82 125:83 126:83 127:84 128:85 129:86 130:86 131:86 132:87 133:88 134:89 135:90 136:91 137:92 138:93 139:94 140:95 141:96 142:97 143:98 144:99 145:100 146:100 147:100 148:100 149:101 150:102 151:103 152:104 153:105 154:106 155:107 156:108 157:108 158:109 159:110 160:111 161:112 162:113 163:114 164:115 165:116 166:117 167:118 168:118 169:118 170:118 171:119 172:120 173:121 174:121 175:121 176:121 177:122 178:123 179:124 180:125 181:126 182:127 183:128 184:129 185:130 186:131 187:132 188:133 189:134 190:134 191:134 192:135 193:136 194:137 195:137 196:137 197:138 198:139 199:140 200:141 201:142 202:142 203:142 204:143 205:144 206:144 207:145 208:146 209:147 210:148 211:148 212:148 213:148 214:149 215:150 216:151 217:152 218:153 219:153 220:153 221:154 222:155 223:156 224:157 225:157 226:158 227:159 228:160 229:160 230:161 231:162 232:163 233:164 234:165 235:166 236:167 237:168 238:169 239:170 240:171 241:172 242:173 243:174 244:175 245:175 246:175 247:176 248:176 249:177 250:178 251:179 252:180 253:181 254:181 255:181 256:182 257:183 258:184 259:185 260:185 261:185 262:186 263:187 264:188 265:189 266:189 267:189 268:189 269:189 270:189 271:190 272:191 273:192 274:193 275:194 276:195 277:196 278:197 279:198 280:199 281:199 282:199 283:199 284:200 285:201 286:201 287:202 288:203 289:204 290:205 291:205 292:205 293:206 294:207 295:207 296:207 297:208 298:209 299:210 300:211 301:212 302:213 303:214 304:215 305:216 306:216 307:217 308:217 309:217 310:218 311:219 312:220 313:221 314:222 315:223 316:224 317:225 318:225 319:225 320:225 321:226 322:227 323:228 324:229 325:230 326:231 327:232 328:233 329:234 330:235 331:236 332:237 333:238 334:239 335:240 336:240 337:241 338:242 339:243 340:244 341:245 342:246 343:247 344:248 345:249 346:250 347:251 348:252 349:252 350:253 351:254 352:255 353:256 354:257 355:258 356:259 357:260 358:261 359:262 360:263 361:263 362:264 363:265 364:266 365:267 366:268 367:269 368:270 369:271 370:272 371:273 372:274 373:275 374:276 375:276 376:277 377:278 378:279 379:280 380:281 381:282 382:283 383:284 384:284 385:285 386:286 387:287 388:288 389:289 390:290 391:291 392:292 393:293 394:294 395:295 396:295 397:295 398:296 399:297 400:298 401:299 402:299 403:300 404:301 405:302 406:303 407:304 408:305 409:306 410:307 411:308 412:309 413:309 414:309 415:309 416:310 417:311 418:312 419:313 420:314 421:315 422:316 423:317 424:318 425:319 426:319 427:320 428:321 429:322 430:323 431:323 432:323 433:323 434:324 435:325 436:325 437:326 438:327 439:328 440:329 441:330 442:331 443:332 444:333 445:334 446:335 447:336 448:337 449:338 450:338 451:339 452:340 453:341 454:342 455:342 456:342 457:343 458:344 459:345 460:346 461:347 462:348 463:349 464:349 465:350 466:351 467:352 468:353 469:354 470:355 471:356 472:357 473:358 474:359 475:359\n",
            "I0930 06:59:03.868895 140552314279808 run_squad.py:438] token_to_orig_map: 14:0 15:0 16:1 17:2 18:2 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:13 32:13 33:14 34:15 35:15 36:16 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:26 47:27 48:27 49:27 50:28 51:28 52:28 53:29 54:30 55:31 56:32 57:33 58:33 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:47 75:47 76:47 77:48 78:49 79:49 80:50 81:51 82:52 83:53 84:54 85:55 86:56 87:57 88:58 89:58 90:59 91:60 92:61 93:62 94:62 95:63 96:64 97:64 98:64 99:64 100:65 101:66 102:67 103:68 104:69 105:69 106:69 107:69 108:70 109:71 110:72 111:73 112:73 113:73 114:73 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:81 124:82 125:83 126:83 127:84 128:85 129:86 130:86 131:86 132:87 133:88 134:89 135:90 136:91 137:92 138:93 139:94 140:95 141:96 142:97 143:98 144:99 145:100 146:100 147:100 148:100 149:101 150:102 151:103 152:104 153:105 154:106 155:107 156:108 157:108 158:109 159:110 160:111 161:112 162:113 163:114 164:115 165:116 166:117 167:118 168:118 169:118 170:118 171:119 172:120 173:121 174:121 175:121 176:121 177:122 178:123 179:124 180:125 181:126 182:127 183:128 184:129 185:130 186:131 187:132 188:133 189:134 190:134 191:134 192:135 193:136 194:137 195:137 196:137 197:138 198:139 199:140 200:141 201:142 202:142 203:142 204:143 205:144 206:144 207:145 208:146 209:147 210:148 211:148 212:148 213:148 214:149 215:150 216:151 217:152 218:153 219:153 220:153 221:154 222:155 223:156 224:157 225:157 226:158 227:159 228:160 229:160 230:161 231:162 232:163 233:164 234:165 235:166 236:167 237:168 238:169 239:170 240:171 241:172 242:173 243:174 244:175 245:175 246:175 247:176 248:176 249:177 250:178 251:179 252:180 253:181 254:181 255:181 256:182 257:183 258:184 259:185 260:185 261:185 262:186 263:187 264:188 265:189 266:189 267:189 268:189 269:189 270:189 271:190 272:191 273:192 274:193 275:194 276:195 277:196 278:197 279:198 280:199 281:199 282:199 283:199 284:200 285:201 286:201 287:202 288:203 289:204 290:205 291:205 292:205 293:206 294:207 295:207 296:207 297:208 298:209 299:210 300:211 301:212 302:213 303:214 304:215 305:216 306:216 307:217 308:217 309:217 310:218 311:219 312:220 313:221 314:222 315:223 316:224 317:225 318:225 319:225 320:225 321:226 322:227 323:228 324:229 325:230 326:231 327:232 328:233 329:234 330:235 331:236 332:237 333:238 334:239 335:240 336:240 337:241 338:242 339:243 340:244 341:245 342:246 343:247 344:248 345:249 346:250 347:251 348:252 349:252 350:253 351:254 352:255 353:256 354:257 355:258 356:259 357:260 358:261 359:262 360:263 361:263 362:264 363:265 364:266 365:267 366:268 367:269 368:270 369:271 370:272 371:273 372:274 373:275 374:276 375:276 376:277 377:278 378:279 379:280 380:281 381:282 382:283 383:284 384:284 385:285 386:286 387:287 388:288 389:289 390:290 391:291 392:292 393:293 394:294 395:295 396:295 397:295 398:296 399:297 400:298 401:299 402:299 403:300 404:301 405:302 406:303 407:304 408:305 409:306 410:307 411:308 412:309 413:309 414:309 415:309 416:310 417:311 418:312 419:313 420:314 421:315 422:316 423:317 424:318 425:319 426:319 427:320 428:321 429:322 430:323 431:323 432:323 433:323 434:324 435:325 436:325 437:326 438:327 439:328 440:329 441:330 442:331 443:332 444:333 445:334 446:335 447:336 448:337 449:338 450:338 451:339 452:340 453:341 454:342 455:342 456:342 457:343 458:344 459:345 460:346 461:347 462:348 463:349 464:349 465:350 466:351 467:352 468:353 469:354 470:355 471:356 472:357 473:358 474:359 475:359\n",
            "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True 471:True 472:True 473:True 474:True 475:True\n",
            "I0930 06:59:03.869670 140552314279808 run_squad.py:440] token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True 384:True 385:True 386:True 387:True 388:True 389:True 390:True 391:True 392:True 393:True 394:True 395:True 396:True 397:True 398:True 399:True 400:True 401:True 402:True 403:True 404:True 405:True 406:True 407:True 408:True 409:True 410:True 411:True 412:True 413:True 414:True 415:True 416:True 417:True 418:True 419:True 420:True 421:True 422:True 423:True 424:True 425:True 426:True 427:True 428:True 429:True 430:True 431:True 432:True 433:True 434:True 435:True 436:True 437:True 438:True 439:True 440:True 441:True 442:True 443:True 444:True 445:True 446:True 447:True 448:True 449:True 450:True 451:True 452:True 453:True 454:True 455:True 456:True 457:True 458:True 459:True 460:True 461:True 462:True 463:True 464:True 465:True 466:True 467:True 468:True 469:True 470:True 471:True 472:True 473:True 474:True 475:True\n",
            "INFO:tensorflow:input_ids: 101 2040 15186 1996 5756 3460 1997 2671 3014 2006 2000 2017 1029 102 5564 1010 4698 2118 1010 12993 1010 15186 1996 5756 3014 1997 3460 1997 2671 2006 2033 1012 1996 2168 2095 1010 1045 2363 2019 5756 3014 1997 3460 1997 2671 2013 1996 2462 2102 1010 11831 1012 2875 1996 2203 1997 1010 14855 29045 5311 2118 15186 2006 2033 1996 6225 1997 3460 1997 2671 2012 1037 2569 9530 19152 1012 2000 2026 12208 1010 1996 5756 8972 3014 2001 3018 2012 1037 9530 19152 15506 2058 2011 11268 1012 10164 14115 9516 1012 1045 2001 15186 1996 23731 6819 23706 20668 2319 2247 2007 2852 28217 24409 3286 1012 2023 2051 2002 2018 2908 3458 1996 9859 1997 2151 3460 1010 2729 2030 2769 1012 2009 2018 2042 3053 3174 2086 2144 1045 2018 3734 2026 3014 1999 25010 3330 1012 1000 2115 3942 2003 2438 2005 2033 2000 2131 2092 1010 2339 3288 1037 3460 1998 5247 2769 2006 2010 9883 1000 1029 2009 2003 1996 12943 23296 8462 11657 1997 2035 2122 5919 2008 7288 1996 3014 1998 3737 1997 1037 2711 1005 1055 3947 1998 2836 1012 7188 1045 20215 2055 2026 2269 1005 1055 24436 2740 1010 1045 2052 3942 8223 2229 11872 2213 2007 1037 2204 2103 3460 1012 2296 2051 1045 2106 2061 1010 2002 2052 9610 3207 2033 2005 2026 14203 5142 1998 8835 2033 2006 1996 11727 22667 2006 1996 3460 1012 1999 2671 1010 4507 2003 2008 2029 6526 1012 2043 1045 2587 1996 1038 1012 8040 3014 2607 2012 2358 1012 3312 1005 1055 1010 1045 2001 11499 1997 2151 2060 5724 2005 3020 2495 1012 2974 1010 4406 2671 1010 2003 1037 2177 4023 1012 2007 1037 2695 1011 4619 3014 1999 25010 3330 1998 11532 1999 6228 22755 1010 3103 25329 2213 2001 2132 1997 1996 5090 2177 2012 2852 19422 1012 2065 2017 2024 1037 3213 2040 2052 10082 9544 2000 2022 1037 5160 2030 1037 3460 1010 2115 2517 2616 2097 5438 2021 2431 1996 9012 1997 2115 8141 1025 2065 2017 2024 1037 3836 2040 2052 2738 2022 1037 6883 1010 2115 8128 2097 3113 2021 2431 1996 2342 2005 3716 1997 2115 2493 1025 2065 2017 2024 1037 7155 2040 16424 2671 1010 2115 2836 2097 13225 2021 2431 1996 3791 1997 2115 3260 1012 2004 1045 2298 2012 2009 1010 1996 4130 1997 2671 2064 2467 3612 2083 1996 2540 1012 6360 1010 1045 2150 5204 1997 1996 4489 2090 2671 1998 2974 1010 2090 2470 1998 2458 1012 2275 12221 1998 10520 2015 2031 2467 2042 1998 2467 2097 2022 2019 16112 2112 1997 2151 2476 1010 2130 2028 1999 2671 1012 1045 2031 2802 2026 2166 2699 2000 7861 9869 2026 2269 1999 2026 2219 2088 1997 2671 1998 2974 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.872720 140552314279808 run_squad.py:442] input_ids: 101 2040 15186 1996 5756 3460 1997 2671 3014 2006 2000 2017 1029 102 5564 1010 4698 2118 1010 12993 1010 15186 1996 5756 3014 1997 3460 1997 2671 2006 2033 1012 1996 2168 2095 1010 1045 2363 2019 5756 3014 1997 3460 1997 2671 2013 1996 2462 2102 1010 11831 1012 2875 1996 2203 1997 1010 14855 29045 5311 2118 15186 2006 2033 1996 6225 1997 3460 1997 2671 2012 1037 2569 9530 19152 1012 2000 2026 12208 1010 1996 5756 8972 3014 2001 3018 2012 1037 9530 19152 15506 2058 2011 11268 1012 10164 14115 9516 1012 1045 2001 15186 1996 23731 6819 23706 20668 2319 2247 2007 2852 28217 24409 3286 1012 2023 2051 2002 2018 2908 3458 1996 9859 1997 2151 3460 1010 2729 2030 2769 1012 2009 2018 2042 3053 3174 2086 2144 1045 2018 3734 2026 3014 1999 25010 3330 1012 1000 2115 3942 2003 2438 2005 2033 2000 2131 2092 1010 2339 3288 1037 3460 1998 5247 2769 2006 2010 9883 1000 1029 2009 2003 1996 12943 23296 8462 11657 1997 2035 2122 5919 2008 7288 1996 3014 1998 3737 1997 1037 2711 1005 1055 3947 1998 2836 1012 7188 1045 20215 2055 2026 2269 1005 1055 24436 2740 1010 1045 2052 3942 8223 2229 11872 2213 2007 1037 2204 2103 3460 1012 2296 2051 1045 2106 2061 1010 2002 2052 9610 3207 2033 2005 2026 14203 5142 1998 8835 2033 2006 1996 11727 22667 2006 1996 3460 1012 1999 2671 1010 4507 2003 2008 2029 6526 1012 2043 1045 2587 1996 1038 1012 8040 3014 2607 2012 2358 1012 3312 1005 1055 1010 1045 2001 11499 1997 2151 2060 5724 2005 3020 2495 1012 2974 1010 4406 2671 1010 2003 1037 2177 4023 1012 2007 1037 2695 1011 4619 3014 1999 25010 3330 1998 11532 1999 6228 22755 1010 3103 25329 2213 2001 2132 1997 1996 5090 2177 2012 2852 19422 1012 2065 2017 2024 1037 3213 2040 2052 10082 9544 2000 2022 1037 5160 2030 1037 3460 1010 2115 2517 2616 2097 5438 2021 2431 1996 9012 1997 2115 8141 1025 2065 2017 2024 1037 3836 2040 2052 2738 2022 1037 6883 1010 2115 8128 2097 3113 2021 2431 1996 2342 2005 3716 1997 2115 2493 1025 2065 2017 2024 1037 7155 2040 16424 2671 1010 2115 2836 2097 13225 2021 2431 1996 3791 1997 2115 3260 1012 2004 1045 2298 2012 2009 1010 1996 4130 1997 2671 2064 2467 3612 2083 1996 2540 1012 6360 1010 1045 2150 5204 1997 1996 4489 2090 2671 1998 2974 1010 2090 2470 1998 2458 1012 2275 12221 1998 10520 2015 2031 2467 2042 1998 2467 2097 2022 2019 16112 2112 1997 2151 2476 1010 2130 2028 1999 2671 1012 1045 2031 2802 2026 2166 2699 2000 7861 9869 2026 2269 1999 2026 2219 2088 1997 2671 1998 2974 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.873170 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.973966 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0930 06:59:03.976095 140552314279808 run_squad.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000014\n",
            "I0930 06:59:03.976399 140552314279808 run_squad.py:432] unique_id: 1000000014\n",
            "INFO:tensorflow:example_index: 14\n",
            "I0930 06:59:03.976519 140552314279808 run_squad.py:433] example_index: 14\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0930 06:59:03.976618 140552314279808 run_squad.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is tc ##v ? [SEP] the tactical core vehicle ( tc ##v ) project had been hanging fire for quite some time . [SEP]\n",
            "I0930 06:59:03.976743 140552314279808 run_squad.py:436] tokens: [CLS] what is tc ##v ? [SEP] the tactical core vehicle ( tc ##v ) project had been hanging fire for quite some time . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:4 13:4 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:13\n",
            "I0930 06:59:03.976854 140552314279808 run_squad.py:438] token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:4 13:4 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:13\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True\n",
            "I0930 06:59:03.976957 140552314279808 run_squad.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 22975 2615 1029 102 1996 8608 4563 4316 1006 22975 2615 1007 2622 2018 2042 5689 2543 2005 3243 2070 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.977226 140552314279808 run_squad.py:442] input_ids: 101 2054 2003 22975 2615 1029 102 1996 8608 4563 4316 1006 22975 2615 1007 2622 2018 2042 5689 2543 2005 3243 2070 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.977544 140552314279808 run_squad.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0930 06:59:03.977829 140552314279808 run_squad.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "I0930 06:59:03.979176 140552314279808 run_squad.py:1240] ***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 15\n",
            "I0930 06:59:03.979479 140552314279808 run_squad.py:1241]   Num orig examples = 15\n",
            "INFO:tensorflow:  Num split examples = 15\n",
            "I0930 06:59:03.979655 140552314279808 run_squad.py:1242]   Num split examples = 15\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0930 06:59:03.979859 140552314279808 run_squad.py:1243]   Batch size = 8\n",
            "WARNING:tensorflow:From run_squad.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0930 06:59:03.980095 140552314279808 deprecation_wrapper.py:119] From run_squad.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:Could not find trained model in model_dir: output/, running initialization to predict.\n",
            "I0930 06:59:03.980552 140552314279808 estimator.py:612] Could not find trained model in model_dir: output/, running initialization to predict.\n",
            "WARNING:tensorflow:From run_squad.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0930 06:59:04.015004 140552314279808 deprecation.py:323] From run_squad.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0930 06:59:04.015304 140552314279808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From run_squad.py:703: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0930 06:59:04.017276 140552314279808 deprecation_wrapper.py:119] From run_squad.py:703: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From run_squad.py:710: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0930 06:59:04.022332 140552314279808 deprecation.py:323] From run_squad.py:710: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0930 06:59:04.044630 140552314279808 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0930 06:59:04.044956 140552314279808 tpu_estimator.py:2965] Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0930 06:59:04.045417 140552314279808 run_squad.py:598] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
            "I0930 06:59:04.045619 140552314279808 run_squad.py:600]   name = input_ids, shape = (?, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
            "I0930 06:59:04.045780 140552314279808 run_squad.py:600]   name = input_mask, shape = (?, 512)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
            "I0930 06:59:04.045963 140552314279808 run_squad.py:600]   name = segment_ids, shape = (?, 512)\n",
            "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
            "I0930 06:59:04.046109 140552314279808 run_squad.py:600]   name = unique_ids, shape = (?,)\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0930 06:59:04.050244 140552314279808 deprecation_wrapper.py:119] From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0930 06:59:04.052390 140552314279808 deprecation_wrapper.py:119] From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0930 06:59:04.095557 140552314279808 deprecation_wrapper.py:119] From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0930 06:59:04.155435 140552314279808 deprecation.py:323] From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0e9f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0e9f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:04.250565 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0e9f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0e9f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:04.349188 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:04.444160 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab13fc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:04.568921 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:04.689960 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:04.894908 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.021795 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.117379 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.214036 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.329751 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0a3b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b91d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b91d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.448573 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b91d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b91d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.573766 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.692976 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.798639 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:05.894296 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae0f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae60198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae60198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.016010 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae60198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae60198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.129276 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.232555 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.355440 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.449634 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.547406 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aac52f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.684332 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae2edd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae2edd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.820574 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae2edd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aae2edd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aafceef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aafceef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:06.922362 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aafceef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aafceef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.043802 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.144201 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.242865 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab1acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab34208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab34208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.363020 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab34208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab34208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.484271 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.603426 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf886a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.721472 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.827094 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:07.934912 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa97bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99e128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.075777 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99e128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.196949 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aad80160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aad80160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.301177 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aad80160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aad80160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.532409 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.633059 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.728302 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aacd2390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99eef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99eef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.864094 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99eef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa99eef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:08.974359 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa8b0e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa8b0e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.087675 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa8b0e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa8b0e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.208892 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.303702 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.403286 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa661208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa844278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa844278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.537547 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa844278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa844278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.664347 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.798390 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab9cdfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:09.926753 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.022429 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.117869 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5628d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5076a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5076a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.242777 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5076a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa5076a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.355265 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.455533 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab0b9390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.576179 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.670825 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.764395 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa3701d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa570748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa570748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:10.893727 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa570748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa570748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaba7a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaba7a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.011537 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaba7a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaba7a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.139429 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aaf03390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa1c6da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa1c6da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.280103 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa1c6da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa1c6da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.400832 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.519497 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa14e320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa413780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa413780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.650201 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa413780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa413780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.784505 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aab48400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:11.896155 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.016315 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.108047 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.204436 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa28c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa0ba470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa0ba470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.329611 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa0ba470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa0ba470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa69bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa69bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.441073 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa69bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa69bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.543715 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4aa540320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab124dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab124dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0930 06:59:12.843708 140552314279808 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab124dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4ab124dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From run_squad.py:632: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0930 06:59:13.250978 140552314279808 deprecation_wrapper.py:119] From run_squad.py:632: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0930 06:59:14.363003 140552314279808 run_squad.py:634] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363233 140552314279808 run_squad.py:640]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363386 140552314279808 run_squad.py:640]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363478 140552314279808 run_squad.py:640]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363559 140552314279808 run_squad.py:640]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363643 140552314279808 run_squad.py:640]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363717 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363792 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363862 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.363935 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364001 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364072 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364139 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364209 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364276 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364375 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364470 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364545 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364612 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364691 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364758 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364824 140552314279808 run_squad.py:640]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364891 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.364972 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365044 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365117 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365185 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365261 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365344 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365420 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365486 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365550 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365618 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365704 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365772 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365845 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365911 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.365996 140552314279808 run_squad.py:640]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366073 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366158 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366230 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366309 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366401 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366481 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366549 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366620 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366697 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366768 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366836 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366914 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.366986 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367063 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367130 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367195 140552314279808 run_squad.py:640]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367264 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367362 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367449 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367523 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367589 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367669 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367736 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367805 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367872 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.367939 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.368008 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.368078 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.368143 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.448735 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.448939 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.449212 140552314279808 run_squad.py:640]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.449397 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.449568 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.449717 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.449870 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450025 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450181 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450312 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450481 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450625 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450765 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.450905 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.451073 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.451221 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.451387 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.451532 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.451675 140552314279808 run_squad.py:640]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.451849 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.452075 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.452228 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.452401 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.452547 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.452702 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.452846 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453008 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453157 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453298 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453459 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453604 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453746 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.453896 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454050 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454193 140552314279808 run_squad.py:640]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454379 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454537 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454684 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454835 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.454974 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.455142 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.455285 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.455458 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.455602 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.455744 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.455886 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456054 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456199 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456366 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456512 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456655 140552314279808 run_squad.py:640]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456794 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.456942 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.457101 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.457255 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.457416 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.457588 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.457734 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.457883 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458036 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458178 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458333 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458491 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458634 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458782 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.458923 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459078 140552314279808 run_squad.py:640]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459219 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459387 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459532 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459681 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459822 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.459969 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.460127 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.460277 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.460440 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.460583 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.460722 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.460873 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461025 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461179 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461334 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461480 140552314279808 run_squad.py:640]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461623 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461774 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.461916 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462082 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462227 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462396 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462541 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462690 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462830 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.462970 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.463127 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.463276 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.463440 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.463592 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.463731 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.463871 140552314279808 run_squad.py:640]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464023 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464178 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464336 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464494 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464641 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464791 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.464932 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465098 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465240 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465401 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465545 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465697 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465838 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.465998 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.466146 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.466285 140552314279808 run_squad.py:640]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.466444 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.466598 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.466739 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.466887 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467042 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467198 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467358 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467515 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467659 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467799 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.467936 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.468105 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.468247 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.468419 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.468581 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.468729 140552314279808 run_squad.py:640]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.468872 140552314279808 run_squad.py:640]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.469036 140552314279808 run_squad.py:640]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.469180 140552314279808 run_squad.py:640]   name = cls/squad/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "I0930 06:59:14.469349 140552314279808 run_squad.py:640]   name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0930 06:59:14.469940 140552314279808 estimator.py:1147] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0930 06:59:14.617131 140552314279808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0930 06:59:14.976290 140552314279808 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-30 06:59:14.976705: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-09-30 06:59:14.981148: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2020-09-30 06:59:14.981474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1948840 executing computations on platform Host. Devices:\n",
            "2020-09-30 06:59:14.981524: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-09-30 06:59:15.323598: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0930 07:00:21.988748 140552314279808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0930 07:00:22.043081 140552314279808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Processing example: 0\n",
            "I0930 07:00:44.988126 140552314279808 run_squad.py:1259] Processing example: 0\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0930 07:01:04.289424 140552314279808 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0930 07:01:04.289705 140552314279808 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:Writing predictions to: output/predictions.json\n",
            "I0930 07:01:04.289885 140552314279808 run_squad.py:745] Writing predictions to: output/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: output/nbest_predictions.json\n",
            "I0930 07:01:04.289981 140552314279808 run_squad.py:746] Writing nbest to: output/nbest_predictions.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyH5k7Vs29zu"
      },
      "source": [
        "#Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRZOyriW3au4"
      },
      "source": [
        "!cp \"/content/bert/output/predictions.json\" \"/content/drive/My Drive/Thesis project/Thesis project/datasets/post BERT\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGMtO6Vb5vIC"
      },
      "source": [
        "import csv\n",
        "with open(\"/content/drive/My Drive/Thesis project/Thesis project/datasets/post BERT/questions.csv\",\"w\") as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow([\"Questions\"])\n",
        "  for t in test_questions:\n",
        "    writer.writerow([t]) "
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}