{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Q/A.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanaythakral/BERT-Q-A/blob/master/BERT%20for%20QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAac8I9PszN2"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8tpzbIxsx8l",
        "outputId": "74fc96dd-406d-4f78-961b-2719da5d46ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuuAk1XCsx7Q",
        "outputId": "3cc19b77-df99-4797-a770-da46e476562b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Thesis project/Thesis project/datasets/WOF_split_into_sentences.csv')\n",
        "sentences = list(df['Sentences'])\n",
        "len(sentences)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0bANhj3vS7t",
        "outputId": "10949909-8eb4-4aa7-a1a2-0692d0255ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.35.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4r97qrSs1Mr"
      },
      "source": [
        "#Context Extraction \n",
        "Using TF-IDF cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LrnnlWns_gg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk import wordpunct_tokenize, WordNetLemmatizer, sent_tokenize, pos_tag\n",
        "from nltk.corpus import stopwords as sw, wordnet as wn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import string \n",
        "import json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reZhLQBds_fM"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "X = normalize(X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfQilXwis_eg",
        "outputId": "9974a492-6bc3-49e0-9fd8-e0e3ccac2a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3085, 6929)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFYQTr5Ms_d3"
      },
      "source": [
        "def get_context(query,X,data_sentences):\n",
        "  Question = vectorizer.transform([query])\n",
        "  Question = normalize(Question)\n",
        "  cosineSimilarities = cosine_similarity(Question, X).flatten()\n",
        "  idx = cosineSimilarities.argsort()[::-1][:20]\n",
        "  temp = \"\"\n",
        "  print(query)\n",
        "  for i in idx:\n",
        "    if(cosineSimilarities[i] != 0):\n",
        "      # if(i-1 >=0):\n",
        "      #   temp = temp + data_sentences[i-1]\n",
        "      temp = temp + data_sentences[i]\n",
        "      # if(i+1 < len(data_sentences)):\n",
        "      #   temp = temp + data_sentences[i+1]\n",
        "  return temp\n",
        "\n",
        "def make_json_list(queries,X,sentences):\n",
        "  jsondata = {}\n",
        "  data1 = {}  \n",
        "  paras =[]\n",
        "  gpt2_feed = []\n",
        "  for idx,query in enumerate(queries):\n",
        "    context = get_context(query,X,sentences)\n",
        "    if(context == \"\"):\n",
        "      gpt2_feed.append(query)\n",
        "      continue\n",
        "    qa1 = {}\n",
        "    qa1[\"question\"] = query\n",
        "    qa1[\"id\"] = str(idx)\n",
        "    qa1[\"is_impossible\"] = \"\"\n",
        "    qas = [qa1]\n",
        "    paragraph1 = {}\n",
        "    paragraph1[\"qas\"] =[qa1]\n",
        "    paragraph1[\"context\"] = context\n",
        "    paras.append(paragraph1)\n",
        "\n",
        "  data1[\"paragraphs\"] = paras\n",
        "  data1[\"title\"] = \"WOF\"\n",
        "  data = [data1]\n",
        "  jsondata[\"version\"] = \"v2.0\"\n",
        "  jsondata[\"data\"] = data\n",
        "  jstr = json.dumps(jsondata,indent = 5)\n",
        "  print(jstr)\n",
        "  return jstr\n",
        "\n",
        "\n",
        "def make_json(query,X,sentences,idx):\n",
        "  context = get_context(query,X,sentences)\n",
        "  if(context == \"\"):\n",
        "    return 0\n",
        "  jsondata = {}\n",
        "  data1 = {}  \n",
        "  qa1 = {}\n",
        "  paragraph1 = {}\n",
        "  qa1[\"question\"] = query\n",
        "  qa1[\"id\"] = str(idx)\n",
        "  qa1[\"is_impossible\"] = \"\"\n",
        "  qas = [qa1]\n",
        "  paragraph1[\"qas\"] =[qa1]\n",
        "  paragraph1[\"context\"] = context\n",
        "  \n",
        "  \n",
        "  paras = [paragraph1]\n",
        "  data1[\"paragraphs\"] = paras\n",
        "  data1[\"title\"] = \"WOF\"\n",
        "  data = [data1]\n",
        "  jsondata[\"version\"] = \"v2.0\"\n",
        "  jsondata[\"data\"] = data\n",
        "  jstr = json.dumps(jsondata,indent = 5)\n",
        "  print(json.dumps(jsondata,indent = 5))\n",
        "  return jstr"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G07wuzdzs_c-"
      },
      "source": [
        "test_questions = [\"What is your name?\",\"What is SLV?\", \"When is your birthday?\" , \"Who is Narayan?\", \"Who is your sister?\", \"where are you from?\", \"Where is Pentagon?\" , \"where did Trishul take off from?\", \"What is Prithvi?\" ,\"What is Astra?\", \"Did you have childhood friends?\",\"Which school did you go to as a child?\" , \"when did you start liking Science?\", \"What was your role in Nike-Apache?\" , \"What are sounding rockets used for?\" , \"Are you religious?\" , \"What is SAM?\" , \"Who is Indira Gandhi?\" , \"Who conferred the Honorary Doctor of Science degree on to you?\" , \"What is TCV?\"]\n",
        "test_questions_B = [\"How can I overcome difficulty?\",\"Why did I fail?\",\"How can I become successful?\",\"How can I be more creative?\",\"What is love?\",\"Do you need to fail to succeed?\",\"Is there an afterlife?\",\"What is the meaning of life?\",\"How do you judge a person?\",\"What is the most important thing in you life?\",\"What is your definition of success?\",\"What type of person do I want to be?\",\"How can you love yourself more today?\",\"How can you change someone's life for the better today?\",\"What inspire you the most?\",\"What should I do next?\",\"What should I have for dinner?\",\"cheer up\",\"what is your mission?\"]\n",
        "test_questions_C = [\"Why do we create Art?\", \"What is free will?\", \"What is freedom\",\"What is truth?\",\"What is the soul?\",\"What do you fear most?\",\"Is there such a thing as luck\",\"Are clowns funny or scary?\",\"What are rights?\",\"What is mercy?\",\"What is self-esteem?\",\"what is age?\",\"Can money buy happiness?\",\"Do you like music?\",\"What are dreams?\",\"How to be happy?\",\"What is beauty?\",\"Should you forgive people?\",\"Is our universe real?\",\"Does god exist?\",\"What is friendship?\",\"What is patriotism?\",\"Are wars necessary?\",\"What is time?\",\"What do you think about time travel?\",\"What is philosophy?\",\"Who are you?\",\"Do animals have feelings?\",\"What is the goal of life?\",\"Is lying okay?\",\"Is humanity headed in the right direction?\",\"What is wisdom?\",\"What is waste of human potential?\",\"What is funny?\",\"Are animals moral?\",\"is privacy a right?\",\"What is your definition of evil?\",\"Is censorship necessary?\",\"Who are you?\",\"How to be confident?\",\"Is everyone's life value equal?\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD3x_guOuEJ"
      },
      "source": [
        "test_questions_philosophy = test_questions_B + test_questions_C"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_y0m2KO0tz",
        "outputId": "0710eec2-4fb1-43fa-e011-145af642463a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(test_questions_philosophy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dxUNnAkQPGc"
      },
      "source": [
        "jstr = make_json_list(test_questions_C,X,sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac-YYsECQboE"
      },
      "source": [
        "filename = \"/content/drive/My Drive/Thesis project/Thesis project/datasets/jsons/context.json\"\n",
        "save_json(jstr,filename)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IywmpB-BtZho"
      },
      "source": [
        "def save_json(jstr,filename):\n",
        "  with open(filename, \"w\") as outfile: \n",
        "    outfile.write(jstr) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfVKdEYltBXt"
      },
      "source": [
        "#BERT Q/A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNdTz5a1tIJ8",
        "outputId": "ced34318-0d5a-4c33-c6c9-be8e45a1333a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.85 KiB | 4.07 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "--2020-10-01 18:45:44--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.124.128, 172.217.212.128, 172.217.214.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.124.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M  84.1MB/s    in 5.9s    \n",
            "\n",
            "2020-10-01 18:45:50 (65.6 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo_RMir3vDL3",
        "outputId": "044c879c-4b14-409c-ebe0-6a2165d6eac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd bert"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCztOOvNungT",
        "outputId": "4f2eb73f-8cd3-44f1-e520-dbbc0e4c8e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is => ', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU address is =>  grpc://10.33.99.162:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 12367101994050641944),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6361398146712378670),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7922992186653088150),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14664204367298079330),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2407478756424986262),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13524195400686258921),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12595504404499426901),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7006396697049832972),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5982699396838716067),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 929138062685910794),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 167757144296703676)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhzUdM8puqIQ",
        "outputId": "f9bc1e09-bd76-4fe5-a012-a9458e259fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "BUCKET = 'bucket-bert-qa' #@param {type:\"string\"}\n",
        "assert BUCKET, '*** Must specify an existing GCS bucket name ***'\n",
        "output_dir_name = 'bert_output' #@param {type:\"string\"}\n",
        "BUCKET_NAME = 'gs://{}'.format(BUCKET)\n",
        "OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET,output_dir_name)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://bucket-bert-qa/bert_output *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YtEyIvxuyQU"
      },
      "source": [
        "!cp \"/content/drive/My Drive/Thesis project/Thesis project/datasets/jsons/context.json\" \"/content/bert\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M7PGeWYUV56",
        "outputId": "e04bf16a-ca77-4156-8f2f-7cd895b9ddb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "context.json\t\t    predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
            "CONTRIBUTING.md\t\t    README.md\n",
            "create_pretraining_data.py  requirements.txt\n",
            "extract_features.py\t    run_classifier.py\n",
            "__init__.py\t\t    run_classifier_with_tfhub.py\n",
            "LICENSE\t\t\t    run_pretraining.py\n",
            "modeling.py\t\t    run_squad.py\n",
            "modeling_test.py\t    sample_text.txt\n",
            "multilingual.md\t\t    tokenization.py\n",
            "optimization.py\t\t    tokenization_test.py\n",
            "optimization_test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHwzYd2IvHgA"
      },
      "source": [
        "def run():\n",
        "  !python run_squad.py \\\n",
        "    --vocab_file=$BUCKET_NAME/uncased_L-12_H-768_A-12/vocab.txt \\\n",
        "    --bert_config_file=$BUCKET_NAME/uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "    --init_checkpoint=$OUTPUT_DIR/model.ckpt-10859 \\\n",
        "    --do_train=False \\\n",
        "    --max_query_length=30  \\\n",
        "    --do_predict=True \\\n",
        "    --predict_file=context.json \\\n",
        "    --predict_batch_size=8 \\\n",
        "    --n_best_size=3 \\\n",
        "    --max_seq_length=512 \\\n",
        "    --doc_stride=128 \\\n",
        "    --version_2_with_negative=True \\\n",
        "    --output_dir=output/"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuKnZVYtUhmG"
      },
      "source": [
        "run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOAsv79lPfgg"
      },
      "source": [
        "def load_json(filename):\n",
        "  with open(filename) as f:\n",
        "    res = json.load(f)\n",
        "    return res"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMA-e7dPNVgi"
      },
      "source": [
        "def process_individual(query,X,sentences,idx):\n",
        "  jstr = make_json(query,X,sentences,idx)\n",
        "  if(jstr == 0):\n",
        "    print(\"No context\")\n",
        "    return 0 \n",
        "  else:\n",
        "    filename = \"/content/bert/context.json\"\n",
        "    save_json(jstr,filename)\n",
        "    run()\n",
        "  return jstr"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYdCM-ALOhuP"
      },
      "source": [
        "def make_prediction(questions,X,sentences):\n",
        "  predictions = {}\n",
        "  for idx,query in enumerate(questions):\n",
        "    jstr = process_individual(query,X,sentences,idx)\n",
        "    if(jstr == 0):\n",
        "      continue\n",
        "    filename = \"/content/bert/output/predictions.json\"\n",
        "    res = load_json(filename)\n",
        "    if(str(idx) in res):\n",
        "      predictions[str(idx)] = res[str(idx)]\n",
        "  return predictions"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QiFvF9EXvNO"
      },
      "source": [
        "pred = make_prediction(test_questions_C,X,sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OueNHRqpYTr9"
      },
      "source": [
        "filename = \"/content/drive/My Drive/Thesis project/Thesis project/datasets/post BERT/predictions_B.json\"\n",
        "p1 = json.dumps(pred)\n",
        "save_json(p1,filename)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxzdvpTRcup2",
        "outputId": "351427bd-a5e9-4b79-f527-7322a1ce87c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "pred"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': '',\n",
              " '1': '',\n",
              " '10': 'I too could aspire to become whatever I wished',\n",
              " '11': 'sixty years of age',\n",
              " '12': 'The entire room was irradiated with happiness.',\n",
              " '13': \"I filled my room with the music of Bismillah Khan's shehnai\",\n",
              " '14': \"two plans have evolved out of the nation's dreams\",\n",
              " '15': 'I am happy to see your work',\n",
              " '16': '',\n",
              " '18': 'This is made real',\n",
              " '19': 'They exist at various levels of the human personality',\n",
              " '2': '',\n",
              " '20': 'equal warmth',\n",
              " '22': 'wars were waged over religious and ideological beliefs',\n",
              " '23': 'a second re-organization',\n",
              " '24': '',\n",
              " '25': 'one-to- one substitution',\n",
              " '27': 'I experienced mixed feelings',\n",
              " '28': 'the goal that makes the difference',\n",
              " '3': 'there is a great deal that most of us can individually do to increase our freedom',\n",
              " '30': '',\n",
              " '32': '',\n",
              " '34': 'moral compulsion',\n",
              " '35': '',\n",
              " '37': '',\n",
              " '39': 'tense',\n",
              " '4': 'Nandi',\n",
              " '40': 'His friendship embraced with equal warmth',\n",
              " '6': 'If there is one thing outsiders dislike, it is unpleasant surprises'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyH5k7Vs29zu"
      },
      "source": [
        "#Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRZOyriW3au4"
      },
      "source": [
        "!cp \"/content/bert/output/predictions.json\" \"/content/drive/My Drive/Thesis project/Thesis project/datasets/post BERT\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGMtO6Vb5vIC"
      },
      "source": [
        "import csv\n",
        "with open(\"/content/drive/My Drive/Thesis project/Thesis project/datasets/post BERT/questions_philosophy.csv\",\"w\") as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow([\"Questions\"])\n",
        "  for t in test_questions_B:\n",
        "    writer.writerow([t]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s454czRY8PX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}